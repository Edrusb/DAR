<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <link href="style.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta content="text/html; charset=ISO-8859-1" http-equiv="content-type">
    <title>DAR/LIBDAR Internals - Notes</title>
  </head>
  <body>

    <a name="top">&nbsp;</a>
    <div class=top>
      <img alt="Dar Documentation" src="dar_s_doc.jpg" style="float:left;">
      <h1>Dar/Libdar Internals - Notes</h1>
    </div>

    <div class=jump>
      <div class=menuitem>
	<a href="#top">Back to top</a>
      </div>
    </div>

    <div class=page>
      <div class=menuleft>
	<div class=menuitem>
	  <a href="#intro">Introduction</a>
	</div>
	<div class=menuitem>
	  <a href="#EA_and_diff">EA &amp; differential backup</a>
	</div>
	<div class=menuitem>
          <a href="#archive_structure">Archive structure in brief</a>
	</div>
	<div class=menuitem>
	  <a href="#overflow">Overflow in arithmetic integer operations</a>
	</div>
	<div class=menuitem>
	  <a href="#thread_safe">libdar and thread-safe requirement</a>
	</div>
	<div class=menuitem>
	  <a href="#NLS">Native Language Support</a>
	</div>
	<div class=menuitem>
	  <a href="#Dar_relase_Process_in_brief">Dar Release Process</a>
	</div>
	<div class=menuitem>
	  <a href="#Dar_version_naming">Dar's Versions</a>
	</div>
	<div class=menuitem>
          <a href="#scrambling">Scrambling (weak encryption)</a>
	</div>
	<div class=menuitem>
	  <a href="#strong_encryption">Strong encryption internals</a>
	</div>
	<div class=menuitem>
          <a href="#asym">Public key based encryption internals</a>
	</div>
	<div class=menuitem>
	  <a href="#multi-threaded">Multi-threading in libdar</a>
	</div>
	<div class=menuitem>
	  <a href="#block_compression_mode">Streaming versus block Compression mode</a>
	</div>

      </div>

      <div class=mainleft>

	<h2><a name="intro">Introduction</a></h2>
	<p>
	  Here takes place a collection of notes. These have been created after
	  implementation of a given feature, mainly for further
	  reference but also as user information. The idea behind
	  these notes are to remind some choices of implementation, the
	  arguments and reasons that lead to them, but also
	  let the user have a way to be informed about the
	  choices done and be able to bring his remarks without having
	  to deeply look into the code to learn dar's internals.
	</p>

	<h2><a name="EA_and_diff">EA &amp; differential backup</a></h2>

	<h3>Brief presentation of EA:</h3>

	<p>
	  EA stands for <i>Extended Attributes</i>.
	  In Unix filesystem a regular file is composed of a
          set of bytes (the data) and an <i>inode</i> (containing the <i>metadata</i>).
	  The inode add properties to the file, such as owner, group, permission, dates (last
          modification date of the data [mtime], last access date to
          data [atime], and last inode change date [ctime]), etc). Last,
          the name of the file is not contained in the inode, but in the
          directory(ies) it is linked to. When a file is linked more
          than once in the directory tree, we speak about "hard links".
          This way the same data and associated inode appears several
          time in the same or different directories. This is not the
          same as a symbolic links, which later one is a file that contains the
          path to another file (which may or may not exist). A symbolic
          link has its own inode. OK, now let's talk about EA:
	</p>

	<p>
	  Extended attributes is a recent feature of Unix file system (at the time
          of the writing, year 2002). They are not part of the
          inode, nor part of the data, nor part of a given directory. They
          are stored beside the inode and are a set of pair of <i>key</i> and
          <i>value</i>. The owner of the file can add or define any key and
          eventually associate it an arbitrary data value. The user has also
	  the means to list and remove a particular key for the EA.
	  What are they used for: Simply a more flexible way to associate information to a file.
	</p>
	<p>
          One particular interesting use of EA, is ACL: <i>Access Control
            List</i>. ACL are implemented using EA (Linux) and add a more fine grain
          in assigning access permission to file. For more information one
          EA and ACL, see the site of Andreas Grunbacher:
	</p>

	<p>
          <a href="http://acl.bestbits.at/">http://acl.bestbits.at/</a>
	</p>

	<p>
	  File forks under MACOS X also relies on EA, as well the security features
	  brought by SELinux.
	</p>


	<h3>EA &amp; Differential Backup</h3>
	<p>
	  to determine
          that an EA has changed, <i>dar</i> looks at the <i>ctime</i> value of the
	  inode. if <i>ctime</i>
          has changed, (due to EA change, but also due to permission or owner
          change) dar saves the EA. ctime also changes, if atime or mtime
          changes. So if you access a file or modify it, dar will consider
          that the EA have changed also. This is not really fair, I admit.
	</p>
	<p>
          It may sound better would be to compare EA one by one, and record
          those that have changed or have been deleted. But to be able to do
          so, all EA and their associated values  must reside in the archive
	  table of content (the <i>catalogue</i>), which is by design stored
	  in memory. As EA can grow up to 64 KB by file, this can lead to a
          quick saturation of the virtual memory, which is already enough
          solicited by other information from <i>catalogue</i>.
	</p>
	<p>
          These two schemes implies a different pattern for saving EA in
          archive. In the first case (no EA in memory except at time of
          operation on it), to avoid skipping in the archive (and ask the
          user to change of disks too often, or just put pressure on the cache and
	  disk I/O), EA must be stored beside the
          data of the file (if present). Thus they must be distributed all
          along the archive (except at the end that only contains the
          catalogue).
	</p>
	<p>
          In the second case (EA are loaded in memory for comparison), EA
          must reside beside or within the catalogue, in any case at the
          end of the archive, not to have to user to need all disks to
          just take an archive as reference.
	</p>
	<p>
          As the catalogue grows already fast with the number of file to
          save (from a few bytes for hard_link to 400 bytes around per
          directory inode), the memory saving option has been adopted.
	</p>
	<p>
          Thus, EA changes are based on the ctime change. Unfortunately,
          no system call permits to restore ctime. Thus, restoring a
          differential backup after its reference has been restored, will
          present restored inode as more recent than those in the
          differential archive, thus the <code>-r</code> option would prevent any EA
          restoration. In consequence, <code>-r</code> has been disabled for EA, it
          does only concern data contents. If you don't want to restore
          any EA but just more recent data, you can use the following :
	  <code> -r -u "*"</code>
	</p>

	<h2><a name="archive_structure">Archive structure in brief</a></h2>

	<h3>The Slice Level</h3>
	<p>
	  A slice is composed of a header,
          data and trailer (the trailer appeared with archive format
          version 8)
	</p>
	<code class=block>
	  +--------+-------------------------------------------+-------+
	  | header |  Data                                     |Trailer|
	  |        |                                           |       |
	  +--------+-------------------------------------------+-------+
	</code>

	<p>
          the <b>slice header</b> is composed of:
	</p>

	<ul>
          <li>a magic number that tells this is a dar slice</li>
          <li>
	    a internal_name which is unique to a given archive and
            shared by all slices
          </li>
          <li>
	    a flag that tells whether the slice is the last of the
            archive or whether a trailer is present that contains this
            info.
          </li>
          <li>
	    a extension flag, that was used in older archive but which
            now always set to 'T' telling that a TLV list follows
	  </li>
          <li>
	    A TLV (Type Length Value) list of item, it contains:
	  </li>
          <ul>
            <li>the slice size</li>
            <li>first slice size</li>
            <li>the data_name</li>
          </ul>
	</ul>

	<p>
	  The TLV list will receive any
          future new field related to slice header.
	</p>
	<code class=block>
	  +-------+----------+------+-----------+-------+
	  | Magic | internal | flag | extension | TLV   |
	  | Num.  | name     | byte | byte      | list  |
	  +-------+----------+------+-----------+-------+
	</code>
	<p>
          The header is the first thing
          to be written, and if the current slice is not the last slice
          (all data to write could not fit in it), before format 8, the
          flag field was changed indicating that another slice follows.
          Since archive format 8, the flag is set to a specific value
          indicating that the information telling whether the slice is
          the last or not is placed in a slice trailer, a new
          "structure" that appeared with that format and which is
          located at the end of each slice.
	</p>
	<p>
          The header is also the first part to be read.
	</p>
	<p>
          A TLV list is of course a list of TLV:
	</p>
	<code class=block>
	  +-------+----------+------+-----------+- ...-----+-------+
	  | Number| TLV 1    | TLV 2| TLV 3     |          | TLV n |
	  | of TLV|          |      |           |          |       |
	  +-------+----------+------+-----------+--...-----+-------+
	</code>
	<p>
          Each TLV item is, as commonly,
          defined as set of three fields:
	</p>
	<code class=block>
	  +---------+-------------------------+-------------------------+
	  | Type    | Length                  | Value                   |
	  |(2 bytes)| (arbitrary large value) | (arbitrary large data)  |
	  +---------+-------------------------+-------------------------+
	</code>

	<p>
          The 2 bytes type is large
          enough for today's need (65535 different types while only
          three used), however TLV 65535 is reserved for future use and
          will signal a new format for the type field.
	</p>

	<p>
	  To know in
          which slice and at which position to find a particular data, dar
          needs to know each file's size. This is the reason why each
          slice contains the slice size information, in particular the
          last slice. In older version, dar had to read the first slice
          first to get this slicing information. Then it could read the
          archive contents at the end of the last slice. Today, reading
          the last slice, dar can fetch the slicing scheme from the slice
          header (what we just detailed) and fetch the archive contents at
          the end of this same last slice.
	</p>
	<p>
          <b>The trailer</b> (which is one byte length) is new since archive
          format version 8 (released 2.4.0). It contains the value that
          was located in the header flag field in older archive format,
          telling whether the slice is the last of the archive or not.
          When writting down a single sliced archive (no -s option
          provided), both the header and the trailer tell that the slice
          is the last of the archive (duplicated information). However,
          when doing multi-sliced archive, it is not possible to known
          whether a slice is the last before reaching the requested amount
          of data per slice (which depends on the amount of byte to save,
          compression ratio, encryption overhead, etc.). Thus the header
          flag contains a value telling that to know whether the slice is
          the last or not, one must read the trailer.
	</p>
	<p>
          In older format, it was necessary to seek back to update the
          header with the correct information when a new slice had to be
          created. But, keeping this behavior, it would not have been
          possible to make a digest "on the fly" (see --hash option). The
          addition of the trailer was required for that feature: to
          compute a md5 or sha1, ... hash for each slice. But, this costs
          one byte per slice, yes.
	</p>

	<h3>Data Name</h3>
	<p>
	  As seen above in the header
          fields, we have among others the three following identifiers:
	</p>
	<ul>
          <li>magic number</li>
          <li>internal name</li>
          <li>data name</li>
	</ul>

	<p>
	  As already said, magic number
          is constant and let dar be (almost) sure a given file is a dar
          slice file, this is also based in particular on that field
          that the common unix 'file' command identifies an dar archive.
          Also briefly explained, the internal_name is a identifier that
          let dar be almost sure that several slices are from the same
          archive (problem car arise if two archives of same basename
          have their slices mixed together: dar will see that and report
          it to the user).
	</p>
	<p>
          The new and not yet described field is the "data_name". The
          data_name field is also present in the archive catalogue (the
          table of content) of each archive. It may be the same value as
          the one in the slice headers (normal archives) or another
          value if the archive results from a catalogue isolation
          process.
	</p>
	<p>
          Why this field? A new feature with release 2.4.0 is the
          ability to use an extracted catalogue to backup a internal
          catalogue of a given archive. Comparing the data_name value of
          the catalogue resulting from the isolation operation to the
          data_name value present int the slices of an archive to
          rescue, dar can be (almost) sure that the extracted catalogue
          matches the data present in the archive the user is trying to
          use it with.
	</p>
	<p>
          In brief:
	</p>
	<div class=table>
	  <table class=center>
            <tr>
              <th>Fields</th>
	      <th>Normal Archive</th>
              <th>Resliced Using dar_xform</th>
              <th>Resulting From Isolation</th>
	      <th>isolated archive resliced with dar_xform</th>
	    </tr>
            <tr>
              <th>Internal_name (slice header)</th>
              <td>A</td>
              <td>B</td>
              <td>C</td>
              <td>D</td>
            </tr>
            <tr>
              <th>data_name (slice header)</th>
              <td>A</td>
              <td>A</td>
              <td>C</td>
              <td>C</td>
            </tr>
            <tr>
              <th>data_name (archive catalogue)</th>
              <td>A</td>
              <td>A</td>
              <td>A</td>
              <td>A</td>
            </tr>
	  </table>
	</div>

	<h3>Archive Level</h3>
	<p>
	  The archive level describes
          the structure of the slice's data field (removing header and
          trailer of each slice), when they are all sticked together
          from slice to slice:
	</p>
	<code class=block>
	  +---------+----------------------------+-----------+--------+---------+--------+
	  | version |   Data                     | catalogue | term 1 | version | term 2 |
	  | header  |                            |           |        | trailer |        |
	  +---------+----------------------------+-----------+--------+---------+--------+
	</code>

	<h4>version header</h4>
	<p>
          The <b>version header</b> is an almost diplication of <i>version trailer</i>. It is
          used when reading an archive in sequential mode, to be able to
          prepare the proper compression layer, and known whether escape
          sequence mark are present in the archive. It is present by default but absent
	  when removing tape marks (<code>-at</code> option).
	</p>

	<h4>version trailer</h4>
	<p>
          the <b>version trailer</b> (which may still be called "version header" in
          some part of the documentation because it was originally located at
          the beginning of the archive in previous archive format) is
          composed of:
	</p>

	<ul>
          <li>edition version of the archive</li>
          <li>compression algorithm used</li>
          <li>
	    command line used for creating the archive, now known as
            "user comment"
          </li>
          <li>flag, telling:
            <ul>
              <li>whether the archive is encrypted,</li>
              <li>whether it has escape sequence marks,</li>
              <li>whether the header/trailer contains an encrypted key</li>
              <li>whether the header/trailer contains the initial offset field</li>
              <li>whether the archive is signed</li>
              <li>
		whether the header/trailer contains the slice
		layout of the archive of reference
	      </li>
              <li>
		whether the archive has salt+iteration count+hash algo for
		key derivation fonction (KDF)
              </li>
            </ul>
          <li>
	    initial offset (telling where starts the data in the
            archive, is only present in the trailer)
	  </li>
          <li>
	    crypto algorithm used (present only if flag tells that the
            archive is encrypted)
	  </li>
          <li>
	    size of the crypted key that follows (present only if the
            flag tells an encrypted key is present)
	  </li>
          <li>
	    encrypted key (encrypted by mean of GPG asymetric algorithm,
            present only if flag says so)
	  </li>
	  <li>
	    the slice layout of the backup of reference if the current archive
	    is an isolated catalogue
	  </li>
          <li>
	    eventually, salt, iteration_count and hash algo for key
            derivation fonction (KDF) (used since version 2.6.0 when
            strong encryption is set)
          </li>
          <li>
	    CRC (Cyclic Redundancy Check) computed on the whole version
            header or trailer
          </li>
	</ul>

	<code class=block>
	  +---------+------+---------------+------+--------+-------+----------+---------------+------------+------+------+-----------+-----+-------+
	  | edition | algo | command line  | flag | initial| crypto| crypted  | gnupg crypted |  reference | salt | salt | iteration |hash | CRC   |
	  |         |      |               |      | offset | algo  | key size | sym. key      |  slicing   | size | (KDF)| count(KDF)|(KDF)|       |
	  +---------+------+---------------+------+--------+-------+----------+---------------+------------+------+------+-----------+-----+-------+
	</code>

	<p>
	  The trailer is used when
          reading an archive in direct access mode, to build the proper
          compression layer, escape layer (it is needed if mark have
          been inserted in the archive to un-escape data that could else
          be taken as an escape sequence mark) and encryption layer.
	</p>

	<h4>Slice Layout</h4>

	<p>
	  <b>slice_layout</b> is a class holding information about the first slice size, other file size as well as size of slice headers.
	  It is used in <em>sar</em> class to store the slicing information read from the class <em>header</em> which for historical reason
	  does not use the slice_layout class but read/write those fields as independent ones. Class <em>sar</em> thus relies on class <em>header</em>
	  to read or write this information to/from an archive.
	</p>
	<p>
	  This class is also used in class <em>header_version</em> which is used to read/write the archive header/trailer at the beginning and
	  at the end of the backup. The use of the class <em>slice_layout</em> in that structure is only present for isolated catalogues and contains
	  the slicing information of the archive of reference. The class <em>header_version</em> relies on the <em>slice_layout::read()</em>
	  and <em>slice_layout::write()</em> methods to read and write those fields to/from an archive's trailer/header.
	  Here, this information is needed for the <b>-Tslice</b> option to work when applied to an isolated catalogue.
	</p>
	<p>
	  <b>The isolation process:</b> At the end of archive creation, either read from filesystem (normal isolation) or just written to
	  filesystem (on-fly isolation), the field <em>archive::i_archive::slices</em> holds the slice layout of the current archive. It has been
	  read for the <em>sar</em> layer if the archive is sliced or is set to a default value if there is no <em>sar</em> layer and thus no slicing.
	  The isolation process is defined in <em>archive::i_archive::op_isolate()</em>: it transmits the <em>slices</em> information to
	  <em>macro_tools_create_layers()</em> which, in particular, uses it to setup the <em>header_version</em>. Once the layers are built
	  by this routine, this <em>header_version</em> structure is written at the beginning of the archive (version header).
	  After the catalogue has been written to these layers, <em>op_isolate()</em> calls <em>macro_tools_close_layers()</em> giving it
	  this same generated <em>header_version</em> (containing the slice_layout of the current archive, which will be the reference for the isolated
	  catalogue under construction), for it be written at the end of the archive (this is then the "version trailer").
	</p>

	<h4>The data</h4>

	<p>
          <b>The data</b> is a suite of file contents, with EA and FSA if
          present. When tape mark is used, a copy of the CRC is placed
          after's file Data and file's EA, to be used when reading the
          archive in sequential mode. This CRC is also dropped into the
          catalogue which takes place at the end of the archive to be used
          when reading the archive in direct access mode (the default).
          Last when delta binary is used, a file signature may follow the
          file's data:
	</p>

	<code class=block>
	  &nbsp;....--+---------------------+-------+----+----+------------+------------+----+-----------+-----+-....
	  &nbsp;      |  file1 data         | delta | EA | FSA| file2 data | file3 data | EA | file4     | FSA |
	  &nbsp;      | (may be compressed) | sig   |    |    |(no EA/FSA) |            |    | delta sig |     |
	  &nbsp;....--+---------------------+-------+----+----+------------+------------+----+-----------+-----+-....
	</code>

	<p>
          In the previous archive example,
          we find:
	</p>
	<ul>
          <li>
	    for file1: his data, a delta signature of this data,
            Extended Attributes, and File Specific Attributes
	  </li>
          <li>
	    for file2: only his data, he has no delta signature, no
            EA no FSA
	  </li>
          <li>
	    for file3: data and EA
	  </li>
          <li>
	    for file4: no data, only a delta signature and FSA
	  </li>
	</ul>

	<p>
          file1 shows all fields that can be associated with an inode,
          but none is mandatory, though if present they always follow
          this order:
	</p>
	<ul>
          <li><b>Data</b> or <b>delta patch</b></li>
          <li>followed by data/delta patch CRC when tape marks are set</li>
          <li><b>Delta signature</b></li>
          <li>followed by delta signature CRC when tape marks are set</li>
          <li><b>Extended Attributes</b></li>
          <li>followed by EA CRC when tape maks are set</li>
          <li><b>File Specific Attributes</b></li>
          <li>followed by FSA CRC when tape marks are set</li>
	</ul>

	<p>
	  when tape marks are not set, the CRC listed above are not present
	  inline in the archive, though they are still stored in the <i>catalogue</i>
	  at the end of the archive (see below)
	</p>

	<p>
          More precisely about <b>delta signature</b>
	  combined with tape marks, there is
          additional fields present than just the delta sig and its CRC:
	</p>

	<code class=block>
	  +------+------+------+---------------+----------+--------+
	  | base | sig  | sig  | sig data      | data CRC | result |
	  | CRC  | size | block| (if size > 0) |    if    |  CRC   |
	  | (*)  |      | len  |               | size > 0 |        |
	  +------+------+------+---------------+----------+--------+
	</code>

	<ul>
          <li>
	    <b>base CRC</b> is the
            CRC of the file that delta signature has been based on,
            used at restoration time before applying a patch
	    <br>
	    <dl>
	      <dt class>(*)</dt><dd>
		Since format 11.2 (release 2.7.9) this field has been moved
		with the inode information in the catalogue as well as inlined
		along the backup following seqt_file (tape) mark. This CRC
		is only present if the data for a file contains a binary patch.
	      </dd>
	    </dl>

	  </li>
          <li>
	    <b>sig size</b> gives
            the size of the next two fields (sig block len exists only
	    since archive format 10,1). This may be zero if the file
            does not has signature associated but the file's data is a
            delta patch and thus the base and the result CRCs are needed.
	    When sig size is zero, neither "sig block len" nor "sig data"
	    fields are present.
          </li>
	  <li>
	    <b>sig block len</b>
	    since format 10,1 the block size used for signature calculation
	    is variable (it was fixed to 2048 bytes before) depending on the
	    file size under consideration.
	  </li>
          <li>
	    <b>sig data</b> is the
            delta signature data. This field and the following are the
            only one present outside the ending catalogue about delta
            signatures when tape marks are not set.
          </li>
          <li>
	    <b>data CRC</b> is the
            CRC on the previous "sig block len" + "sig data" fields.
          </li>
          <li>
	    <b>result CRC</b> is
            the CRC of the resulting file once patched (to check
            the patching was successful)
	  </li>
	</ul>

	<h4>The catalogue</h4>

	<p>
          <b>the catalogue</b>, contains all inode, directory structure and
          hard_links information as well as data and EA CRC. The directory
          structure is stored in a simple way: the inode of a directory
          comes, then the inode of the files it contains, then a special
          entry named "EOD" for End of Directory. Considering the
          following tree:
	</p>

	<code class=block>
	  &nbsp;- toto
	  &nbsp;   | titi
	  &nbsp;   | tutu
	  &nbsp;   | tata
	  &nbsp;   |   | blup
	  &nbsp;   |   +--
	  &nbsp;   | boum
	  &nbsp;   | coucou
	  &nbsp;   +---
	</code>

	<p>
	  it would generate the following sequence for catalogue storage:
	</p>
	<code class=block>
	  +-------+------+------+------+------+-----+------+--------+-----+
	  |  toto | titi | tutu | tata | blup | EOD | boum | coucou | EOD |
	  |       |      |      |      |      |     |      |        |     |
	  +-------+------+------+------+------+-----+------+--------+-----+
	</code>

	<p>
          the <i>EOD</i> entries take on byte. Doing this way, there is
	  no need to store the full path
          of each file, just the filename is recorded. The file order and the
	  EOD can be used to find the relative path of each entry.
	</p>

	<p>
	  To be complete, the previous sequence is preceeded by:
	</p>
	<ul>
	  <li>
	    the <b>data_name</b> as describe above,
	  </li>
	  <li>
	    the <b>in-place path</b> which is the root path (-R option) used at backup time that can be used
	    at restoration time by mean of -ap option in place of any -R option.
	  </li>
	</ul>
	<p>
	  This sequence is then followed by a CRC calculated on the whole
	  catalogue dumped data:
	</p>

	<code class=block>
	  +------------+----------+------------------------------------+-----+
	  |  data_name | in_place |<--------catalogue content--------->| CRC |
	  |            |          | toto|titi|tata|blup|EOD|boum|...   |     |
	  +------------+----------+------------------------------------+-----+
	</code>

	  <h4>The terminator</h4>
	<p>
	  <b>the terminator</b> stores the position of the beginning of the
          catalogue, it is the last thing to be written. Thus dar first
          reads the terminator, then the catalogue. Well, there is now two
          terminators, both are meant to be read backward. The second
          terminator points to the beginning of the "trailer version"
          which is read first in direct access mode. The first terminator
          points to the start of the catalogue, which is read once the
          adhoc compression and encryption layers has been built based on
          the information found on the "trailer version"
	</p>

	<h3>All Together</h3>
	<p>
	  Here is an example of how data can be structured in a
	  four sliced archive:
	</p>
	<code class=block>
	  +--------+--------+------------------------+--+
	  | slice  | version|  file data + EA        |Tr|
	  | header | header |                        |  |
	  +--------+--------+------------------------+--+
	</code>
	<p>
          the first slice (just above) has been defined smaller using the
          -S option
	</p>
	<code class=block>
	  +--------+-----------------------------------------------------------------+--+
	  | slice  |           file data + EA                                        |Tr|
	  | header |                                                                 |  |
	  +--------+-----------------------------------------------------------------+--+

	  +--------+-----------------------------------------------------------------+--+
	  | slice  |           file data + EA                                        |Tr|
	  | header |                                                                 |  |
	  +--------+-----------------------------------------------------------------+--+

	  +--------+---------------------+-----------+------ +---------+--------+--+
	  | slice  |   file data + EA    | catalogue | term 1| version | term 2 |Tr|
	  | header |                     |           |       | trailer |        |  |
	  +--------+---------------------+-----------+-------+---------+--------+--+
	</code>

	<p>
	  the last slice is smaller because there was not enough data to make it
          full.
	</p>

	<h3>Other Levels</h3>

	<p>
	  Things get a bit more complicated if we consider compression and encryption.
          The way the problem is addressed in dar's code is a bit like
          networks are designed in computer science, using the notion of
	  <b>layers</b>.
	</p>
	<p>
	  Here, there
          is a additional constraint, a given layer may or may not be
          present (encryption, compression, slicing for example). So all
          layer must have the same interface for serving the layer above
          them.
	</p>

	<p>
	  This interface is defined by the pure virtual class name
          <i>generic_file</i>, which provides generic methods for reading,
          writing, skipping, getting the current offset when writing or
          reading data to any layer. Here follows some example of implementation:
	</p>

	<ul>
	  <li>
	    <p>
	      For example the <b>compressor</b> class
              acts as a file which compresses data wrote to it and writes
              compressed data to another <i>generic_file</i> below it.
	    </p>
	  </li>
	  <li>
	    <p>
	      The <b>strong encryption</b> and <b>scramble</b> classes
	      act the same but in place of
              compressing/uncompressing they encrypt/decrypt the data to/from
              another generic_file object "below" them.
	    </p>
	  </li>
	  <li>
	    <p>
	      The <b>sar</b> class which <b>s</b>egment <b>a</b>nd
	      <b>r</b>eassmbles (perfoming thus the slicing)
              follows the same principle:
              it transfers data wrote to it to several fichier
	      [mening <i>file</i> in French] objects.
	    </p>
	  </li>
	  <li>
	    <p>
              Class <b>fichier</b> also inherit from <i>generic_file</i> class,
	      and is just a wrapper for the plain file system calls.
	    </p>
	  </li>
	  <li>
	    <p>
	      Some new classes
              have been added with format 8, in particular the <b>escape</b> class,
              which inserts escape sequence mark at requested position, and
              modifies data wrote for it never looks like an escape sequence
              mark. To reduce the level of context switch when reading the
              catalogue (which makes a ton of small read)
	    </p>
	  </li>
	  <li>
	    <p>
	      a <b>cache</b> class is also present, it gather small writes made
	      to it into larger writes, and pre-reads a large amount of data
	      to answer to the many small reads when building the catalogue
	      in memory from the archive.
	    </p>
	  </li>
	  <li>
	    <p>
	      <b>fichier_libcurl</b> is acts like the class <i>fichier</i>
	      but as it relies on <i>libcurl</i> it let libdar read and write
	      files to remote repository (using SFTP or FTP as of today).
	    </p>
	  </li>
	  <li>
	    <p>
	      class <b>generic_rsync</b> computes the delta signature, or patch a file
	      using <i>librsync</i>
	    </p>
	  </li>
	  <li>
	    <p>
	      class <b>hash_fichier</b> computes a hash (md5, sha1, sh512,...) of the
	      data it is written to before transmitting it unchanged to the layer below it
	    </p>
	  </li>
	  <li>
	    <p>
	      class <b>memory_file</b> is used to store data in memory.
	      <b>secu_memory_file</b> does the same but in secured memory (relying on
	      <i>libgcrypt</i>. It is used to store sensible data like keys and passwords
	    </p>
	  </li>
	  <li>
	    <p>
	      class <b>null_file</b> acts as the well known <code>/dev/null</code> block
	      device of Unix system (drops all what is written to it and reads not data, like
	      an empty file)
	    </p>
	  </li>
	  <li>
	    <p>
	      class <b>spares_file</b> replaces long sequence of zeroed bytes by a special
	      and small structure (a hole) the contains the number of replaced zeroed bytes
	      when you write data to it. The resulting is transmitted to the underlying layer.
	      At reading time, depending on its mode of operation,  it fetches data from
	      the underlying data and either reconstructs the hole on the filesystem
	      (skipping the write cursor after the hole) or replaces the read <i> hole</i>
	      structure by the zeroed bytes it was replacing.
	    </p>
	  </li>
	</ul>
	<p>
          Here are below is an example of possible layer stacking libdar is using to address a particular combinaison of commands and options:
	</p>

	<code class=block>

	  &nbsp;              +----+--+----+-................+---------+
	  &nbsp;archive       |file|EA|file|                 |catalogue|
	  &nbsp;layout        |data|  |data|                 |         |
	  &nbsp;              +----+--+----+-................+---------+
	  &nbsp;                |   |    |      |              |
	  &nbsp;            +-----+ | +-------+ |              |
	  &nbsp;sparse      |spars| | |sparse | |              |
	  &nbsp;file        |file | | |file   | |              |
	  &nbsp;detection   |detec| | |detect.| |              |
	  &nbsp;layer       +-----+ | +-------+ |              |
	  &nbsp;(optional)      |   |    |      |              |
	  &nbsp;                |   |    |      |              |
  	  &nbsp;            +-----+ |    |   +-----+           |
	  &nbsp;            |delta| |    |   |delta|           |
	  &nbsp;            |sig  | |    |   |sig  |           |
	  &nbsp;            +-----+ |    |   +-----+           |
	  &nbsp;                |   |    |      |              |
	  &nbsp;                |   |    |      |              |
	  &nbsp;                V   V    V      V              V
	  &nbsp;              +-----------------------------------------+
	  &nbsp;compression   |         (compressed)  data              |
	  &nbsp;              +-----------------------------------------+
  	  &nbsp;                     |                      |
	  &nbsp;                     |                      |
	  &nbsp;                     V                      V
	  &nbsp;              +-----------------------------------------+
	  &nbsp;escape layer  |   escaped data / escape sequences       |
	  &nbsp;(optional)    +-----------------------------------------+
	  &nbsp;                    |                      |                 / First Terminateur
	  &nbsp;                    |                      |                 |
	  &nbsp;                    |                      |                 V
	  &nbsp;elastic  +---+      |                      |              +----+---+
	  &nbsp;buffers  |EEE|      |                      |              | T1 |EEE|
	  &nbsp;         +---+      |                      |              +----+---+
	  &nbsp;           |        |                      |                    |           Second
	  &nbsp;           V        V                      V                    V         Terminator
	  &nbsp;         +---------------------------------------------------------+            |
	  &nbsp;cipher   |        (encrypted) data / cache if no encryption        |            |
	  &nbsp;         +---------------------------------------------------------+            V
	  &nbsp;                    |                         |                     +---------+----+
	  &nbsp;+-------+           |                         |                     | trailer | T2 |
	  &nbsp;| header|           |                         |                     +---------+----+
	  &nbsp;+-------+           |                         |                          |      |
	  &nbsp;    |               |                         |                          |      |
	  &nbsp;    V               V                         V                          V      v
	  &nbsp;+----------------------------------------------------------------------------------+
	  &nbsp;|                  data                                                            |
	  &nbsp;+----------------------------------------------------------------------------------+
	  &nbsp;        |         |  |         |   |        |   |        |  |        |  |        |
	  &nbsp;+---------+  +---------+  +---------+  +---------+  +---------+  +---------+  +----+
	  &nbsp;|hash_file|  |hash_file|  |hash_file|  |hash_file|  |hash_file|  |hash_file|  |hash|
	  &nbsp;+---------+  +---------+  +---------+  +---------+  +---------+  +---------+  +----+
	  &nbsp;        |        (hash_file are optional)   |   |        |  |        |  |        |
	  &nbsp;slice   |         |  |         |   |        |   |        |  |        |  |        |
	  &nbsp;headers |         |  |         |   |        |   |        |  |        |  |        |
	  &nbsp; |  |   |         |  |         |   |        |   |        |  |        |  |        |
	  &nbsp; |  +---|------\  |  |         |   |        |   |        |  |        |  |        |
	  &nbsp; |      |      |  |  |         |   |        |   |        |  |        |  |        |
	  &nbsp; V      V      V  V  V         V   V        V   V        V  V        V  V        V
	  &nbsp;+---------+  +---------+  +---------+  +---------+  +---------+  +---------+  +----+
	  &nbsp;|HH| data |  |HH| data |  |HH| data |  |HH| data |  |HH| data |  |HH| data |  |HH| |
	  &nbsp;+---------+  +---------+  +---------+  +---------+  +---------+  +---------+  +----+
	  &nbsp; slice 1      slice 2      slice 3      slice 4       slice 5      slice 6    slice 7
	</code>

	<p>
          The <b>elastic buffers</b> are here to prevent plain text attack, where
          one knows which data is expected at a given place, an trying
          to guess the cipher comparing the expected data and the
          encrypted one. As dar generates structured archives, there
          would have some possibility that one use this attack to crack
          an archive encryption. To overcome this problem, elastic
          buffers have been added at the beginning and at the end of
          encrypted data. This way it is not possible to know where is
          located a given archive structure within the encrypted data.
          The elastic buffers are random data that contain at a random
          place a pattern that tells the overall size of the buffer
          (which size is randomly chosen during archive creation). The
          pattern is of the form "&gt;###&lt;" where the hash field
          (###) contains the elastic buffer size in binary. Small
          elastic buffer can be "&gt;&lt;" for two bytes or "X" for one
          byte, but as it is encrypted beside archive data, it is not
          possible to determine its size for one that does not hold the
          archive encryption key. Elastic buffer are usually several
          kilobyte long. Here follows an example of elastic buffer:
	</p>

	<code class=block>
	  972037219&gt;20&lt;8172839
	</code>

	<p>
	  For clarity,
	  the size field between '&gt;' and '&lt;' has been written in
	  decimal instead of binary, as well as the random data inside the
	  elastic buffer. The location of the size field '&gt;20&lt;' is
	  also randomly chosen at creation time.
	</p>

	<p>
	  <b>Teminateur</b>
	  is short structure that is intended to be read backward. It
	  gives the absolute position of a given item within the archive:
	  The second terminateur let dar skip at the beginning of the
	  archive trailer. The first terminateur (eventually encrypted)
	  let dar skip at the beginning of the catalogue).
	</p>

	<h2><a name="overflow">Overflow in arithmetic integer operations</a></h2>

	<p>
	  Some code explanation about the
          detection of integer arithmetic operation overflows. We speak
          about *unsigned* integers, and we have only portable standard
          ways to detect overflows when using 32 bits or 64 bits integer
          in place of infinint.
	</p>
	<p>
          Written in binary notation, a number is a finite suite of digits (0 or
          1). To obtain the original number from its binary
          representation, we must multiply each digit by successive powers of two.
          Example the binary representation "101101" designs the number N
          where:
	  <code class=block>
            N = 2^5 + 2^3 + 2^2 + 2^0
	  </code>
	<p>
          In that context we will say that 5 is the maximum power of N
          (the power of the higher non null binary digit).
	</p>
	<p>
          For the addition operation ("+"), if an overflow occurs, the result
          is less than one or both operands, so overflow is not difficult to
          detect. To convince you, let's assume that the result is greater
          than both operands while it has overflowed. Thus the real result
          (without overflow) less the first operands should gives the second
          argument, but here we get a value that is greater than the all 1
          bits integer (because there was an overflow and the resulting
          overflowed value is greater than the second and the first
          operand), so this is absurd, and in case of overflow the resulting
          value is less than one of the operands.
	</p>
	<p>
          For substraction operation ("-"), if the second operand is greater
          than the first there will be an overflow (result must be
          unsigned thus positive) else there will not be any overflow.
          Thus detection is even more simple.
	</p>
	<p>
          for division ("/") and modulo ("%") operations, there is never an
          overflow (there is just the illicit division by zero).
	</p>
	<p>
          for multiplication operation ("*"), a heuristic has been chosen to
          quickly detect overflow, the drawback is that it may triggers
          false overflow when number get near the maximum possible integer
          value. Here is the heuristic used:
	</p>
	<p>
          given A and B two integers, which max powers are m and n
          respectively, we have:
	</p>
	<code class=block>
	  A &lt; 2^(m+1)
	</code>
	<p>
          and
	</p>
	<code class=block>
          B &lt; 2^(n+1)
	</code>
	<p>
          thus we also have:
	</p>
	<code class=block>
          A.B &lt; 2^(m+1).2^(n+1)
	</code>
	<p>
          which is:
	</p>
	<code class=block>
          A.B &lt; 2^(m+n+2)
	</code>
	<p>
          In consequences we know that the maximum power of the product of A
          by B is at most m+n+1 and while m+n+1 is less than or equal to the
          maximum power of the integer field there will not be overflow else
          we consider there will be an overflow even if it may not be always
          the case (this is an heuristic algorithm).
	</p>

	<h2><a name="thread_safe">libdar and thread-safe requirement</a></h2>

	<p>
          The following should only concern those who plan to
          use libdar in their own programs.
	</p>

	<p>
          If expect to only have one thread using libdar, there is no
          problem, of course, you will however have to call one of the
          get_version() first, as usual. Thing change if you intend to
          have several concurrent threads using libdar library in a
	  same process.
	</p>
	<p>
          libdar is thread-safe but you need to respect certain conditions:
	</p>
	<p>
          Thread-save support must have been activated at libdar compilation time.
	  Several 'configure' options have an impact this thread-safe support:
	</p>
	<dl>
	  <dt class=void>--enable-test-memory</dt><dd>
	    is a <u>debug option</u> that avoid libdar to be
            thread-safe, so don't use it unless debugging non thread relative
	    behaviors.
	  </dd>
	  <dt class=void>--disable-thread-safe</dt><dd>
	    this disable thread safe support in libdar, it may be used for
	    debugging purposes or to marginally speed up the libdar execution
	  </dd>
	</dl>

	<p>
	  If you want to rely in multi-thread support in libdar, a good practice
	  is to check that a call to <code>libdar::compile_time::thread_safe()</code>
	  returns <code>true</code>. If not your program should behave accordingly
	  either abort with an error or have all libdar interaction done in a single
	  thread at a time.
	</p>

	<dl>
	  <dt class=void>IMPORTANT</dt><dd>
            It is vital to to call one of the
	    <code>get_version(...)</code> as first call to <i>libdar</i> and wait for its return
	    before assuming multi-thread support is ready for use.
	  </dd>
	</dl>

	<p>
          For more information about libdar and its API, check the <a href="api_tutorial.html">doc/api_tutorial.html</a>
          document and the API reference manual under <a href="man/index.html">doc/html/index.html</a>
	</p>


	<h2><a name="NLS">Native Language Support</a></h2>

	<p>
	  Native Language Support (NLS) is
          the ability a given program has to display its messages in different
          languages. For dar, this is implemented using the <b>gettext</b> tools.
          This tool must be installed on the system for dar can be able to
          display messages in another language than English (some would
	  joke telling that this is more Frenglish than good old English, they might
	  be right, so feel free to report any too Frenchy syntax, spelling or grammar)
	</p>
	<p>
	  The dar behavior is the following:
	</p>
	<ul>
	  <li>
            On a system without gettext dar will not use gettext at all.
            All messages will be in English
	  </li>
	  <li>
            On a system with gettext dar will use the system's gettext,
            unless you use <code>--disable-nls</code> option with the configure script.
	  </li>
	</ul>

	<p>
          If NLS is available you just have to set the <code>LANG</code> environment
          variable to your locale settings to change the language in which
          dar displays its messages (see ABOUT-NLS for more about the LANG
          variable).
	</p>
	<p>
          Just for information, gettext() is the name of the call that
          makes translations of string in the program. This call is
          implemented in the library called 'libintl' (intl for
          Internationalization).
	</p>
	<p>
          Refer to the ABOUT-NLS file at the root of the source package to
          learn more about the way to display dar's messages in your own
          language. Note that not all languages are yet supported, this is
          up to you to send me a translation in your language and/or
          contact a translating team as explained in ABOUT-NLS.
	</p>
	<p>
          To know which languages are supported by dar, read the
          po/LINGUAS file and check out for the presence of the
          corresponding *.po files in this directory.
	</p>

	<h2><a name="Dar_relase_Process_in_brief"></a>Dar Release Process</h2>

	<h3>General view</h3>
	<p>
	  Dar does not follow the <i>so called modern continuous development</i> also known
	  as <i>agile</i>. First <i>dar</i> is not a devops code while it can be used
	  <b>for devops</b>. <i>dar</i> is rather a (free) product outside
	  any particuar customer specific context. Second keeping the good old
	  development process separating development from quality engineering in different
	  phases over time brings the expected robustness a backup tool must have.
	</p>
	<p>
	  This separation takes the form of branches of a tree where the <b>trunk</b> is
	  the development code, which grows when receiving new features, and the <b>branches</b>
	  carry the so called <i>releases</i>. Several releases can be found on a
	  given branch but branches only receive bug fixes between two releases.
	</p>
	<p>
	  Several branches may be active at a time, leading to several concurrent releases
	  (for examples releases 2.5.22 and 2.6.5 have the same date).
	</p>
	<p>
	  Last all bug fixes from an older and active branch are merged into the more recent branches
	  up to the trunk, which is the development code. But the modification of code in
	  branches is kept as minimal as possible.
	</p>

	<h3>Phasing</h3>
	<h4>Development Phase:</h4>
	<p>
          During that phase, dar receives new features. At this
          stage sources are modified and tested unitary after each feature addition. These
	  modifications and additions take place on the <i>trunk</i>.
	</p>

	<h4>Frozen API Phase:</h4>
	<p>
	  At this stage, no new feature that would change the API are added.
	  The API shall be documented enough to let API users give their feedback about
          the design and its implementation.
	</p>
	<p>
	  During this time, development may continue, whatever is necessary while it does not changes the
          API, like documentation of the whole project, problem fixes in
          libdar, new features in command-line part of the source, and so
          on. A set of non regression test is also updated and run to check that new features
	  works as expected with old ones and old ones still work fine toghether.
	</p>

	<h4>Pre-release Phase:</h4>
	<p>
	  This phase is announced on <a href="https://sourceforge.net/projects/dar/lists/dar-news">dar-news mailing-list</a>
	  which you can subscribe to also be informed about new releases, security issues, and other major problems.
	</p>
	<p>
	  The goal of this phrase is to let anyone test the release candidate in their own
	  environment and report any code building problem and any bug met to the
	  <a href="http://lists.sourceforge.net/lists/listinfo/dar-pre-release">pre-release mailing-list</a>.
	</p>
	<p>
	  Usually this code is on the trunk (the <i>master</i> in GIT)
	  but <a href="http://dar.linux.free.fr/pre-release/">pre-built packages</a> are also provided daily for testing.
	</p>

	<h4>Release Phase:</h4>
	<p>
          When the pre-release ends, the first official release is provided
          (its last number version is zero like for release 2.7.0). It is available
	  broadly by mean of
	  <a href="http://sourceforge.net/project/showfiles.php?group_id=65612">sourceforge mirrors</a>.
	</p>
	<p>
	  A new branch (like branch_2.7.x) is created to hold the released code, and will receive
	  any further releases by mean of bug fixes (releases 2.7.1, releases 2.7.2,...).
	</p>
	<p>
	  As for any new release, an email is sent with the list of Changes to
          the dar-news mailing-list. During that phase, users are welcome to report
          bugs/problem either first asking for support on the dar-support mailing-list
	  or openning a <a href="http://dar.linux.free.fr/feedback.html">bug report</a>.
	</p>

	<h4>Interim Releases:</h4>
	<p>
	  This type of release is fast to setup and will later become an official release. Doing so
	  saves time to update the website, time to generate the windows binaries, time to push
	  data to the sourceforge mirror update, and so on. Interim releases
	  are provided for validating bug fixes, and are setup from the latest code of a branch.
	  They are usually named after the future release they will produce suffixed by RC#
	  (for <b>R</b>elease <b>C</b>andidate).
	  For example, we got version <i>2.6.6.RC2</i> in the past. Note that interim releases
	  are deleted once the official release is done (release 2.6.6 in our example).
	</p>

	<h3><a name="Dar_version_naming"></a>Dar's Version<u>s</u></h3>

	<h4>package release version</h4>
	<p>
	  Dar packages are release during
          the pre-release phase
	  (<a href="#Dar_relase_Process_in_brief">see above</a>).
	  Each version is identified by three number separated
	  by dot like for example, version 2.3.0:
	</p>
	<ul>
	  <li>
	    <b>The last number</b> is
            incremented between releases that take place in the same release
            phase (keeping trace of bug fixes),
	  </li>
	  <li>
	    <b>the middle number</b> increments at
            each pre-release phase and designate a branch.
	  </li>
	  <li>
	    <b>the first number</b> is incremented when
            a major change in the software structure takes place, like for
	    version 2.0.0 which has seen the monolithic <i>dar</i> software
	    being split in two:  the <i>libdar</i> and its API on one side and
	    on the other side <i>dar</i> reduced to translating
	    between command-line and the API
	  </li>
	</ul>
	<p>
          Note that release versionning is completely different from what is
          done for the Linux kernel, here for dar all versionnized packages
          are stable released software and thus stability increases with the
          last number of the version.
	</p>

	<h4>Libdar version</h4>
	<p>
	  Unfortunately, the release version
          does not give much information about the compatibility of
          different libdar version, from the point of view of an external
          application, that thus has not been released with libdar and may
          be faced to different libdar versions. So, libdar has its own
          version. It is also a three number version, (for example,
          libdar version 6.2.7), but each number has a different
          meaning:
	</p>
	<ul>
	  <li>
	    <b>The last number</b> increases with a new version that only
	    fixes bugs (same meaning as package versioning)
	  </li>
	  <li>
	    <b>the middle number increases</b> with when new features has
            been added but older features can be used the same (a software that
	    relied on the previous middle number should still work with a more
	    recent one)
	  </li>
	  <li>
	    <b>the first number</b> changes when the API had to be modified
	    in a way that the use of old feature has changed
	  </li>
	</ul>

	<h4>Other versions</h4>
	<p>
          Beside the libdar library, you can find several command-line
          applications: dar, dar_xform, dar_slave, dar_manager, dar_cp and dar_split.
          These have their own version which is, here too, made of
          three numbers. Their meaning is the same as the meaning for the
          package release version: The last number increases upon bug fix,
          the middle upon new feature, the first upon major architecture
          changes.
	</p>

	<h4>Archive format version</h4>
	<p>
	  When new features come, it is sometime necessary to change the
	  structure of the archive. To be able to know the format used in
	  the archive, a field is present in each archive that defines this
	  format.
	</p>

	<p>
	  Currently the archive format version is <i>11</i> meaning there is
	  around 11 different version of dar archive format, plus the version
	  increment that were needed to fix a bug (like version 8.1 and 10.1), but
	  <i>dar</i> and <i>libdar</i> have been developped to be able to read
	  them all (all those that existed when the version was released).
	</p>

	<h4>Cross reference matrix</h4>
	<p>
	  OK, you may now find that this is
          a bit complex so a list of version is give below. Just remember
          that there are two points of view: The command-line user and the
          external application developer.
	</p>

	<div class=table>
	  <table class=center>
            <tr>
              <th style="min-width:200px">Date</th>
              <th>release (and dar version)</th>
              <th>Archive format</th>
              <th>Database Format</th>
              <th>libdar version</th>
              <th>dar_xform</th>
              <th>dar_slave</th>
              <th>dar_manager</th>
              <th>dar_cp</th>
              <th>dar_split</th>
            </tr>
            <tr>
              <td>April 2nd, 2002</td>
              <th>1.0.0</th>
              <td>01</td>
              <td>----- </td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>April 24th, 2002</td>
              <th>1.0.1</th>
              <td>01</td>
              <td>----- </td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>May 8th, 2002</td>
              <th>1.0.2</th>
              <td>01</td>
              <td>----- </td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>May 27th, 2002</td>
              <th>1.0.3</th>
              <td>01</td>
              <td>----- </td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 26th, 2002</td>
              <th>1.1.0</th>
              <td>02</td>
              <td>----- </td>
              <td>-----</td>
              <td>1.0.0</td>
              <td>1.0.0</td>
              <td>-----</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Nov. 4th, 2002</td>
              <th>1.2.0</th>
              <td>03</td>
              <td>01 </td>
              <td>-----</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.0.0</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Jan. 10th, 2003</td>
              <th>1.2.1</th>
              <td>03</td>
              <td>01 </td>
              <td>-----</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.0.0</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>May 19th, 2003</td>
              <th>1.3.0</th>
              <td>03</td>
              <td>01 </td>
              <td>-----</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>-----</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Nov. 2nd, 2003</td>
              <th>2.0.0</th>
              <td>03</td>
              <td>01 </td>
              <td>1.0.0</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.2.0</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Nov. 21th, 2003</td>
              <th>2.0.1</th>
              <td>03</td>
              <td>01 </td>
              <td>1.0.1</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.2.0</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Dec. 7th, 2003</td>
              <th>2.0.2</th>
              <td>03</td>
              <td>01 </td>
              <td>1.0.2</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.2.0</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Dec. 14th, 2003</td>
              <th>2.0.3</th>
              <td>03</td>
              <td>01 </td>
              <td>1.0.2</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.2.1</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Jan. 3rd, 2004</td>
              <th>2.0.4</th>
              <td>03</td>
              <td>01 </td>
              <td>1.0.2</td>
              <td>1.1.0</td>
              <td>1.1.0</td>
              <td>1.2.1</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Feb. 8th, 2004</td>
              <th>2.1.0</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.0</td>
              <td>1.2.0</td>
              <td>1.2.0</td>
              <td>1.2.1</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>March 5th, 2004</td>
              <th>2.1.1</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.1</td>
              <td>1.2.1</td>
              <td>1.2.1</td>
              <td>1.2.2</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>March 12th, 2004</td>
              <th>2.1.2</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.2</td>
              <td>1.2.1</td>
              <td>1.2.1</td>
              <td>1.2.2</td>
              <td>1.0.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>May 6th, 2004</td>
              <th>2.1.3</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.3</td>
              <td>1.2.1</td>
              <td>1.2.1</td>
              <td>1.2.2</td>
              <td>1.0.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>July 13th, 2004</td>
              <th>2.1.4</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.4</td>
              <td>1.2.1</td>
              <td>1.2.1</td>
              <td>1.2.2</td>
              <td>1.0.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Sept. 12th, 2004</td>
              <th>2.1.5</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.5</td>
              <td>1.2.1</td>
              <td>1.2.1</td>
              <td>1.2.2</td>
              <td>1.0.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Jan. 29th, 2005</td>
              <th>2.1.6</th>
              <td>03</td>
              <td>01 </td>
              <td>2.0.5</td>
              <td>1.2.1</td>
              <td>1.2.1</td>
              <td>1.2.2</td>
              <td>1.0.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Jan. 30th, 2005</td>
              <th>2.2.0</th>
              <td>04</td>
              <td>01 </td>
              <td>3.0.0</td>
              <td>1.3.0</td>
              <td>1.3.0</td>
              <td>1.3.0</td>
              <td>1.0.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Feb. 20th, 2005</td>
              <th>2.2.1</th>
              <td>04</td>
              <td>01 </td>
              <td>3.0.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>May 12th, 2005</td>
              <th>2.2.2</th>
              <td>04</td>
              <td>01 </td>
              <td>3.0.2</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Sept. 13th, 2005</td>
              <th>2.2.3</th>
              <td>04</td>
              <td>01 </td>
              <td>3.1.0</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Nov. 5th, 2005</td>
              <th>2.2.4</th>
              <td>04</td>
              <td>01 </td>
              <td>3.1.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Dec. 6th, 2005</td>
              <th>2.2.5</th>
              <td>04</td>
              <td>01 </td>
              <td>3.1.2</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Jan. 19th, 2006</td>
              <th>2.2.6</th>
              <td>04</td>
              <td>01 </td>
              <td>3.1.3</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Feb. 24th, 2006</td>
              <th>2.2.7</th>
              <td>04</td>
              <td>01 </td>
              <td>3.1.4</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.3.1</td>
              <td>1.0.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Feb. 24th, 2006</td>
              <th>2.3.0</th>
              <td>05</td>
              <td>01 </td>
              <td>4.0.0</td>
              <td>1.4.0</td>
              <td>1.3.2</td>
              <td>1.4.0</td>
              <td>1.1.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 26th, 2006</td>
              <th>2.3.1</th>
              <td>05</td>
              <td>01 </td>
              <td>4.0.1</td>
              <td>1.4.0</td>
              <td>1.3.2</td>
              <td>1.4.0</td>
              <td>1.1.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Oct. 30th, 2006</td>
              <th>2.3.2</th>
              <td>05</td>
              <td>01 </td>
              <td>4.0.2</td>
              <td>1.4.0</td>
              <td>1.3.2</td>
              <td>1.4.0</td>
              <td>1.1.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Feb. 24th, 2007</td>
              <th>2.3.3</th>
              <td>05</td>
              <td>01 </td>
              <td>4.1.0</td>
              <td>1.4.0</td>
              <td>1.3.2</td>
              <td>1.4.1</td>
              <td>1.2.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 30th, 2007</td>
              <th>2.3.4</th>
              <td>06</td>
              <td>01 </td>
              <td>4.3.0</td>
              <td>1.4.0</td>
              <td>1.3.2</td>
              <td>1.4.1</td>
              <td>1.2.0</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Aug. 28th, 2007</td>
              <th>2.3.5</th>
              <td>06</td>
              <td>01 </td>
              <td>4.4.0</td>
              <td>1.4.1</td>
              <td>1.3.3</td>
              <td>1.4.2</td>
              <td>1.2.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Sept. 29th, 2007</td>
              <th>2.3.6</th>
              <td>06</td>
              <td>01 </td>
              <td>4.4.1</td>
              <td>1.4.1</td>
              <td>1.3.3</td>
              <td>1.4.2</td>
              <td>1.2.1</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Feb. 10th, 2008</td>
              <th>2.3.7</th>
              <td>06</td>
              <td>01 </td>
              <td>4.4.2</td>
              <td>1.4.2</td>
              <td>1.3.4</td>
              <td>1.4.3</td>
              <td>1.2.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 20th, 2008</td>
              <th>2.3.8</th>
              <td>07</td>
              <td>01 </td>
              <td>4.4.3</td>
              <td>1.4.2</td>
              <td>1.3.4</td>
              <td>1.4.3</td>
              <td>1.2.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>May 22nd, 2009</td>
              <th>2.3.9</th>
              <td>07</td>
              <td>01 </td>
              <td>4.4.4</td>
              <td>1.4.2</td>
              <td>1.3.4</td>
              <td>1.4.3</td>
              <td>1.2.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>April 9th, 2010</td>
              <th>2.3.10</th>
              <td>07</td>
              <td>01 </td>
              <td>4.4.5</td>
              <td>1.4.2</td>
              <td>1.3.4</td>
              <td>1.4.3</td>
              <td>1.2.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>March 13th, 2011</td>
              <th>2.3.11 </th>
              <td>07 </td>
              <td>01 </td>
              <td>4.5.0 </td>
              <td>1.4.3 </td>
              <td>1.3.4 </td>
              <td>1.4.3 </td>
              <td>1.2.2 </td>
              <td>-----</td>
            </tr>
            <tr>
              <td>February 25th, 2012</td>
              <th>2.3.12</th>
              <td>07</td>
              <td>01</td>
              <td>4.5.1</td>
              <td>1.4.3</td>
              <td>1.3.4</td>
              <td>1.4.3</td>
              <td>1.2.2</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 2nd, 2011</td>
              <th>2.4.0</th>
              <td>08</td>
              <td>02</td>
              <td>5.0.0</td>
              <td>1.5.0</td>
              <td>1.4.0</td>
              <td>1.5.0</td>
              <td>1.2.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>July 21st, 2011</td>
              <th>2.4.1</th>
              <td>08</td>
              <td>02</td>
              <td>5.1.0</td>
              <td>1.5.0</td>
              <td>1.4.0</td>
              <td>1.6.0</td>
              <td>1.2.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Sept. 5th, 2011</td>
              <th>2.4.2</th>
              <td>08</td>
              <td>02</td>
              <td>5.1.1</td>
              <td>1.5.0</td>
              <td>1.4.0</td>
              <td>1.6.0</td>
              <td>1.2.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>February 25th, 2012</td>
              <th>2.4.3</th>
              <td>08</td>
              <td>03</td>
              <td>5.2.0</td>
              <td>1.5.0</td>
              <td>1.4.0</td>
              <td>1.7.0</td>
              <td>1.2.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>March 17th, 2012</td>
              <th>2.4.4</th>
              <td>08</td>
              <td>03</td>
              <td>5.2.1</td>
              <td>1.5.0</td>
              <td>1.4.0</td>
              <td>1.7.1</td>
              <td>1.2.3</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>April 15th, 2012</td>
              <th>2.4.5</th>
              <td>08</td>
              <td>03</td>
              <td>5.2.2</td>
              <td>1.5.1</td>
              <td>1.4.1</td>
              <td>1.7.2</td>
              <td>1.2.4</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 24th, 2012</td>
              <th>2.4.6</th>
              <td>08</td>
              <td>03</td>
              <td>5.2.3</td>
              <td>1.5.2</td>
              <td>1.4.2</td>
              <td>1.7.3</td>
              <td>1.2.5</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>July 5th, 2012</td>
              <th>2.4.7</th>
              <td>08</td>
              <td>03</td>
              <td>5.2.4</td>
              <td>1.5.2</td>
              <td>1.4.3</td>
              <td>1.7.3</td>
              <td>1.2.5</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>September 9th, 2012</td>
              <th>2.4.8</th>
              <td>08</td>
              <td>03</td>
              <td>5.3.0</td>
              <td>1.5.3</td>
              <td>1.4.4</td>
              <td>1.7.4</td>
              <td>1.2.6</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>January 6th, 2013</td>
              <th>2.4.9</th>
              <td>08</td>
              <td>03</td>
              <td>5.3.1</td>
              <td>1.5.3</td>
              <td>1.4.4</td>
              <td>1.7.4</td>
              <td>1.2.7</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>March 9th, 2013</td>
              <th>2.4.10</th>
              <td>08</td>
              <td>03</td>
              <td>5.3.2</td>
              <td>1.5.3</td>
              <td>1.4.4</td>
              <td>1.7.4</td>
              <td>1.2.7</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>Aug. 26th, 2013</td>
              <th>2.4.11</th>
              <td>08</td>
              <td>03</td>
              <td>5.4.0</td>
              <td>1.5.4</td>
              <td>1.4.5</td>
              <td>1.7.5</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>January 19th, 2014</td>
              <th>2.4.12</th>
              <td>08</td>
              <td>03</td>
              <td>5.5.0</td>
              <td>1.5.4</td>
              <td>1.4.5</td>
              <td>1.7.6</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>April 21st, 2014</td>
              <th>2.4.13</th>
              <td>08</td>
              <td>03</td>
              <td>5.6.0</td>
              <td>1.5.5</td>
              <td>1.4.5</td>
              <td>1.7.7</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 15th, 2014</td>
              <th>2.4.14</th>
              <td>08</td>
              <td>03</td>
              <td>5.6.1</td>
              <td>1.5.5</td>
              <td>1.4.5</td>
              <td>1.7.7</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>September 6th, 2014</td>
              <th>2.4.15</th>
              <td>08</td>
              <td>03</td>
              <td>5.6.2</td>
              <td>1.5.6</td>
              <td>1.4.6</td>
              <td>1.7.8</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>January 18th, 2015</td>
              <th>2.4.16</th>
              <td>08</td>
              <td>03</td>
              <td>5.6.3</td>
              <td>1.5.6</td>
              <td>1.4.6</td>
              <td>1.7.8</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>January 31th, 2015</td>
              <th>2.4.17</th>
              <td>08</td>
              <td>03</td>
              <td>5.6.4</td>
              <td>1.5.6</td>
              <td>1.4.6</td>
              <td>1.7.8</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>August 30th, 2015</td>
              <th>2.4.18 </th>
              <td>08.1 </td>
              <td>03</td>
              <td>5.6.5</td>
              <td>1.5.6</td>
              <td>1.4.6</td>
              <td>1.7.8</td>
              <td>1.2.8</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>October 4th, 2015</td>
              <th>2.4.19</th>
              <td>08.1</td>
              <td>03</td>
              <td>5.6.6</td>
              <td>1.5.6</td>
              <td>1.4.6</td>
              <td>1.7.8</td>
              <td>1.2.8</td>
              <td>----- </td>
            </tr>
            <tr>
              <td>November 21th, 2015</td>
              <th>2.4.20</th>
              <td>08.1</td>
              <td>03</td>
              <td>5.6.7</td>
              <td>1.5.8</td>
              <td>1.4.8</td>
              <td>1.7.10</td>
              <td>1.2.10</td>
              <td>----- </td>
            </tr>
            <tr>
              <td>April 24th, 2016</td>
              <th>2.4.21</th>
              <td>08.1</td>
              <td>03 </td>
              <td>5.6.8 </td>
              <td>1.5.9 </td>
              <td>1.4.9 </td>
              <td>1.7.11 </td>
              <td>1.2.10</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>June 5th, 2016</td>
              <th>2.4.22</th>
              <td>08.1</td>
              <td>03 </td>
              <td>5.6.9</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>October 29th, 2016</td>
              <th>2.4.23</th>
              <td>08.1</td>
              <td>03 </td>
              <td>5.6.9</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>January 21st, 2017</td>
              <th>2.4.24</th>
              <td>08.1</td>
              <td>03 </td>
              <td>5.6.10</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>-----</td>
            </tr>
            <tr>
              <td>October 4th, 2015</td>
              <th>2.5.0</th>
              <td>09</td>
              <td>04</td>
              <td>5.7.0</td>
              <td>1.5.7</td>
              <td>1.4.7</td>
              <td>1.7.9</td>
              <td>1.2.9</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>October 17th, 2015</td>
              <th>2.5.1</th>
              <td>09</td>
              <td>04</td>
              <td>5.7.1</td>
              <td>1.5.8</td>
              <td>1.4.8</td>
              <td>1.7.10</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>November 21st, 2015</td>
              <th>2.5.2</th>
              <td>09</td>
              <td>04</td>
              <td>5.7.2</td>
              <td>1.5.8</td>
              <td>1.4.8</td>
              <td>1.7.10</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>January 4th, 2016</td>
              <th>2.5.3</th>
              <td>09</td>
              <td>04</td>
              <td>5.7.3</td>
              <td>1.5.8</td>
              <td>1.4.8</td>
              <td>1.7.10</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>April 24th, 2016</td>
              <th>2.5.4</th>
              <td>09 </td>
              <td>04 </td>
              <td>5.8.0 </td>
              <td>1.5.9 </td>
              <td>1.4.9 </td>
              <td>1.7.11 </td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>June 5th, 2016</td>
              <th>2.5.5</th>
              <td>09</td>
              <td>04</td>
              <td>5.8.1</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>September 10th, 2016</td>
              <th>2.5.6</th>
              <td>09</td>
              <td>04</td>
              <td>5.8.2</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>October 29th, 2016</td>
              <th>2.5.7</th>
              <td>09</td>
              <td>04</td>
              <td>5.8.3</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>January 2nd, 2017</td>
              <th>2.5.8</th>
              <td>09</td>
              <td>04</td>
              <td>5.8.4</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>January 21st, 2017</td>
              <th>2.5.9</th>
              <td>09</td>
              <td>04</td>
              <td>5.9.0</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>April 4th, 2017</td>
              <th>2.5.10</th>
              <td>09</td>
              <td>04</td>
              <td>5.10.0</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.11</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>June 23rd, 2017</td>
              <th>2.5.11</th>
              <td>09</td>
              <td>04</td>
              <td>5.11.0</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.12</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>September 2nd,2017</td>
              <th>2.5.12</th>
              <td>09</td>
              <td>04</td>
              <td>5.11.1</td>
              <td>1.5.9</td>
              <td>1.4.9</td>
              <td>1.7.12</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>October 28th, 2017</td>
              <th>2.5.13</th>
              <td>09</td>
              <td>04</td>
              <td>5.12.0</td>
              <td>1.5.10</td>
              <td>1.4.10</td>
              <td>1.7.13</td>
              <td>1.2.10</td>
              <td>1.0.0</td>
            </tr>
            <tr>
              <td>December 20th, 2017</td>
              <th>2.5.14</th>
              <td>09</td>
              <td>04</td>
              <td>5.12.1</td>
              <td>1.5.10</td>
              <td>1.4.10</td>
              <td>1.7.13</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
            <tr>
              <td>April 28th, 2018</td>
              <th>2.5.15</th>
              <td>09</td>
              <td>04</td>
              <td>5.12.2</td>
              <td>1.5.10</td>
              <td>1.4.10</td>
              <td>1.7.13</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
            <tr>
              <td>July 19th, 2018</td>
              <th>2.5.16</th>
              <td>09</td>
              <td>04</td>
              <td>5.12.3</td>
              <td>1.5.10</td>
              <td>1.4.10</td>
              <td>1.7.13</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
            <tr>
              <td>September 30th, 2018</td>
              <th>2.5.17</th>
              <td>09</td>
              <td>04</td>
              <td>5.13.0</td>
              <td>1.5.10</td>
              <td>1.4.10</td>
              <td>1.7.13</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
            <tr>
              <td>December 8th, 2018</td>
              <th>2.5.18</th>
              <td>09</td>
              <td>04</td>
              <td>5.13.1</td>
              <td>1.5.10</td>
              <td>1.4.10</td>
              <td>1.7.13</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
            <tr>
              <td>January 19th, 2019</td>
              <th>2.5.19</th>
              <td>09</td>
              <td>04</td>
              <td>5.13.2</td>
              <td>1.5.11</td>
              <td>1.4.11</td>
              <td>1.7.14</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
	    <tr>
              <td>February 9th, 2019</td>
              <th>2.5.20</th>
              <td>09</td>
              <td>04</td>
              <td>5.13.3</td>
              <td>1.5.11</td>
              <td>1.4.11</td>
              <td>1.7.14</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
	    </tr>
	    <tr>
              <td>May 25th, 2019</td>
              <th>2.5.21</th>
              <td>09</td>
              <td>04</td>
              <td>5.13.4</td>
              <td>1.5.11</td>
              <td>1.4.11</td>
              <td>1.7.14</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
	    <tr>
              <td>July 6th, 2019</td>
              <th>2.5.22</th>
              <td>09</td>
              <td>04</td>
              <td>5.13.5</td>
              <td>1.5.11</td>
              <td>1.4.11</td>
              <td>1.7.14</td>
              <td>1.2.10</td>
              <td>1.1.1</td>
            </tr>
            <tr>
              <td>December 16th, 2018</td>
              <th>2.6.0</th>
              <td>10</td>
              <td>05</td>
              <td>6.0.0</td>
              <td>1.6.0</td>
              <td>1.5.0</td>
              <td>1.8.0</td>
              <td>1.2.11</td>
              <td>1.1.2</td>
            </tr>
            <tr>
              <td>January 19th, 2019</td>
              <th>2.6.1</th>
              <td>10</td>
              <td>05</td>
              <td>6.0.1</td>
              <td>1.6.0</td>
              <td>1.5.0</td>
              <td>1.8.0</td>
              <td>1.2.11</td>
              <td>1.1.2</td>
            </tr>
	    <tr>
              <td>February 9th, 2019</td>
              <th>2.6.2</th>
              <td>10</td>
              <td>05</td>
              <td>6.0.2</td>
              <td>1.6.1</td>
              <td>1.5.1</td>
              <td>1.8.1</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
            </tr>
	    <tr>
	      <td>March 30th, 2019</td>
              <th>2.6.3</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.1.0</td>
              <td>1.6.1</td>
              <td>1.5.1</td>
              <td>1.8.1</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
            </tr>
	    <tr>
	      <td>May 25th, 2019</td>
              <th>2.6.4</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.1.1</td>
              <td>1.6.1</td>
              <td>1.5.1</td>
              <td>1.8.1</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
	    </tr>
	    <tr>
	      <td>July 6th, 2019</td>
              <th>2.6.5</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.1.2</td>
              <td>1.6.1</td>
              <td>1.5.1</td>
              <td>1.8.1</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
	    </tr>
	    <tr>
	      <td>September 21st, 2019</td>
              <th>2.6.6</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.0</td>
              <td>1.6.2</td>
              <td>1.5.2</td>
              <td>1.8.2</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
	    </tr>
	    <tr>
	      <td>January 12th, 2020</td>
              <th>2.6.7</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.1</td>
              <td>1.6.2</td>
              <td>1.5.2</td>
              <td>1.8.2</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
	    </tr>
	    <tr>
	      <td>February 8th, 2020</td>
              <th>2.6.8</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.2</td>
              <td>1.6.2</td>
              <td>1.5.2</td>
              <td>1.8.2</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
	    </tr>
	    <tr>
	      <td>March 22nd, 2020</td>
              <th>2.6.9</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.3</td>
              <td>1.6.2</td>
              <td>1.5.2</td>
              <td>1.8.2</td>
              <td>1.2.12</td>
              <td>1.1.2</td>
	    </tr>
	    <tr>
	      <td>May 31st, 2020</td>
              <th>2.6.10</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.4</td>
              <td>1.6.3</td>
              <td>1.5.3</td>
              <td>1.8.3</td>
              <td>1.2.13</td>
              <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>September 5th, 2020</td>
              <th>2.6.11</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.5</td>
              <td>1.6.3</td>
              <td>1.5.3</td>
              <td>1.8.3</td>
              <td>1.2.13</td>
              <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>September 11th, 2020</td>
              <th>2.6.12</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.6</td>
              <td>1.6.3</td>
              <td>1.5.3</td>
              <td>1.8.3</td>
              <td>1.2.13</td>
              <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>November 8th, 2020</td>
              <th>2.6.13</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.7</td>
              <td>1.6.3</td>
              <td>1.5.3</td>
              <td>1.8.3</td>
              <td>1.2.13</td>
              <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>March 14th, 2021</td>
              <th>2.6.14</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.8</td>
              <td>1.6.3</td>
              <td>1.5.3</td>
              <td>1.8.3</td>
              <td>1.2.13</td>
              <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>May 13th, 2021</td>
	      <th>2.6.15</th>
	      <td>10.1</td>
	      <td>05</td>
	      <td>6.2.9</td>
	      <td>1.6.3</td>
	      <td>1.5.3</td>
	      <td>1.8.3</td>
	      <td>1.2.13</td>
	      <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>January 2nd, 2022</td>
              <th>2.6.16</th>
              <td>10.1</td>
              <td>05</td>
              <td>6.2.10</td>
              <td>1.6.3</td>
              <td>1.5.3</td>
              <td>1.8.3</td>
              <td>1.2.13</td>
              <td>1.1.3</td>
	    </tr>
	    <tr>
	      <td>April 24th, 2021</td>
              <th>2.7.0</th>
              <td>11</td>
              <td>06</td>
              <td>6.3.0</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.2.13</td>
              <td>1.2.0</td>
	    </tr>
	    <tr>
	      <td>May 13th, 2021</td>
              <th>2.7.1</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.0</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.2.13</td>
              <td>1.2.0</td>
	    </tr>
	    <tr>
	      <td>September 25th, 2021</td>
              <th>2.7.2</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.1</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.2.13</td>
              <td>1.2.0</td>
	    </tr>
	    <tr>
	      <td>January 2nd, 2022</td>
              <th>2.7.3</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.2</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.2.13</td>
              <td>1.2.1</td>
	    </tr>
	    <tr>
	      <td>March 13th, 2022</td>
              <th>2.7.4</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.3</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.2.13</td>
              <td>1.2.1</td>
	    </tr>
	    <tr>
	      <td>April 13th, 2022</td>
              <th>2.7.5</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.4</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.2.13</td>
              <td>1.2.1</td>
	    </tr>
	    <tr>
	      <td>June 19th, 2022</td>
              <th>2.7.6</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.5</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>August 7th, 2022</td>
              <th>2.7.7</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.4.6</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>November 29th, 2022</td>
              <th>2.7.8</th>
              <td>11.1</td>
              <td>06</td>
              <td>6.5.0</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>March 26th, 2023</td>
              <th>2.7.9</th>
              <td>11.2</td>
              <td>06</td>
              <td>6.5.1</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>June 25th, 2023</td>
              <th>2.7.10</th>
              <td>11.2</td>
              <td>06</td>
              <td>6.6.0</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>August 5th, 2023</td>
              <th>2.7.11</th>
              <td>11.2</td>
              <td>06</td>
              <td>6.6.1</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>September 3rd, 2023</td>
              <th>2.7.12</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.7.0</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>October 1st, 2023</td>
              <th>2.7.13</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.7.1</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>March 23rd, 2024</td>
              <th>2.7.14</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.7.2</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>June 6th, 2024</td>
              <th>2.7.15</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.7.3</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>December 9th, 2024</td>
              <th>2.7.16</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.8.0</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>March 22nd, 2025</td>
              <th>2.7.17</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.8.1</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>May 20th, 2025</td>
              <th>2.7.18</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.8.2</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>july 31st, 2025</td>
              <th>2.7.19</th>
              <td>11.3</td>
              <td>06</td>
              <td>6.8.3</td>
              <td>1.7.0</td>
              <td>1.6.0</td>
              <td>1.9.0</td>
              <td>1.3.0</td>
              <td>1.2.2</td>
	    </tr>
	    <tr>
	      <td>August 2nd, 2025</td>
              <th>2.8.0</th>
              <td>11.3</td>
              <td>06</td>
              <td>7.0.0</td>
              <td>1.7.0</td>
              <td>1.6.1</td>
              <td>1.10.0</td>
              <td>1.4.0</td>
              <td>1.2.2</td>
	    </tr>
	  </table>
	</div>

	<h2><a name="scrambling">Scrambling (weak encryption)</a></h2>

	<p>
          Before strong encryption was
          implemented, dar had only a very simple and weak encryption
          mechanism. It remains available in current release under the
          "scram" algorithm name. It mains advantage is that is does not
          rely on any external library, it is completely part of libdar.
	</p>

	<p>
          How does it works?
	</p>
	<p>
          Consider the pass phrase as a
          string, thus a sequence of bytes, thus a sequence of integer
          each one between 0 and 255 (including 0 and 255). The data to
          "scramble" is also a sequence of byte, usually much longer than
          the pass phrase. The principle is to add byte by byte the pass
          phrase to the data, modulo 256. The pass phrase is repeated all
          along the archive. Let's take an example:
	</p>
	<p>
          the pass phrase is "he\220lo" (where \220 is the character which
          decimal value is 220). The data is "example"
	</p>
	<p>
          Taken from ASCII standard we have:
	</p>
	<ul>
	  <li>h = 104</li>
          <li>l = 108</li>
          <li>o = 111</li>
          <li>e = 101</li>
          <li>x = 120</li>
          <li>a = 97</li>
          <li>m = 109</li>
          <li>p = 112</li>
	</ul>

	<code class=block>
          &nbsp;          e       x       a       m       p       l       e
          &nbsp;          101     120     97      109     112     108     101
          &nbsp;
          &nbsp;  +       h       e       \220    l       o       h       e
          &nbsp;          104     101     220     108     111     104     101
          &nbsp;
          &nbsp;  ---------------------------------------------------------------
          &nbsp;
          &nbsp;          205     221     317     217     223     212     202
          &nbsp;
          &nbsp;  ---------------------------------------------------------------
          &nbsp;  modulo
          &nbsp;  256 :   205     221     61      217     223     212     202
          &nbsp;          \205    \201    =       \217    \223    \212    \202
	</code>

	<p>
          thus the data "example" will be written in the archive as
          <code>\205\201=\217\223\212\202</code>
	</p>

	<p>
          This method allows to decode any
          portion without knowing the rest of the data. It does not
          consume much resources to compute, but it is terribly weak and
          easy to crack. Of course, the data is more difficult to retrieve
          without the key when the key is long. Today dar can also use
          strong encryption (blowfish and few others) and thanks to a
          encryption block can still avoid reading the whole archive to
          restore any single file.
	</p>



	<h2><a name="strong_encryption">Strong encryption internals</a></h2>

	<h3>Encryption per block</h3>
	<p>
	  To not completely break the
          possibility to directly access a file withing a <i>dar</i> backup,
	  the archive is not encrypted as a whole (as would probably do
	  an external program, like <i>openssl</i>). The
          encryption is done per large block of data. This way,
	  each block can be decrypted independently from the others,
	  and if you want to read some data somewhere
          you only need to decrypt the whole block(s) it is located in.
	</p>
	<p>
	  Such encryption block size can range from 10 bytes to 4 GB
	  (10 kiB is the default value). We will
	  design these as <b>libdar cipher block</b>, to differentiate with
	  what the underlying cipher algoritm uses as block.
	</p>
	<h3>CBC and IV</h3>
	<p>
	  Inside each libdar cipher block, <i>dar</i> relies on
	  the CBC mode (Cipher Block Chaining). In this mode, the data
	  of a libdar cipher block is split in small plaintext blocks (a few tens of
	  bytes as defined by the cipher algorithm). These plaintext blocks
	  are not ciphered independently, but the ciphering result is melt with
	  the next plaintext block before the ciphering operation.
	  The advantage of doing so, is that a repeated data pattern
	  does not lead to a repeated encryption pattern. However the first
	  plaintext block of a libdar cipher block is not melt with anything. To
	  cope with that an <i>Initial Vector</i> (IV) can be provided to 'randomize'
	  the encryption result, though one has to record what was the IV at time
	  of encryption to be able to decipher the data.
	</p>
	<p>
	  The <i>IV</i> for each <i>libdar cipher block</i> is derived from its number
	  inside the dar backup/archive and from the encryption key. The result
	  is that even if you have the same data in two libdar cipher blocks,
	  it will not result in the same encrypted data common to both (or to more
	  libdar cipher blocks)
	</p>
	<h3>Elastic buffer</h3>
	<p>
          An "elastic buffer" is introduced at the beginning and at the
          end of the archive, to protect against plain text attack.
          The elastic buffer size randomly varies and is defined at
          execution time. It is composed of randomly generated data
	  (using <code>gcry_create_nonce()</code>).
	</p>
	<p>
	  But to be able at reading time to determine the amount of random garbage
	  that has been put at the beginning and at the end of the archive by mean
	  of such elastic buffers, a small structure is randomly dropped inside
	  the garbage that tells the overall size of this random data:
	</p>
	<p>
	  Two marks characters '&gt;' and '&lt;' delimit a <b>size field</b>, which
	  indicate the byte size of the elastic buffer. The size field is
	  randomly placed in the elastic buffer. Last, the buffer is encrypted
	  with the rest of the data. Typical elastic buffer size range
	  from 1 byte to 10 kB, for both initial and terminal elastic
	  buffers.
	</p>
	<p>
          Elastic buffers may also be used inside libdar encryption blocks, when
	  the <i>libdar cipher block</i> size is not a multiple of the
	  the ciphering algorithm plaintext block size. Such elastic buffer
	  is added for padding at the end of the <i>libdar cipher block</i>.
	</p>

	<h3>Key Derivation Fonction - KDF</h3>
	<p>
	  Just above, we saw:
	</p>
	<ul>
	  <li>
	    how CBC inside a <i>libdar cipher block</i> avoided repetitive data
	    to be seen as repetitive encrypted data
	  </li>
	  <li>
	    how different IV could avoid exposing repetitive data between
	    <i>libdar cipher blocks</i> to be seen as repetitive encrypted data
	  </li>
	  <li>
	    We also see how <i>elastic buffer</i> randomly moved data structure
	    inside an archive to minimize code book attack.
	  </li>
	</ul>

	<p>
	  <b>First</b>, what if you use always the same password/passphrase between
	  different archives? Breaking one archive will let the attacker access
	  all archives or backups. Worse, an attacker has much more data
	  to work on and compute statistical decryption methods to get to its
	  goal.
	</p>
	<p>
          <b>Second</b>, directly using a human provided password would provide a
          weak encryption. Because in all the possible key values, humans choices lead
	  to a very restricted set of values: only letters, digits, space and eventually
	  punctuation characters, with a certain order at words level and
	  phrase level, even 5ubst1tu1n9 (substituing) letters by digits does
	  not bring much more randomness... Think that in the 256 different values
	  a byte can have we barely use 50 of them. Thing that in the may letter
	  combinaisons we have, we are far from using all of them (how many English words do you
	  know that contain 'xz'? ...Or even more unreadable larger sequences?)
	</p>
	<p>
	  To get one step further in securing your data, <i>libdar</i> makes use
	  of a <b>K</b>ey <b>D</b>erivation <b>F</b>unction (KDF):
	</p>
	<p>
	  Strong encryption uses secret key, to cipher/uncipher data, we
          will say "password" to simplify in the following.
	</p>
	<p>
	  To overcome this human weakness, the state of the art
          is to use a <i>Key Derivation Function</i>, which takes in input the
          human provided password plus a "salt" and outputs a stronger key
          (salt is described below). This function is based on a hash
          algoritm (sha1 by default, but this value can be modified since
          archive format 10/release 2.6.0) and an iteration count (2000
          before format 10 and 200000 interations since release 2.6.0 by default).
          The KDF mixes salt and passphrase then hash the
          result and applies the hashing algorithm on it repeatedly the number of
	  iteration count that has been selected, the final result is the <i>hashed password</i>
	</p>
	<p>
	  Note that as an
	  alternative to PBKDF2 (from PKCS#5 v2) which is the name of the KDF algorithm
	  we have just described, release 2.7.0 brings the modern <b>argon2</b> KDF,
	  which is the default, it has been built against libargon2 library.
	  Argon2 also makes use of a salt and an interation could, so what was described
	  above stays valid at a global view level.
	</p>
	<p>
	  So the KDF transform the well know human namespace of secret keys in a new namespace
	  for keys, not wider, but not that well known. Of course, anyone with the knownledge
	  of the salt, iteration count and algorithm is able to know it, but
	  <b>it costs a lot of effort in computing resource</b>! And this is the objective.
	  No need to hide or make secret the KDF parameters, when an attacker that
	  would requires hours or days to crack a password based on a dictionnary attack
	  now needs years or centuries to do so.
	</p>

	<h3>Choosing the salt</h3>

	<p>
          The <b>salt</b> is a randomly
          chosen value by <i>libdar</i> and stored in clear in the archive
          header, beside the iteration count and hash algorithm used for
          the KDF. Thus even if the user has the same password for
          different archive, the effective real key used for strong encryption
          will differ from archive to archive or from backup to backup,
	  making much more difficult
          for an attacker to crack an archive using statistical methods
          over a large number of archives sharing the same human provided
          password. And second point, a dictionnary attack is much more costly
	  to succeed, either you need hundred thouthand more time of hundred
	  thouthand more CPU power.
	</p>

	<h3>In summary</h3>

	<p>
	  In summary, <b>salt</b> randomize keys between archive, <b>elastic buffers</b>
	  randomize
	  data location inside the archive, <b>IV</b> randomize encryption between libdar
	  encryption blocks, and <b>CBC mode</B> randomize encryption withing a libdar encryption
	  block.
	</p>

	<p>
          Here follows a diagram of the way key, block number, cipher
          algorithm and Initial Vector (IV) interact together:
	</p>

	<code class=block>
	  &nbsp;           +------------------- [ algo in CBC mode ] -----------------------------> main key handle
	  &nbsp;algorithm -+                           ^                                                  |
	  &nbsp;           +---> max key len           |                                                  |
	  &nbsp;                     |                 |                                                  |
	  &nbsp;                     |                 |                                                  |
	  &nbsp;                     v                 |                                                  |
	  &nbsp;password ------> [  KDF  ] ------> hashed_key -------------+                              |
	  &nbsp;                     ^                                     |                              |
	  &nbsp;                     |                                     |                              |
	  &nbsp;salt ----------------+                                     v                              |
	  &nbsp;                     ^                              [ SHA1/SHA256 ]                       |
	  &nbsp;                     |                                     |                              |
	  &nbsp;hash algo -----------+                                     |                              |
	  &nbsp;                     ^                                     v                              |
	  &nbsp;                     |                                essiv_password                      |
	  &nbsp;iteration count -----+                                     |                              |
	  &nbsp;                                                           |                              |
	  &nbsp;                                                           v                              |
	  &nbsp;                                           [ Blowfish/AES256 in ECB mode ]                |
	  &nbsp;                                                           |                              |
	  &nbsp;                                                           |                              |
	  &nbsp;                                                           v                              |
	  &nbsp;. . . . . . . . . .                                 essiv key handle                      |
	  &nbsp;. Initialization  .                                        |                              |
	  &nbsp;. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .|. . . . . . . . . . . . . . . | . . . . . . . . . .
	  &nbsp;                                                           v                              |
	  &nbsp;libdar cipher block's number -----------------------> [ encrypt ] ------> IV -----+       |
	  &nbsp;                                                                                  |       |
	  &nbsp;                                                                                  |       |
	  &nbsp;                                                                                  v       v
	  &nbsp;libdar cipher block's data ---------------------------------------------------> [ encrypt/decrypt ] -----> data
	  &nbsp;
	</code>

	<h2><a name="asym"></a>Public key based encryption internals</h2>

	<p>
	  Dar does not encrypt the whole
          archive with a recipient's public key, but rather randomly chooses
          a (long) password for symmetric encryption (as seen above, except
          it does not need KDF and salt as it can select a much better
          random key than human can do), encrypts that password with the
          recipient's public keys (eventually signing it with your own
          private key) and drops a copy of this ciphered/signed data into
          the archive. At reading time, dar read the archive header to find
          the encrypted password, decrypt it using the user's private key
          then use that password, now in clear, to decrypt the rest of the
          archive with the adhoc symmetric algorithm.
	</p>
	<p>
          Signing is done on the randomly chosen ciphering key as seen
          above, but also on the catalogue (the table of content located at
          the end of the archive). More precisely the catalogue is
          sha512-hashed and the resulting hash is signed. The catalogue hash
          and its signature are stored encrypted in the archive right after
          the catalogue.
	</p>

	<h3>Why not using only asymmetric encryption end to end?</h3>
	<p>
	  First, for a given fixed amount of data, the resulting ciphered
          data size may vary. Thus sticking ciphered block together in the
          archive would not lead to easily know where a block starts and
          where is located its end. Second, doing that way allows an archive
          to have several different recipients, the password is ciphered for
          each of them and the archive is readable by any specified
          recipient, while they do not share any key. Doing that way has
          very little impact of archive size.
	</p>

	<h3>Why not using signing from end to end?</h3>
	<p>
	  First, this can be done without dar, just use gpg on the slices of
	  an archive, so there is no advantage in having such feature inside
          dar. The other reason is time, as signing the whole archive would
          be long. it would also be very painful to validate a given archive
          authenticity (time to read a whole archive), here we can leverage
          the fact the archive is encrypted (thus tampering the archive
          would be seen when unciphering it) and that dar uses of several
          mechanismes (compression, clear text CRC) to detect data
          corruption.
	</p>

	<h3>Security restriction when signing an archive for multiple recipients</h3>

	<p>
          For a multi recipient archive, any recipient has decode the
          signed and encrypted key. One could even reuses this same encryption key
          which may also be signed by the original sender to build a new
          archive with totally different content. Since 2.7.0 a warning is issued
	  when this condition is met, but the action is still allowed as it may make
	  sense when exchanging data between a set of people that trust each other,
	  but still need to validate the authenticity of the exchanged data
	  (over Internet for example).
	</p>
	<p>
	  But to exploit this security restriction the attack should still be difficult
	  as the table of content (the catalogue) should is also signed within the archive.
	  Touching any part of it would break this signature, thus the archive table of
	  content cannot be tampered if the signature algorithm is strong. This
	  <i>catalogue</i> contains the CRC of any file data, EA and FSA, as well as the
	  size of the compressed data. Thus the attacker may modify the file's data but must
	  manage for the resulting modification to still satisfy the CRC and have the same
	  lenght. Worse, if compression is used, the modification must not exceed the amount
	  of compressed data and must stay uncompressible by the same compression algorithm
	  that was used for that file in the original archive.
	</p>
	<p>
	  In short, if this security restriction exists and in exploitable in therory,
	  it is not so easy to realize it for a large portion of the archive.
	</p>

	<h2><a name="multi-threaded">Multi-threading in libdar</a></h2>

	<h3>Ciphering</h3>
	<p>
	  The ciphering in dar/libdar is performed by large block of data (see -# option
	  and consorts), it was
	  thus possible (added in 2.7.0) to parallelize the ciphering/deciphering operation assigning
	  different blocks to different threads without changing the archive format.
	  The measured performance gain is quite good, but usually hidden by the
	  compression load or disk I/O. More than 2 threads for ciphering/deciphering
	  does not bring much benefit to the
	  overall processing time.
	</p>
	<p>
	  To assign blocks
	  to worker threads (those that compute the ciphering algorithm), two helper
	  threads are needed: one that copy data into block of memory and scatters it to
	  workers for they can work in total autonomy, and another one that gather the resulting block of
	  memory in the correct order.
	<p/>
	<p>
	  If performance gain is present and no change in the archive format
	  was necessary to leverage multi-threading
	  for ciphering/deciphering, however, this has some impact on memory usage
	  required by dar. Each thread will need a pair of blocks (one for the clear
	  data, one for the ciphered equivalent). In addition, the gathering
	  and scattering structures of blocks to/from the workers (which we will globally
	  design under the term <i>ratelier</i> can hold each N block of memory
	  (N being the number of workers) in fact the size of these
	  structures has been chosen a bit wider: N+N/2. Last the helper thread that
	  feeds data to the worker may hold one pair of block under construction,
	  and the gathering thread may obtain from the ratelier_gather a whole structure (N+N/2 blocks)
	  to work with. For N worker, the number of memory block is N+N/2 for each ratelier
	  plus N for each worker, plus N+N/2 for the gathering thread and one for the scattering thread,
	  which makes around 7*N blocks of additional memory requirement. Concretely, having 5 threads with
	  encryption block of 10240 bytes (10 KiB) leads dar to allocate 350 KiB (7x5x10) of additional
	  memory compared to the single threaded implementation.
	</p>

	<h3>Compression</h3>
	<p>
	  For compression, things have been more complicated, as before release 2.7.0 compression was done
	  per file in <b>streaming mode</b>. In that mode <i>dar</i> has to provide a sequential flow of bytes to the compression
	  engine and at the same time retrieve the compression/decompression counterpart. The API provided
	  by the different libraries (libz, libbzip2, liblzo2, liblzma5, libzstd, liblz4) do not provide
	  multi-threaded approach for this mode of compressing data, however this gives the best compression
	  ratio you can expect for a given file, given compression algorithm and compression level.
	<p/>
	<p>
	  Before 2.7.0 parallelization had been tried but with little success by running compression and
	  encryption in different threads. Usually one of the threads spent most of its time waiting for
	  the other and the overall performance gain was little due to the added thread management and
	  synchronization overhead. This scheme
	  has been completely abandoned to the one exposed above for encryption. To extend this method
	  to compression, a new compression mode has to be added, to the legacy streaming one to:
	  the <b>block compression mode</b>, which is described below. Note that with release 2.7.0 both mode will coexist,
	  and you will still be able to read old archive and generate new one with the old single thread/streaming approach.
	<p/>
	<p>
	  The implementation is quite similar to the encryption approach, a set of worker proceed to the compression
	  or decompression of one block at a time and two helper threads are used, one feed on one side and the
	  other gather the results on the other side.
	<p/>
	<p>
	  The consequence is a slightly degraded compression ratio when the block size is chosen small. But with
	  larger blocks there is not noticeable compression ratio difference, though it has have an impact
	  on the memory usage. That's a balance to find between what memory mean you have
	  and want to use, how much time you have and want to spend for the compression and how much space you
	  have want to use to store the resulting archive.
	  Choosing a block size
	  of 102400 bytes (see extended syntax of -z option) with 4 threads (see -G option) will lead libdar to
	  allocated 2800 KiB (~ 2.7 GiB) in addition
	  to what libdar already uses for single thread approach (same formula as what is described above for
	  encryption). If you use both parallel encryption and parallel
	  compression at the same time you have to sum the additional memory requirements of each feature.
	</p>

	<h4>Command-line</h4>
	<p>
	  The thread number for both encryption and compression is driven by the -G option. See man page
	  for details. Note that, as described above, multi-threaded compression/decompression is only
	  possible with the new compression per block method, which means you have to specify a compression block
	  size (see -z option).
	</p>

	<h2><a name="block_compression_mode">Streaming versus block Compression mode</a></h2>

	<h3>Streaming compression</h3>

	<p>
	  Since its first day with version 1.0.0, dar/libdar provides streaming compression. It started with <b>gzip</b>
	  algorithm, has been extended later to <b>bzip2</b>, then <b>lzo</b>, <b>xz/lzma</b>, and since release 2.7.0
	  two new algorithms have been added: <b>zstd</b> and <b>lz4</b>.
	</p>
	<p>
	  Streaming compression let libdar provide new decompress data bytes and in return from time
	  to time get back some compressed data bytes from the compression engine. There is no limitation in size: a stream
	  of uncompressed data enters the compression engine from which exists another stream of compressed data.
	  You do not need very large memory buffers to feed and gather data to/from the engine,
	  and can obtain very good compression ratio. Though the process cannot be parallelized as
	  the stream of incoming data must be provided to this single engine in the expected order.
	  The process is similar for decompression, you give back to the engine the compressed data.
	  It does not matter if you feed the engine by smaller or larger groups of bytes than what
	  the engine provided when compressing, as long as you keep the byte sequence order, the resulting uncompressed stream will be the original
	  one you gave for compression.
	</p>
	<p>
	  Such streaming compression is natively provided by libz, libbz2, libxz/lzma and libzstd. So
	  dar store these compressed data as provided: an unstructured and arbitrarily long sequence
	  of bytes corresponding to the (compressed) data of a given file. Yes, dar compress file per
	  file: a new file, a new stream.
	</p>

	<h3>Block compression</h3>

	<p>
	  For lzo algorithm (added with 2.4.0 release) the liblzo2 library does not provide such streaming
	  interface, only a per buffer compression is available.
	  That is to say, you have to provide block of uncompressed
	  data from which you get a variable amount of compressed bytes. To decompress the data
	  you have to provide back this exact block to the decompression engine. If you sticked the
	  blocks together and do not provide them back at their original boundaries, the decompression
	  will fail.
	</p>
	<p>
	  For that reason dar use a structure inside the compressed file's data to record where
	  each block starts and ends, this way it is possible to feed the decompressing engine with coherent
	  compressed data and get back the original clear data.
	</p>
	<p>
	  The structure used is made of an arbitrary long sequence of blocks. Each block is constitued
	  of three fields:
	</p>
	<ul>
	  <li><b>a Type</b> which has two values, either <i><b>D</b>ata</i> or <i><b>E</b>nd of file</i></li>
	  <li>an <b>block size</b> which is zero for <i>end of file</i> block types</li>
	  <li><b>a sequence of compressed bytes</b> which length is given by the <i>block size</i> field</li>
	</ul>
	<code class=block>
	  +--------+-----------+---------------------+--------+------------+-----------------+-----+--------+----------------------+<br/>
	  | Type=D |block size | compressed data ... | Type=D | block size | compressed data | ... | type=E | block size = 0 (EOF) |<br/>
	  +--------+-----------+---------------------+--------+------------+-----------------+-----+--------+----------------------+<br/>
	</code>
	<p>
	  One thing you cannot guess from a given compressed data is how much uncompressed data it will
	  generate, while you have to prepare and allocate in memory a buffer large enough to receive it.
	  It has been decided to slice the file's data in uncompressed block <b>not larger than</b> the maximum
	  liblzo2 can handle, which is 240 kiB. So at decompression time, whatever is the size of the
	  compressed block we can provide a 240 kiB buffer to receive the decompressed data and repeat
	  the process as much time as necessary to process the whole compressed data of a given file.
	</p>
	<p>
	  With release 2.7.0 when adding lz4 compression algorithm, it has been found that the
	  "streaming API" of lz4 library was not really a streaming API as it requested to provide back
	  the exact compressed block and not a stream of bytes for the decompression to be possible. For that
	  reason, lz4 streaming is done the exact same way as what has been implemented for lzo streaming:
	  This is a block compression with 240 kiB block size.
	</p>
	<p>
	  The <b>block compression new feature</b> you have starting release 2.7.0 is thus just an extension of this method
	  by providing to the user the ability to select the maximum size of the uncompressed data block that
	  will be compressed at a time. The -z option has been extended to allow one to specify that block size.
	  If set to zero we stick to the streaming mode, else we use block compression.
	</p>
	<p>
	  But for a given algorithm (except lzo and lz4) streaming mode and block mode are not compatible,
	  the first has no structure (no block and cannot thus be processed in parallel) the second adds some
	  non-compressed bytes beside the compressed data (the block headers). For that reason the new archive
	  format contains the block size used at creation time in the archive header and trailer, which first
	  let libdar allocate buffer large enough to receive decompressed data and second use the correct
	  mode to retrive the
	  original data.
	</p>

	<h3>Multi threading</h3>

	<p>
	  As mentionned earlier, to provide multi-threading support for compression (added
	  at release 2.7.0) the use of per block compression is necessary. In the dar archive, this mode
	  of compression provides the same structured data of compressed blocks as described above for
	  lzo, but with the additional freedom to choose the block size (which stay fixed at 240 kiB for lzo and lz4
	  pseudo-streaming mode) and any compression algorithm supported by libdar.
	</p>
	<p>
	  But that is not enough to have per block structure in archive to have multi-threaded processing:
	  you have also to setup the code that read in advance, feed block in parallel to different threads,
	  having each their own compression/decompression engine set and ready for use, gather the
	  resulting work, reordering them if necessary before writing down to filesystem. The method used here is very similar to what was used
	  to add multi-threading suppor for encryption/decryption (see previous chapter)
	</p>
	<p>
	  Last, if multi-threading is not possible for real streaming compression, it is available in dar/libdar
	  for lz4 and lzo algorithm that are implemented as 240 KiB block compression. For other algorithm,
	  streaming compression use different API of the libraries libdar relies on from the block compression,
	  and is not possible to parallelize.
	</p>
      </div>
    </div>
  </body>
</html>
