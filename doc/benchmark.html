<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <link href="style.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta content="text/html; charset=ISO-8859-1" http-equiv="content-type">
    <title>Benchmarking backup tools</title>
  </head>
  <body>

    <center><h1>Benchmarking backup tools</h1></center>

    <h2>Introduction</h2>
    <p>
      This document has for objective to compare common backup tools under Unix
      (Linux, FreeBSD, MACOS X...), among the most commonly available today.
      <ul>
	<li>
	  The <b>first target</b> we want to address is being able to backup and restore a whole system
	  from a minimal environment without assistance of an already existing local server (disaster context).
	</li>
	<li>
	  The <b>second target</b> is being able to securely keep for the long term an archived data. Securely here means having the ability to detect data corruption and limit its impact on the rest of the archive.
	</li>
      </ul>
      Both targets may need compression and ciphering inside backup depending on the context (public cloud storage, removable media, ...), limited storage space.
    </p>
    <p>
      Backup softwares that requires servers already running
      on the local network (For examples <i>Bacula</i>, <i>Amanda</i>, <i>Bareos</i>, <i>UrBackup</i>, <i>Burp</i>...) cannot
      adress our first target as we would have first to reconstruct such server in
      case of disaster (from what then?) in order be able to restore our system and its data.
    </p>
    <p>
      Partition cloning systems (<i>clonezilla</i>, <i>MondoRescue</i>, <i>RescueZilla</i>,
      <i>partclone</i>, <i>dump</i> and consorts) are targetted at block copy and as such cannot backup a live system:
      you have to shutdown and boot on a CD/USB key or run in single user-mode in order to "backup". This cannot
      be automated and has a strongly impact on the user as she/he has to interrupt her/his work during the whole
      backup operation.
    <p>
      Looking at the remaining backup tools, with or without Graphical User Interface, most of them
      rely on one of the three backend softwares, <i>tar</i>, <i>rsync</i> and <i>dar</i>:
    </p>
    <ul>
      <li>Software based on <b>dar</b>: gdar, DarGUI, Baras, Darbup, Darbrrd, HUbackup, SaraB...</li>
      <li>Software based on <b>rsync</b>: TimeShift, rsnapshot... </li>
      <li>Software based on <b>tar</b>: BackupPC, Duplicity, fwbackups... </li>
    </ul>
    <p>
      We will thus compare these three softwares for the different test famillies described below.
    </p>

    <h2>Tests Famillies</h2>
    <p>
      Several aspects need to consider:
    </p>
    <lu>
      <li><b>completness</b> of the restoration: file permissions, dates precision, hardlinks, file attributes, Extended Attributes, sparse files...</li>
      <li><b>main features</b> around backup: differential backup, snapshot, deduplication, compression, encrytion, file's history...</li>
      <li><b>robustness</b> of the backup: how data corruption impact the backup, how it is reported...</li>
      <li><b>execution performance</b>: execution time, memory consumption, multi-threading support...</li>
    </lu>
    <p>
      <b><u>Hardware used for Testing</u></b>
    </p>

    <p>
      Performance tests has been performed on an <a href="https://www.hpe.com">HPE</a> Proliant server
      (a <i>ProLiant XL230a Gen9</i> running two <i>Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz</i> processors) running
      a Devuan beowulf Linux system and also on a <a href="https://www.proxmox.com/en/">Proxmox</a>
      Virtual Machine running a FreeBSD 12.1 on an <i>Intel Core i5-7400 (3 GHz)</i> based computer.
    </p>

    <h2>Benchmark Results</h2>

    <p>
      The results presented here are a synthesis of the test logs provided in appendix. They are in turn summarized in conclusion of this document.
    </p>

    <h3>Completness of backup and restoration</h3>

    <table class=center>
      <tr>
	<th>Software</th>
	<th>plain file</th>
	<th>symlink</th>
	<th>hardlinked files</th>
	<th>hardlinked sockets</th>
	<th>hardlinked pipes</th>
	<th>user</th>
	<th>group</th>
	<th>perm.</th>
	<th>ACL</th>
	<th>Extended Attributes</th>
	<th>FS Attributes</th>
	<th>atime</th>
	<th>mtime</th>
	<th>ctime</th>
	<th>btime</th>
	<th>Spares File</th>
	<th>Disk usage optimization</th>
      </tr>
      <tr>
	<td>Dar</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>-</td>
	<td>yes(1)</td>
	<td>yes</td>
	<td>yes</td>
      </tr>
      <tr>
	<td>Rsync</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes(4)</td>
	<td>yes(5)</td>
	<td>-</td>
	<td>-</td>
	<td>yes</td>
	<td>-</td>
	<td>yes(1)</td>
	<td>yes(6)</td>
	<td>yes(6)</td>
      </tr>
      <tr>
	<td>Tar</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>- <i>(2)</i></td>
	<td>-</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes</td>
	<td>yes(7)</td>
	<td>yes(8)</td>
	<td>-</td>
	<td>-</td>
	<td>yes(3)</td>
	<td>-</td>
	<td>yes(1)</td>
	<td>yes(6)</td>
	<td>-</td>
      </tr>
    </table>
    <ul>
      <li>(1) "Yes" under MACoS X, FreeBSD and BSD systems. As of today (year 2020), Linux has no way to set the <i>btime</i> aka <i>birthtime</i> or yet <i>creation time</i></li>
      <li>(2) <i>tar</i> does even not save and restore plain normal sockets, but that's not a big issue in fact as Unix sockets should be recreated by the applications that provide corresponding service</li>
      <li>(3) unless <code>--xattrs</code> is provided, <i>mtime</i> is saved by <i>tar</i> but with an accuracy of only 1 second, while today's systems provide nanosecond precision</li>
      <li>(4) needs -A option</li>
      <li>(5) needs -X option</li>
      <li>(6) needs -S option</li>
      <li>(7) needs --acl option</li>
      <li>(8) needs --xattrs option</li>
    </ul>
    </p>

    <h3>Feature set</h3>

    <p>
      In addition to the exhaustivity of the restored data (seen above), several features are a
      <i>must have</i> when creating backups. Their description and what they bring to a backup process
      is provided below, followed by a table of how they are supported on the different softwares under test:
    </p>

    <dl>
      <dt>Historization</dt><dd>
	Historization is the ability to restore a deleted file even long after the mistake has been made by
	rotating backups over an arbitrary large number of backup set. Having associated tools
	to quickly locate the backup where resides a particular file's version becomes important
	when the history increases. Historization can be done with only full backups, but of course better
	leverages differential and incremental backups.
      </dd>
      <br/>

      <dt>Data filtering</dt><dd>
	Not all files need to be saved:
	<ul>
	  <li>
	    some <b>directories</b> (like <code>/tmp, /proc, /sys, /dev, /home/*/.cache</code>) are useless to save
	  </li>
	  <li>
	    some <b>files</b> based on their name or part of their name --- their extension for
	    example, (like emacs's backup files <code>*~</code> or your music files<code>*.mp3</code> you already
	    have archives somewhere, and so on) need not to be saved neither.
	  </li>
	  <li>
	    You may wish to ignore files located one or more particular <b>mounted filesystem</b>, or at the
	    opposite, only consider certains volume/disk/mounted filesystem and ignore all others, and have different
	    backup rotation cycles for those.
	  </li>
	  <li>
	    You may also find better to <b>tag</b> files one by one (manually by mean of an automated process of
	    your own), to be excluded from or included in the backup
	  </li>
	  <li>
	    Instead of tagging you could also let a process define a long <b>file listing</b> to backup and/or to ignore.
	  </li>
	  <li>
	    Last, you may well need a mix of several of these mechanisms at the same time
	  </li>
      </dd>
      <br/>

      <dt>Slicing (or multi-volume)</dt><dd>
	Having a backup split into several files of given max size can address several needs:
	<ul>
	  <li>hold the backup on several removal media (CD, DVD, USB keys...) smaller than the backup itself</li>
	  <li>transfer the backup from a large space to another by mean of a smaller removable media</li>
	  <li>transfer the backup over the network and recover at the last transmitted slice rather than restarting the whole
	    transfer in case of network issue</li>
	  <li>store the backup int the cloud where the provider limits the file size</li>
	  <li>be able to restore a backup on a system where storage space cannot hold both the backup and the restored system</li>
	  <li>transfer back from the cloud only a few slices to restore some files, when cloud provider does not provide adhoc protocols (sftp, ftp, ...) but only a user web based interface</li>
	</ul>
	Of course, multi-volume is really interesting if you don't have to concatenate all the slices to be able to have a usable backup.
	<br/>
	<br/>
	Last the previously identified use cases for backup slicing turn around limited storage space, thus having compression available when
	multi-volume is used is a key point here.
      </dd>
      <br/>

      <dt>Symmetric strong encryption</dt><dd>
	Symmetric strong encryption is the ability to cipher a backup with a password or passphrase and use that same key to decipher it. Some
	well known algorithms in this area are AES, blowfish, camellia...
	<br/>
	Symmetric strong encryption is interesting for the following cases:
	<ul>
	  <li>if your disk is ciphered, would you store your backup in clear on the cloud?</li>
	  <li>you do not trust your cloud provider to not inspect your data and make marketing profile of yourself with it.</li>
	  <li>You want to prevent your patented data or industrial secret recipies from falling into the competition's hands or goverment agencies that could clone it without fear of being prosecuted. This use case applies whether your backup is stored on local disk, removable media or public cloud.</li>
	  <li>Simply because in your country, you have the right and the freedom to have privacy.</li>
	  <li>Because your today democratic country could tomorrow verse into a dictatorship and based on some arbitrary criteria,
	    (belief, political opinion, sexual orientation...) you could suffer tomorrow from having this information having been accessible
	    today to the authorities or even having been publicly released, while you still need backup using arbitrary storage medium.
	  </li>
	</ul>
      </dd>
      <br/>

      <dt>Asymmetric strong encryption</dt><dd>
	Asymmetrical strong encryption is the ability to cipher a backup with a public key and having the corresponding private key for deciphering it (PGP, GnuPG...).
	<br/>
	Asymmetric encrypion is mainly interesting when exchanging data over Internet between different persons, or eventually for archiving data in the public cloud.
	Having it for backup seems not appropriate and is more complex than symmetric strong encryption, as restoration requires
	the private key, which thus must be stored outside the backup itself still be protected from unauthorized access.
	The private key use can still be protected with a password or a passphrase
	but this gives the same feature level as symmetrical encryption with a more complex process and not much more security.
      </dd>
      <br/>

      <dt>Protection against plain-text attack</dt>
      <dd>Ciphering data must be done with a minimum level of security, in particular when the ciphered data has well defined
	structure and patterns, like a backup file format is expected to have. Knowing such expected structure of the clear data
	may lead an attacker to undisclose the whole ciphered data. This is known as <i>plain-text attack</i>.
      </dd>
      <br/>

      <dt>Key derivation function</dt><dd>
	<ul>
	  <li>
	    Using the same password/passphrase for different backups is convenient but not secure. Having a key derivation function
	    using a <i>salt</i> let you use the same password/passphrase while the data will be encrypted with a different key each time,
	    this is the role of the <i>Key Derivation Function (KDF)</i> (PKCS5/PBKDF2, Argon2...).
	  </li>
	  <li>
	    Another need for a KDF is that usually the human provided
	    password/passphrase are weak: Even when we use letters, digits and some special characters, passwords and passphrases are still located in a
	    small area of possible keys that a <i>dictionnary attack</i> can leverage. As the KDF is also by design CPU intensive,
	    it costs a lot of effort and time to an attacker to derive each word of a dictionnary to its resulting KDF transformed words.
	    The required time to perform a dictionnary attack can thus be multiplied by several hundred thousand times,
	    leading to an effective time of tens of years and even centuries rather than hours or days.
	  </li>
      </dd>
      <br/>

      <dt>File change detection</dt><dd>
	When backing up a live system, it is important to detect, retry saving or flag files that changed during the time
	they were read for backup. In such situation, the backed file could be recorded in a state it never had: As the backup process
	reads sequentially from the beginning to the end, if a modification <i>A</i> is done at the end of file then a
	modification <i>B</i> is made at its beginning during this file's backup, the backup may contain <i>B</i> and not <i>A</i>
	while at not time
	the file contained <i>B</i> without <i>A</i>. Seen the short time a file can be read, time accuracy of micro or nanoseconds
	is mandatory to detect such file change during a backup process, else you will screw up your data in the backup and have nothing
	to rely on in the occurence of a deleted file by mistake, disk crash or disaster.
	<br/>
	At restoration time, if the file has been saved anyway, it should be good to know the such file was not saved properly, maybe
	restoring a older version but a sane one would be better. Something the user/sysadmin cannot guess if the backup does not hold
	such type of information.
      </dd>
      <br/>

      <dt>Multi-level backup</dt><dd>
	Multi-level backup is the ability to make use of <b>full</b> backups, <b>differential</b> backups and/or eventually <b>incremental</b> backups.
	<br/>
	The advantage of differential and incremental backups compared to full ones is the much shorter time they require to complete
	and the reduces storage space and/or bandwidth they imply when transfered over the network.
      </dd>
      <br/>

      <dt>Binary delta</dt>
      <dd>Without binary delta, when performing a differential or incremental backup, if a file has changed since the previous
	backup, it will be resaved entirely. Some huge files made by some well know applications (mailboxes for example) would consume
	a lot of storage space and lead to a long backup time even when performing incremental or differential backups. Binary delta is
	the ability to only store the part of a file that changed since a reference state, this lead to important space gain and reduction
	of the backup duration.
      </dd>
      <br/>

      <dt>Detecting suspicious modifications</dt>
      <dd>When performing a backup based on a previous one (differential, incremental, decremental backups), it is possible
	to check the way the metadata of saved files have changed until then and warn the user when some uncommon pattens are met.
	Those may be the trace of a rootkit, virus, ransomware or trojan, trying to hide its presence and activities.
      </dd>
      <br/>

      <dt>Snapshot</dt><dd>
	A snapshot is like a differential backup made right after the full backup (no file has changed): it is a minimal
	set of information that can be used to:
	<ul>
	  <li>
	    create an incremental or differential backup without having the full backup around
	    or more generally the backup of reference: When backup are stored remotely, snapshot is a must.
	  </li>
	  <li>
	    compare the current living filesystem with a status it had at the time the snapshot was made
	  </li>
	  <li>
	    bring some metadata redundancy and repairing mean to face a corrupted backup
	  </li>
	</ul>
      </dd>
      <br/>

      <dt>On-fly hashing</dt><dd>
	On-fly hashing is the ability to generate a hashing of the backup at the same time it is generated and before it is written
	to storage. Such hash can be used to:
	<ul>
	  <li>validate a backup has been properly transfered to a public storage cloud having hash computation done in parallel</li>
	  <li>check that no data corruption has occured (doubt about disk or memory) even when the backup is written to local disk</li>
	</ul>
	Hashing validation is usually faster than backup testing or backup comparison, though it does not validate your ability
	to rely on the backup as deeply as these later operations. Hashing can be made after the backup has been completed but
	it will need to re-read the whole backup and you will have to wait for the necessary storage I/O for the operation to complete.
	On-fly hashing should leverage the fact the data is in memory so it saves the corresponding disk I/O and corresponding
	latency, thus it is much faster. As it is also done in memory it can help detect file corruption on the backup destination media
	(like USB keys or poor quality hardware).
      </dd>
      <br/>

      <dt>Run custom command during operation</dt><dd>
	For an automated backup process, it is often necessary to run commands before and after the backup operation itself.
	But also during the backup process. For example, when entering a directory, one could need to run an arbitrary command
	generating a file that will be included in the backup. Or while exiting such directory performing some cleanup operation in that same directory.
	Another use case is found when slicing the backup, by the ability to perform after each slice generation a custom operation like uploading the
	slice to cloud, burning to DVD-/+RW, loading a tape from a tape library...
      </dd>
      <br/>

      <dt>Dry-run execution</dt><dd>
	When tuning a backup process, it is often necessary to verify quickly that all will work flawlessly without having
	to wait for a backup to complete, consume storage resource and network bandwidth.
      </dd>
      <br/>

      <dt>User message within backup</dt><dd>
	Allowing the user to add an arbitrary message within the backup may be useful when the filename is too small
	to hold the needed information (like the context the backup or archive was made, hint for the passphrase... and so on).
      </dd>
      <br/>

      <dt>Backup sanity test</dt><dd>
	It is crutial in a backup process to validate that the generated
	backup is usable. There are many reasons it could not be the case, from
	a data corruption in memory, on disk or over the network ; a disk space saturation
	leading to truncated backup, down to a software bug.
      </dd>
      <br/>

      <dt>Comparing with original data</dt><dd>
	One step further for backup and archiving validation is compairing file content and metadata with the system it has.
      </dd>
      <br/>

      <dt>Tunable verbosity</dt><dd>
	When a backup process is in production and works nicely, it is usually interesting to have the minimal output possible
	for that any error still be possible to log. While when setting up a backup process, having more detailed
	information is required to understand and validate that the backup process follows the expected path.
      </dd>
      <br/>

      <dt>Modify the backup's content</dt><dd>
	Once a backup has been completed, you might notice that you have saved extra files you ought not to save. Being able to drop
	them from the backup to save some space without having to restart the whole backup may lead to a huge time saving.
	<br/>
	<br/>
	You might also need to add some extra files that were outside the backup scope, having the possibility to add them
	without restarting the whole backup process may also lead to a huge time saving.
      </dd>
      <br/>

      <dt>Stdin/stdout backup read/write</dt><dd>
	Having the ability to pipe the generated backup to an arbitrary command is on of the ultimate key of
	backup software flexibility.
      </dd>
      <br/>

      <dt>Remote network storage</dt><dd>
	This is the ability to produce directly a backup to a network storage without using local disk, and to
	be able to restore directly reading a backup from the such remote storage still without using local storage.
	<i>Network/Remote storage</i> is to be understood as remote network storage like public cloud, private cloud,
	personal NAS... that are accesible from the network by mean of a file transfer protocols (scp, sftp, ftp,
	rcp, http, https...)
      </dd>
      <br/>

    </dl>

    <table class=center>
      <tr class=center>
	<th width="40%">Feature</th>
	<th width="20%">Dar</th>
	<th width="20%">Rsync</th>
	<th width="20%">Tar</th>
      <tr>
      <tr>
	<th class=left>Historization</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Data filtering by directory</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Data filtering by filename</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Data filtering by filesystem</th>
	<td>Yes</td>
	<td>limited</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Data filtering by tag</th>
	<td>limited</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>Data filtering by files listing</th>
	<td>Yes</td>
	<td>yes</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Slicing/multi-volume</th>
	<td>Yes</td>
	<td>-</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Symmetric encryption</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Asymmetric encryption</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Plain-text attack protection</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>PBKDF2 Key Derivation Function</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>ARGON2 Key Derivation Function</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>File change detection</th>
	<td>Yes</td>
	<td>-</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Multi-level backup</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Binary delta</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>Detecting suspicious modifications</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>Snapshot for diff/incr. backup</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Snapshot for comparing</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>Snapshot for redundancy</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>On-fly hashing</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>Run custom command during operation</th>
	<td>Yes</td>
	<td>-</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Dry-run execution</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>User message within backup</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
      </tr>
      <tr>
	<th class=left>Backup sanity test</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Comparing with original data</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Tunable verbosity</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Modify the backup's content</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>limited</td>
      </tr>
      <tr>
	<th class=left>Stdin/stdout backup read/write</th>
	<td>Yes</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Remote network storage</th>
	<td>Yes</td>
	<td>limited</td>
	<td>Yes</td>
      </tr>
    </table>

    <p>
      The presented results above is a synthesis of the tests detailed in appendix.
    </p>

    <h3>Robustness</h3>

    <p>
      The objectif here is to see how a minor data corruption can impacts the backup. Such type of
      corruption (a single bit invertion) can be caused by network transfert, cosmic particle hitting
      the memory bank, or simply due to the time passing stored on a particular medium. In real life
      data corruption may impact more than one bit, right. But if the ability to workaround the corruption of a
      single bit does not bring any information about the ability to recover larger volume
      of data corruption, the <u>inability</u> to recover a single bit, is enough to know that the same software
      will behave even worse when larger portion of data corruption will be met.
    </p>

    <table class=center>
      <tr>
	<th style="min-width:30%">Behavior</th>
	<th style="min-width:10%">Dar</th>
	<th style="min-width:10%">Rsync</th>
	<th style="min-width:10%">Tar alone</th>
	<th style="min-width:10%">Tar + gzip</th>
      </tr>
      <tr>
	<th class=left>Detects backup corruption</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
	<td>Yes</td>
      </tr>
      <tr>
	<th class=left>Warn or avoid restoring corrupted data</th>
	<td>Yes</td>
	<td>-</td>
	<td>-</td>
	<td>Yes</td>
      <tr>
      <tr>
	<th class=left>Able to restore all files not concerned by the corruption</th>
	<td>Yes</td>
	<td>Yes</td>
	<td>Yes</td>
	<td>-</td>
      </tr>
    </table>

    <p>
      To protect your data, you can go one step further computing data redundancy with <a href="https://github.com/Parchive/par2cmdline">Parchive</a>
      on top of your backup or archives. This will allow you to repair them in case of corruption.
      <ul>
	<li>
	  Though, <i>rsync</i> is not adapted to that process as creating a global redundancy of a directory tree is much more complex, error-prone.
	  At the opposite, <i>tar</i> and <i>dar</i> are pretty well adapted as a backup may
	  be is a single file or a few big files if using slicing or multi-volume backup.
	</li>
	<li>
	  Second, whatever is the redundancy level you select, if the data corruption exceed this level, you will not be able to repair your backups and
	  archives. Thus, better relying on a robust and redundant backup file structure, and here <i>dar</i> has some big advantages.
	</li>
	<li>
	  Last, if execution time is important for you, having a sliced backup with a slice size smaller than the available RAM
	  and running <i>Parchive</i> right after each slice created, will save a lot of disk I/O and can <b>speed up the overall process
	  by more than 40%</b>. But here too, only <i>dar</i> provides this possibility.
	</li>
      </ul>
    </p>

    <p>
      The presented results above is a synthesis of the tests detailed in appendix.
    </p>

    <h3>Performance</h3>

    <p>
      In the following, we have distinguished two purpose of backup tools: the "identical" copy of a set of files and directories (short term operation) and the
      usual backup operation (long term storage and historization).
    </p>

    <h4>Performance of file copy operation</h4>

    <p>
      The performance aspect to consider for this target is exclusively the execution speed, this may imply data reduction
      on the wire only if the bandwidth is low enough for the compression processing time added does not ruine the gain on
      transfer time. Compression time is not dependent on the backup tool but on the data, and we will see in the backup
      performances tests, the way the different backup tools do reduce data on the wire. For the execution time we get the following
      results:
    </p>

    <h5>Single huge file</h5>
    <p>The copied data was a Linux distro installation ISO file</p>

    <div class="cadre">
      <div class="gauge best" style="width: 17%;">cp: 2.58 s</div>
      <div class="gauge normal" style="width: 61%;">Dar: 9.18 s</div>
      <div class="gauge normal" style="width: 100%">Rsync: 15.28 s</div>
      <div class="gauge normal" style="width: 43%">Tar: 6.51 s</div>
    </div>

    <h5>Linux system</h5>

    <p>The copied data was a fresh fully featured Linux installed system</p>

    <div class="cadre">
      <div class="gauge best" style="width: 31%;">cp: 5.15 s</div>
      <div class="gauge normal" style="width: 100%;">Dar: 16.78 s</div>
      <div class="gauge normal" style="width: 99%">Rsync: 16.59 s</div>
      <div class="gauge normal" style="width: 48%">Tar: 8.04 s</div>
    </div>

    <h5>Conclusion</h5>
    <p>
      for local copy <b><i>cp</i></b> is the fastest but totally unusable for remote copy. At first sight one could think
      <i>tar</i> would be the best alternative for remote copy, but that would not take into account the fact you will probably want
      to use secured connection (unless all segments of the underlying network are physically yours, end to end). Thus once the
      backup will be generated, using <i>tar</i> will require an extra user operation, extra computing time to cipher/decipher and time to
      transfer the data while both alternatives, <i>rsync</i> and <i>dar</i>, have it integrated: they can copy and transfer at the
      same time, with both the gain of time and the absence of added operations for the user.
    </p>
    <p>
      In consequence, for remote copy, if this is for a unique/single remote copy, <b><i>dar</i></b> will be faster than <i>rsync</i> most of the time
      (even when using compression to cope with low bandwidth, see the backup test results, below). But for recurring remote copy even if <b><i>rsync</i></b> is not faster that
      <i>dar</i>, it has the advantage  of being designed espetially for this task as in that context we do not need to store the data compressed nor ciphered.
      Things we can summarize as follows:
    </p>

    <table class=center>
      <tr>
	<th>Operation</th>
	<th>Best Choice</th>
	<th>Alternative</th>
      </tr>
      <tr>
	<th class=left>Local copy</th>
	<td>cp</td>
	<td>tar</td>
      </tr>
      <tr>
	<th class=left>One-time remote copy</th>
	<td>dar</td>
	<td>rsync</td>
      </tr>
      <tr>
	<th class=left>recurrent remote copy</th>
	<td>rsync</td>
	<td>dar</td>
      </tr>
    </table>

    <h4>Performance of backup operation</h4>
    <p>
      For backup we consider the following criteria by order of importance:
    </p>
    <ol>
      <li>data reduction on backup storage</li>
      <li>data reduction when transmitted over the network</li>
      <li>execution time to restore a few files</li>
      <li>execution time to restore a full and differential backups</li>
      <li>execution time to create a full and differential backups</li>
    </ol>
    <p>
      Why this order?
    </p>
    <ul>
      <li>
	Because usually backup creation is done at low priority in background and
	on a day to day basis, the execution time is less important than reducing the storage usage: reducing storage usage gives longer
	backup history and increases the ability
	to recover accidentically removed files much later after the mistake has been done (which may be detected
	weeks or months afteward).
      </li>
      <li>
	Next, while your backup storage can be anything,
	including low cost or high end dedicated one, we see more and more frequently externalized backups, which main declinaison
	is based on public cloud storage, leading to relatively cheap disaster recovery solution. However, your WAN/Internet acces will
	be drained by the backup volumes flying away and you probably don't want them to consume too much of this bandwidth which could
	slow down your business or Internet access. As a workaround, one could rate-limit the bandwidth for backup exchanges only. But doing
	so will extend the backup transfer time so much that you may have to reduce the backup frequency to not have two backup
	transfered at the same time. This would lead you to lose data accuracy of saved data: A too low backup frequency will only allow you
	to restore your systems in the state they had several days instead of several hours or several tens of minutes, before the disaster
	occured. For that reason data reduction on the wire is the second criterium. Note that data reduction on storage
	usually implies data reduction on the wire, but the opposite is not always true, depending on the backup tool.
      </li>
      <li>
	Next, it is much more frequent to have
	to restore a few files (corrupted or deleted by mistake) and we need this to be quick because this is an interactive operation and
	that the missing data is mandatory to go forward for one's work, which workflow may impact several other persons.
      </li>
      <li>
	The least frequent operation (hopefully) is the restoration of a whole system
	in case of disaster. Having it performing quick is of course important, but less than having a complete, robust, accurate and
	recent backup somewhere, that you can count on to restore your systems in the most recent possible state.
      </li>
    </ul>
    <p>
      Note that the following result do not take into account the performance penalty implied by the
      <b>network latency</b>. Several reasons to that:
    </p>
    <ul>
      <li>
	it would not measure the software performance but the network bandwidth and latency which is not the object
	of this benchmark and may vary with distance, link layer technology and number of devices crossed,
      </li>
      <li>
	We can assume the network penalty to be proportional to data processed by each software, as all protocol used are usually TCP based
	(ftp, sftp, scp, ssh, ...), which performance is related to the system parameters (window size, MTU, etc.) not to the backup software
	itself. As we only rely on tmpfs
	filesystems to avoid dependency on disk I/O latency, we may approximate that the network latency or a reduction of network bandwidth would
	just inflate the relative execution time of the different tested softwares in a linear manner. In other words, adding network between
	system and backup storage should thus not modify the relative performances of the softwares under test.
      </li>
    </ul>
    <p>
      For all the backup performance tests that follow (but not for file copy performance tests seen above),
      compression has been used using the same and most commonly
      supported algorithm: gzip at level 6. Other algorithm can complete faster or provide better compression ratio, but this is linked to
      chosen compression algorithm and data to compress, not to the backup tools tested here.
    </p>


    <h4>Data reduction on backup storage</h4>

    <h5>Full backup</h5>

    <div class="cadre">
      <div class="gauge normal" style="width: 38%;">Dar: 1580562224 bytes</div>
      <div class="gauge normal" style="width: 38%">Dar+sparse: 1578428790 bytes</div>
      <div class="gauge normal" style="width: 39%">Dar+sparse+binary delta: 1602481058 bytes</div>
      <div class="gauge normal" style="width: 100%">Rsync: 4136318307 bytes</div>
      <div class="gauge normal" style="width: 100%">Rsync+sparse: 4136318307 bytes</div>
      <div class="gauge normal" style="width: 37%">tar: 1549799048 bytes</div>
      <div class="gauge best" style="width: 37%">tar+sparse: 1549577862 bytes</div>
    </div>

    <h5>Differential backup</h5>

    <div class="cadre">
      <div class="gauge normal" style="width: 100%;">Dar: 49498524 bytes</div>
      <div class="gauge normal" style="width: 100%">Dar+sparse: 49505251 bytes</div>
      <div class="gauge best" style="width: 48%">Dar+sparse+binary delta: 23883368 bytes</div>
      <div class="gauge ref" style="width: 100%">Rsync: not supported</div>
      <div class="gauge ref" style="width: 100%">Rsync+sparse: not supported</div>
      <div class="gauge normal" style="width: 90%">tar: 44607904 bytes</div>
      <div class="gauge normal" style="width: 90%">tar+sparse: 44604194 bytes</div>
    </div>

    <h5>Full + Differential backup</h5>
    <p>
      This is a extrapolation of the required volume for backup, after one week of daily backup of the Linux system
      under test, assuming the activity is as minimal each day as it was here between the initial day of the
      full backup and the day of the first differential backup (a few package upgrade and no user activity).
    </p>

    <div class="cadre">
      <div class="gauge normal" style="width: 100%;">Dar: 1927051892 bytes</div>
      <div class="gauge normal" style="width: 100%">Dar+sparse: 1924965547 bytes</div>
      <div class="gauge best" style="width: 92%">Dar+sparse+binary delta: 1769664634 bytes</div>
      <div class="gauge ref" style="width: 100%">Rsync: not supported</div>
      <div class="gauge ref" style="width: 100%">Rsync+sparse: not supported</div>
      <div class="gauge normal" style="width: 97%">tar: 1862054376 bytes</div>
      <div class="gauge normal" style="width: 97%">tar+sparse: 1861807220 bytes</div>
    </div>

    <p>
      This previous results concerns the backup of a steady Linux system, relative difference of data reduction might favorize both <i>rsync</i>
      and <i>dar+binary delta</i> when the proportion of large files being slightly modified increases (like mailboxe files).
    </p>


    <h4>Data reduction over network</h4>

    <h5>Full backup</h5>

    <div class="cadre">
      <div class="gauge normal" style="width: 99%;">Dar: 1580562224 bytes</div>
      <div class="gauge normal" style="width: 98%">Dar+sparse: 1578428790 bytes</div>
      <div class="gauge normal" style="width: 100%">Dar+sparse+binary delta: 1602481058 bytes</div>
      <div class="gauge normal" style="width: 99%">Rsync: 1587714486 bytes</div>
      <div class="gauge normal" style="width: 99%">Rsync+sparse: 1587714474 bytes</div>
      <div class="gauge normal" style="width: 97%">tar: 1549799048 bytes</div>
      <div class="gauge best" style="width: 97%">tar+sparse: 1549577862 bytes</div>
    </div>

    <h5>Differential backup</h5>

    <div class="cadre">
      <div class="gauge normal" style="width: 100%;">Dar: 49498524 bytes</div>
      <div class="gauge normal" style="width: 100%">Dar+sparse: 49505251 bytes</div>
      <div class="gauge best" style="width: 48%">Dar+sparse+binary delta: 23883368 bytes</div>
      <div class="gauge normal" style="width: 59%">Rsync: 29293958 bytes</div>
      <div class="gauge normal" style="width: 59%">Rsync+sparse: 29293958 bytes</div>
      <div class="gauge normal" style="width: 90%">tar: 44607904 bytes</div>
      <div class="gauge normal" style="width: 90%">tar+sparse: 44604194 bytes</div>
    </div>

    <h5>Full + Differential backup</h5>
    <p>
      This is the same extrapolation done above (one week of daily backup), but for the volume of data transmitted over the network instead of the backup volume on storage.
    </p>

    <div class="cadre">
      <div class="gauge normal" style="width: 100%;">Dar: 1927051892 bytes</div>
      <div class="gauge normal" style="width: 100%">Dar+sparse: 1924965547 bytes</div>
      <div class="gauge best" style="width: 92%">Dar+sparse+binary delta: 1769664634 bytes</div>
      <div class="gauge normal" style="width: 93%">Rsync: 1792772192 bytes</div>
      <div class="gauge normal" style="width: 93%">Rsync+sparse: 1792772180 bytes</div>
      <div class="gauge normal" style="width: 97%">tar: 1862054376 bytes</div>
      <div class="gauge normal" style="width: 97%">tar+sparse: 1861807220 bytes</div>
    </div>

    <h4>Execution time to restore a few files</h4>
    <div class="cadre">
      <div class="gauge normal" style="width: 3.9%;">Dar: 0.98 s</div>
      <div class="gauge normal" style="width: 4.49%">Dar+sparse: 1.13 s</div>
      <div class="gauge normal" style="width: 5.05%">Dar+sparse+binary delta: 1.27 s</div>
      <div class="gauge best" style="width: 0.01%">Rsync: 3 ms</div>
      <div class="gauge best" style="width: 1%">Rsync+sparse: 3 ms</div>
      <div class="gauge normal" style="width: 100%">tar: 25.15 s </div>
      <div class="gauge normal" style="width: 99%">tar+sparse: 25 s</div>
    </div>
    <p>
      Here the phenomenum is even more important when the file to restore is located near the end of the <i>tar</i> backup,
      as <i>tar</i> sequentially reads the whole backup up to the requested file.
    </p>


    <h4>Execution time to restore a whole system - full backup</h4>
    <div class="cadre">
      <div class="gauge best" style="width: 14.48%;">Dar: 22.94 s</div>
      <div class="gauge normal" style="width: 19.17%">Dar+sparse: 30.36 s</div>
      <div class="gauge normal" style="width: 19.16%">Dar+sparse+binary delta: 30.35 s</div>
      <div class="gauge normal" style="width: 99.63%">Rsync: 157.81 s</div>
      <div class="gauge normal" style="width: 100%">Rsync+sparse: 158.39 s</div>
      <div class="gauge normal" style="width: 16.87%">tar: 26.72 s </div>
      <div class="gauge normal" style="width: 16.59%">tar+sparse: 26.27 s</div>
    </div>

    <h4>Execution time to restore a single differential backup</h4>
    <div class="cadre">
      <div class="gauge normal" style="width: 100%;">Dar: 3.48 s</div>
      <div class="gauge normal" style="width: 100%">Dar+sparse: 3.48 s</div>
      <div class="gauge normal" style="width: 98.85%">Dar+sparse+binary delta: 3.44 s</div>
      <div class="gauge ref" style="width: 100%">Rsync: not supported</div>
      <div class="gauge ref" style="width: 100%">Rsync+sparse: not supported</div>
      <div class="gauge normal" style="width: 42.53%">tar: 1.48 s </div>
      <div class="gauge normal" style="width: 43.1%">tar+sparse: 1.5 s</div>
    </div>

    <h4>Execution time to restore a whole system - full + differential backup</h4>
    <p>
      We use here the same extrapolation a week of daily backup done above: the first backup being a full backup
      and differential/incremental backups done the next days.
    </p>

    <p>
      <u>Clarifying the terms used:</u> the <u>differential</u> backup saves only what has changed since the full backup
      was made. The consequence is that each day the backup is slightlty bigger to process, depending on the
      way data changed (if all files change every day, like mailboxes, user files, ...) each new differential backup will have the same size
      and take the same processing time to complete.
      At the opposite, if new data is added each day, the differential backup size will be each day the sum of the <i>incremental</i>
      backups that could be done instead since the full backup.
    </p>
    <p>
      At the difference of the differential backup, the <u>incremental</u> backup saves only what has changed
      since the last backup (full or incremental). For constant activity like the steady Linux system we used here, the incremental
      backup size should be the same along the time (and equivalent to the size of the first differential backup), thus the extrapolation is easy
      and not questionable: the restoration time is the time to restore the full and the time to restore the first differential backup times
      the number of days that passed.
    </p>

    <h4>Execution time to restore a whole system - lower bound</h4>

    <p>
      The lower bound, is the sum of the execution time of the restoration of the full backup and one differential backup
      seen just above. It corresponds the minimum execution time restoring a whole system from full+differnential backup.
    </p>
    <div class="cadre">
      <div class="gauge best" style="width: 16.68%;">Dar: 26.42 s</div>
      <div class="gauge normal" style="width: 21.36%">Dar+sparse: 33.84 s</div>
      <div class="gauge normal" style="width: 21.33%">Dar+sparse+binary delta: 33.79 s</div>
      <div class="gauge ref" style="width: 99.63%">Rsync: full backup only 157.81 s</div>
      <div class="gauge ref" style="width: 100%">Rsync+sparse: full backup only 158.39</div>
      <div class="gauge normal" style="width: 17.80%">tar: 28.2 s</div>
      <div class="gauge normal" style="width: 17.53%">tar+sparse: 27.77 s</div>
    </div>

    <h4>Execution time to restore a whole system - higher bound</h4>

    <p>
      The higher bound, is the sum of the execution time of the restoration plus seven times the execution time of the differential
      backup. It corresponds the worse case scenario where each day new data is added (still using a steady Linux system with constant activity).
      It also corresponds the scenario of restoring a whole system from a full+incremental backups (7 incremental backup have to be restored, in
      that week span scenario):

    </p>
    <div class="cadre">
      <div class="gauge normal" style="width: 29.86%;">Dar: 47.3 s</div>
      <div class="gauge normal" style="width: 34.55%">Dar+sparse: 54.72 s</div>
      <div class="gauge normal" style="width: 34.36%">Dar+sparse+binary delta: 54.43 s</div>
      <div class="gauge ref" style="width: 99.63%">Rsync: full backup only 157.81 s</div>
      <div class="gauge ref" style="width: 100%">Rsync+sparse: full backup only 158.39</div>
      <div class="gauge normal" style="width: 23.41%">tar: 37.08 s </div>
      <div class="gauge best" style="width: 23.21%">tar+sparse: 36.77 s</div>
    </div>



    <h4>Execution time to create a backup</h4>

    <div class="cadre">
      <div class="gauge normal" style="width: 81.62%;">Dar: 149.73 s</div>
      <div class="gauge normal" style="width: 86.13%">Dar+sparse: 157.99 s</div>
      <div class="gauge normal" style="width: 88.65%">Dar+sparse+binary delta: 162.62 s</div>
      <div class="gauge normal" style="width: 85.58%">Rsync: 156.98 s</div>
      <div class="gauge normal" style="width: 100%">Rsync+sparse: 183.44 s</div>
      <div class="gauge best" style="width: 81%">tar: 148.59 s </div>
      <div class="gauge normal" style="width: 81.43%">tar+sparse: 149.38 s</div>
    </div>

    <h4>Ciphering/deciphering performance</h4>
    <p>
      There is several reasons that implies the need of ciphering data:
    </p>
    <ul>
      <li>if your disk is ciphered, would you store your backup in clear on the cloud?</li>
      <li>do you trust you cloud provider to not inspect your data for marketing profiling?</li>
      <li>Are you sure your patented data, secret industrial recipies will not be used by competition?</li>
      <li>and so on</li>
    </ul>
    <p>
      The ciphering execution time is independent on the nature of the backup, full or differential, compressed
      or not. To evaluate the ciphering performance we will use the same data sets as previously, both compressed
      and uncompressed. However not all software under test are able to cipher the resulting backup. <i>rsync</i>
      is not able to do so.
    </p>

    <h5>Full backup+restoration execution time</h5>

    <div class="cadre">
      <div class="gauge normal" style="width: 100%">Dar: 9.13 s</div>
      <div class="gauge ref" style="width: 100%">Rsync: N/A</div>
      <div class="gauge best" style="width: 80.9%">Tar (openssl): 7.39 s</div>
    </div>

    <h5>Execution time for the restoration of a single file</h5>

    <div class="cadre">
      <div class="gauge best" style="width: 23.4%">Dar: 0.42 s</div>
      <div class="gauge ref" style="width: 100%">Rsync: N/A</div>
      <div class="gauge normal" style="width: 100%">Tar (openssl): 1.79 s</div>
    </div>

    <h5>Storage requirement ciphered without compression</h5>

    <div class="cadre">
      <div class="gauge best" style="width: 97.9%">Dar: 1.46 GiB</div>
      <div class="gauge ref" style="width: 100%">Rsync: N/A</div>
      <div class="gauge normal" style="width: 100%">Tar (openssl): 1.49 GiB</div>
    </div>


    <h2>Conclusion</h2>

    <p>
      So far we have measured perfomance, evaluated features, robusness and completness of the operation. We get a lot of
      results, but it would not be of a great use to anyone reading this document or the one just jumping to its conclusion to not
      get back to use cases and put these results in front:
    </p>
    <p>
      We can identify may uses cases around backup tools and each one has its one contraints and performance criteria:
    </p>

    <h3>Criteria for file copy use cases</h3>

    <table>
      <tr>
	<th>Use Cases</th>
	<th>Key Point</th>
	<th>Optional interesting features</th>
      </tr>
      <tr>
	<th>Local directory copy</th>
	<td>
	  <ul>
	    <li>execution speed</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>completness of copied data and metadata</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>remote directory copy - wide network</th>
	<td>
	  <ul>
	    <li>execution speed</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>completness of copied data and metadata</li>
	    <li>on wire ciphering</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>remote directory copy - narrow network</th>
	<td>
	  <ul>
	    <li>execution speed</li>
	    <li>data reduction on wire</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>completness of copied data and metadata</li>
	    <li>on wire ciphering</li>
	  </ul>
	</td>
      </tr>
    </table>

    <h3>Criteria for backup use cases</h3>

    <table>
      <tr>
	<th>Use Cases</th>
	<th>Key Point</th>
	<th>Optional interesting features</th>
      </tr>
      <tr>
	<th>Full backups only</th>
	<td>
	  <ul>
	    <li>completness of backed up data and metadata</li>
	    <li>data reduction on storage</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>fast restoration of a few files</li>
	    <li>fast restoration of a whole backup</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>full+diff/incr. backup</th>
	<td>
	  <ul>
	    <li>completness of backed up data and metadata</li>
	    <li>data reduced on storage</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>fast restoration of a few files</li>
	    <li>fast restoration of a whole backup</li>
	    <li>managing tool of backups rotation</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>Archiving of private data</th>
	<td>
	  <ul>
	    <li>data reduction on storage</li>
	    <li>robustness of the archive</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>ciphering</li>
	    <li>redundancy data</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>Archiving of public data</th>
	<td>
	  <ul>
	    <li>data reduction on storage</li>
	    <li>robustness of the archive</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>signing</li>
	    <li>fast decompression algorithm</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>Private data exchange over Internet</th>
	<td>
	  <ul>
	    <li>data reduction over the network</li>
	    <li>asymmetric encryption and signing</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>redundancy data</li>
	    <li>multi-volume backup/archive</li>
	    <li>integrated network protocols in backup tool</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>Public data exchange over Internet</th>
	<td>
	  <ul>
	    <li>data reduction over the network</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>hashing</li>
	    <li>sigining</li>
	    <li>integrated network protocols in backup tool</li>
	  </ul>
	</td>
      </tr>
    </table>


    <h3>Complementary criteria depending on the storage type</h3>
    <p>
      And depending on the target storage, the following adds on top:
    </p>

    <table>
      <tr>
	<th>Use Cases</th>
	<th>Key Point</th>
	<th>Optional interesting features</th>
      </tr>
      <th>Local disk</th>
      <td>
	<ul>
	  <li>execution speed</li>
	</ul>
      </td>
      <td>
	<ul>
	  <li>hashing</li>
	</ul>
      </td>
      <tr>
	<th>Data stored on private NAS</th>
	<td>
	  <ul>
	    <li>data reduction on storage</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>multi-volume backup</li>
	    <li>integrated network protocols in backup tool</li>
	    <li>ciphering</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>Data stored on public cloud</th>
	<td>
	  <ul>
	    <li>data reduction on storage and on wire</li>
	    <li>ciphering</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>multi-volumes backup</li>
	    <li>integrated network protocols in backup tool</li>
	  </ul>
	</td>
      </tr>
      <tr>
	<th>Data stored on removable media (incl. tapes)</th>
	<td>
	  <ul>
	    <li>multi-volume backup</li>
	    <li>data reduction on storage</li>
	    <li>on-fly hashing</li>
	  </ul>
	</td>
	<td>
	  <ul>
	    <li>ciphering</li>
	    <li>redundancy data</li>
	  </ul>
	</td>
      </tr>
    </table>


    <h3>Essential oil drop</h3>
    <p>
      In summary regarding the different use cases we have considered and the different caracteristics we tended to measure amont the backup tools we tested:
    </p>
    <ul>
      <li>exhasitivity of backed up data</li>
      <li>available features around backup</li>
      <li>backup robustness facing to media corruption</li>
      <li>overall performance</li>
    </ul>
    <p>
      We can summarize the best software to put in front each particular use case:
    </p>

    <table class=center>
      <tr>
	<th>Use Cases</th>
	<th>Local disk storage</th>
	<th>Private NAS</th>
	<th>Public Cloud</th>
	<th>Removable media</th>
      </tr>
      <tr>
	<th>Local directory copy</th>
	<td>
	  <div class=top>cp</div>
	  <div class="limited tooltip">dar <span class=text>not the fastest</span></div>
	  <div class="limited tooltip">rsync <span class=text>not the fastest</span></div>
	  <div class="ideal tooltip">tar <span class=text>not the fastest</span></div>
	</td>
	<td>
	  -
	</td>
	<td>
	  -
	</td>
	<td>
	  -
	</td>
      </tr>
      <tr>
	<th>One time remote directory copy</th>
	<td>
	  -
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="ideal tooltip">rsync<span class=text>not the fastest</wwspan></div>
	  <div class="limited tooltip">tar<span class=text>no network protocol embedded</span><br/>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="ideal tooltip">rsync<span class=text>not the fastest</span></div>
	  <div class="limited tooltip">tar<span class=text>no network protocol embedded</span></div>
	</td>
	<td>
	    <div class=top>dar</div>
	    <div class="ideal tooltip">rsync<span class=text>not the fastest</span></div>
	    <div class="limited tooltip">tar<span class=text>no network protocol embedded</div>
	</td>
      </tr>
      <tr>
	<th>Recurrent remote directory copy</th>
	<td>
	  -
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>fastest but automation is a bit less straight forward than using <i>rsync</i></span></div>
	  <div class="top">rsync</div>
	  <div class="limited tooltip">tar<span class=text>no network protocol embedded</span></div>
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>fastest but automation is a bit less straight forward than using <i>rsync</i></span></div>
	  <div class=top>rsync</div>
	  <div class="limited tooltip">tar<span class=text>no network protocol embedded</span></div>
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>fastest but automation is a bit less straight forward than using <i>rsync</i></span></div>
	  <div class=top>rsync</div>
	  <div class="limited tooltip">tar<span class=text>no network protocol embedded</span></div>
	</td>
      </tr>
      <tr>
	<th>Full backups only<br/>
	  (private data)</th>
	<td>
	  <div class="top tooltip">dar<span class=text>has the advantage to provide long historization of backups</span></div>
	  <div class="ideal tooltip">rsync<span class=text>no data reduction on storage, slow to restore a whole filesystem</span></div>
	  <div class="ideal tooltip">tar<span class=text>not saving all file attributes and inode types, slow to restore a few files</span><br/>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="limited tooltip">rsync<span class=text>no data reduction on storage</span></div>
	  <div class="ideal tooltip">tar<span class=text>not saving all file attributes and inode types, slow to restore a few files, no network protocol embedded</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>no data ciphering and no reduction on storage</span></div>
	  <div class="limited tooltip">tar<span class=text>not embedded ciphering, not the strongest data encryption, not saving all file attributes and inode types, slow to restore a few files, no network protocol embedded</wwspan></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="limited tooltip">rsync<span class=text>no multi-volume support, no data ciphering and no reduction on storage</span></div>
	  <div class="limited tooltip">tar<span class=text>compression and multi-volume are not supported at the same time, not saving all file attributes and inode types, not embedded ciphering, not the strongest data encryption, </span></div>
	</td>
      </tr>
      <tr>
	<th>full+diff/incr. backups<br/>
	  (priate data)
	</th>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>differential backup not supported, full backup is overwritten</span></div>
	  <div class="ideal tooltip">tar<span class=text>not saving all file attributes and inode types, slow to restore a few files</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>differential backup not supported, full backup is overwritten</span></div>
	  <div class="ideal tooltip">tar<span class=text>not saving all file attributes and inode types, slow to restore a few files, no network protocol embedded</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>differential backup not supported, full backup is overwritten</span></div>
	  <div class="limited tooltip">tar<span class=text>not embedded ciphering, not the strongest data encryption, not saving all file attributes and inode types, slow to restore a few files, no network protocol embedded</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>differential backup not supported, full backup is overwritten, no support for multi-volime, no data reduction, no ciphering</span></div>
	  <div class="limited tooltip">tar<span class=text>compression and multi-volume are not supported at the same time, not saving all file attributes and inode types, not embedded ciphering, not the strongest data encryption, </span></div>
	</td>
      </tr>
      <tr>
	<th>Archiving of private data</th>
	<td>
	  <div class=top>dar</div>
	  <div class="limited tooltip">rsync<span class=text>no data reduction on storage, no detection of data corruption, complex parity data addition</span></div>
	  <div class="ideal tooltip">tar<span class=text>no detection of data corruption or loss of all data after the first corruption met</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="limited tooltip">rsync<span class=text>no data reduction, no detection of data corruption, complex parity data addition</span></div>
	  <div class="ideal tooltip">tar<span class=text>no detection of data corruption or loss of all data after the first corruption met</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>no ciphering, no data reduction, no detection of data corruption, complex parity data addition</span></div>
	  <div class="limited tooltip">tar<span class=text>no detection of data corruption or loss of all data after the first corruption met, no embedded ciphering, no protection against plain-text attack</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>no data reduction, no multi-volume, no ciphering, no detection of data corruption, complex parity data addition</span></div>
	  <div class="noway tooltip">tar<span class=text>compression and multi-volume are not supported at the same time, no detection of data corruption or loss of all data after the first corruption met, no ciphering</span></div>
	</td>
      </tr>
      <tr>
	<th>Archiving of public data</th>
	<td>
	  <div class="ideal tooltip">dar<span class=text>most robust format but not as standard as <i>tar</i>'s</span></div>
	  <div class="limited tooltip">rsync<span class=text>no reduction on storage</span></div>
	  <div class=top>tar</div>
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>most robust archive format but not as standard as <i>tar</i>'s</span></div>
	  <div class="noway tooltip">rsync<span class=text>no reduction on storage, complicated to download a directory tree and files from other protocols than rsync</span></div>
	  <div class=top>tar</div>
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>most robust archive format but not as standard as <i>tar</i></span></div>
	  <div class="noway tooltip">rsync<span class=text>no reduction on storage, complicated to download a directory tree and files from other protocols than rsync</span></div>
	  <div class=top>tar</div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>no reduction on storage, no multi-volume, no detection of data corruption, complex parity data addition</span></div>
	  <div class="limited tooltip">tar<span class=text>compression and multi-volume are not supported at the same time</span></div>
	</td>
      </tr>
      <tr>
	<th>Private data exchange over Internet</th>
	<td>
	  <div class=top>dar</div>
	  <div class="limited tooltip">rsync<span class=text>not the best data reduction over the network</span></div>
	  <div class="ideal tooltip">tar<span class=text>best data reduction on network but no embedded ciphering, no integrated network protocols</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="limited tooltip">rsync<span class=text>no data reduction on storage, not the best data reduction over the network</span></div>
	  <div class="ideal tooltip">tar<span class=text>best data reduction on network, but lack of embedded ciphering, lack of integrated network protocols</span></div>
	</td>
	<td>
	  <div class=top>dar</div>
	  <div class="noway tooltip">rsync<span class=text>no ciphering and no data reduction on storage</span></div>
	  <div class="limited tooltip">tar<span class=text>no embedded ciphering, no integrated network protocols, no protection against plain-text attack, only old KDF functions supported, complex and error prone use of openssl to cipher the archive</span></div>
	</td>
	<td>
	  -
	</td>
      </tr>
      <tr>
	<th>Public data exchange over Internet</th>
	<td>
	  <div class="ideal tooltip">dar<span class=text>not the best data reduction over the network<i>tar</i></span></div>
	  <div class="ideal tooltip">rsync<span class=text>not the best data reduction over the network<i>tar</i></span></div>
	  <div class=top>tar</div>
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>not the best data reduction over the network<i>tar</i></span></div>
	  <div class="limited tooltip">rsync<span class=text>no data reduction on storage, not the best data reduction over the network<i>tar</i></span></div>
	  <div class=top>tar</div>
	</td>
	<td>
	  <div class="ideal tooltip">dar<span class=text>not the best data reduction over the network<i>tar</i></span></div>
	  <div class="limited tooltip">rsync<span class=text>no data reduction on storage, not the best data reduction over the network<i>tar</i></span></div>
	  <div class=top>tar</div>
	</td>
	<td>
	  -
	</td>
      </tr>
    </table>

    <p>
      In the previous table, the different software are listed in alphabetical order, see the details in the previous paragraphs for
      finer classification
    </p>
    <table class=center>
      <tr>
	<th style="width: 20%">Color codes</th>
	<td style="width: 10%"><div class=top>best solution</div></td>
	<td style="width: 10%"><div class=ideal>good solution</div></td>
	<td style="width: 10%"><div class=limited>not optimal</div></td>
	<td style="width: 10%"><div class=noway>not adapted</div></td>
      </tr>
    </table>



    <h2>Appendix 1 - Test logs</h2>
    <h3>Software used for the tests</h3>
    <ul>
      <li><b>dar</b> version 2.7.0</li>
      <li><b>rsync</b> version 3.1.3</li>
      <li><b>tar</b> GNU tar 1.30 under Linux and GNU tar (gdar) 1.32 under FreeBSD</li>
    </ul>

    <h3>Completness of backup and restoration</h3>
    <h4>Dar</h4>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# ./build_test_tree.bash  SRC</b>
	1024+0 records in
	1024+0 records out
	1048576 bytes (1.0 MB, 1.0 MiB) copied, 0.00395381 s, 265 MB/s
	1024+0 records in
	1024+0 records out
	1048576 bytes (1.0 MB, 1.0 MiB) copied, 0.00621889 s, 169 MB/s
	1+0 records in
	1+0 records out
	1 byte copied, 0.000386102 s, 2.6 kB/s
	<b>root@terre:/mnt/localdisk/Benchmark_tools# dar -c backup -R SRC</b>


	--------------------------------------------
	14 inode(s) saved
	including 3 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 14
	--------------------------------------------
	EA saved for 1 inode(s)
	FSA saved for 5 inode(s)
	--------------------------------------------
	<b>root@terre:/mnt/localdisk/Benchmark_tools# mkdir DST</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# dar -x backup -R DST</b>


	--------------------------------------------
	14 inode(s) restored
	including 3 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 14
	--------------------------------------------
	EA restored for 1 inode(s)
	FSA restored for 1 inode(s)
	--------------------------------------------
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      We simply performed backup of <code>SRC</code> directory with dar's default options, then
      restore this backup into the <code>DST</code> directory, let's now compare <code>SRC</code> and <code>DST</code> contents:
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk# du -s SRC DST</b>
	2068    SRC
	<e>1048</e>    DST
	<b>root@terre:/mnt/localdisk#</b>
    </code></div>
    <p>
      The space used by <code>DST</code> is less than the space used by <code>SRC</code>! At first
      we could beleive that not all data could be restored, let's looking for the explanation:
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk#ls -iRl SRC DST</b>
	DST:
	total 1044
	414844 drwxr-xr-x  2 root   root     4096 Oct 28 11:09 SUB
	414850 drwxr-xr-x  2 root   root     4096 Oct 22 11:09 dev
	414848 brw-r--r--  1 root   root     2, 1 Oct 28 11:09 fd1
	414842 crw-r--r--  1 root   root     3, 1 Oct 28 11:09 null
	<e class="red">414841</e> prw-r--r--  2 root   root        0 Oct 28 11:09 pipe
	414840 -rw-rwxr--+ 1 root   root  1048576 Oct 28 11:09 plain_zeroed
	414849 -rw-r--r--  1 nobody root  1048582 Oct 28 11:09 random
	<e>414843</e> -rw-r--r--  2 root   root 10240000 Oct 28 11:09 sparse_file

	DST/SUB:
	total 4
	<e class="red">414841</e> prw-r--r-- 2 root root          0 Oct 28 11:09 hard_linked_pipe
	<e class="blue">414846</e> srw-rw-rw- 2 root root          0 Oct 12 23:00 hard_linked_socket
	<e>414843</e> -rw-r--r-- 2 root root   10240000 Oct 28 11:09 hard_linked_sparse_file
	414845 lrwxrwxrwx 1 root root          6 Oct 28 11:09 symlink-broken -> random
	414847 lrwxrwxrwx 1 bin  daemon        9 Oct 28 11:09 symlink-valid -> ../random

	DST/dev:
	total 0
	<e class="blue">414846</e> srw-rw-rw- 2 root root 0 Oct 12 23:00 log

	SRC:
	total 2064
	411386 drwxr-xr-x  2 root   root     4096 Oct 28 11:09 SUB
	414836 drwxr-xr-x  2 root   root     4096 Oct 22 11:09 dev
	414835 brw-r--r--  1 root   root     2, 1 Oct 28 11:09 fd1
	414834 crw-r--r--  1 root   root     3, 1 Oct 28 11:09 null
	414832 prw-r--r--  2 root   root        0 Oct 28 11:09 pipe
	414826 -rw-rwxr--+ 1 root   root  1048576 Oct 28 11:09 plain_zeroed
	414827 -rw-r--r--  1 nobody root  1048582 Oct 28 11:09 random
	414828 -rw-r--r--  2 root   root 10240000 Oct 28 11:09 sparse_file

	SRC/SUB:
	total 4
	414832 prw-r--r-- 2 root root          0 Oct 28 11:09 hard_linked_pipe
	414837 srw-rw-rw- 2 root root          0 Oct 12 23:00 hard_linked_socket
	414828 -rw-r--r-- 2 root root   10240000 Oct 28 11:09 hard_linked_sparse_file
	414830 lrwxrwxrwx 1 root root          6 Oct 28 11:09 symlink-broken -> random
	414831 lrwxrwxrwx 1 bin  daemon        9 Oct 28 11:09 symlink-valid -> ../random

	SRC/dev:
	total 0
	414837 srw-rw-rw- 2 root root 0 Oct 12 23:00 log
	<b>root@terre:/mnt/localdisk#</b>
    </code></div>
    <p>
      All files are present in <code>DST</code> and use the expected space usage, as reported by the <code>ls</code> command.
      We can also see that the hard linked inode were properly restored for plain file, named pipe and unix socket: the
      inode number in first column is the same (see colorized output above).
    </p>
    <p>
      Maybe something is missing elsewhere?
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk# getfacl SRC/plain_zeroed DST/plain_zeroed</b>
	# file: SRC/plain_zeroed
	# owner: root
	# group: root
	user::rw-
	<e>user:nobody:rwx</e>
	group::r--
	mask::rwx
	other::r--

	# file: DST/plain_zeroed
	# owner: root
	# group: root
	user::rw-
	<e>user:nobody:rwx</e>
	group::r--
	mask::rwx
	other::r--

	<b>root@terre:/mnt/localdisk# getfattr -d SRC/plain_zeroed DST/plain_zeroed</b>
	# file: SRC/plain_zeroed
	<e>user.hello="hello world!!!"</e>

	# file: DST/plain_zeroed
	<e>user.hello="hello world!!!"</e>

	<b>root@terre:/mnt/localdisk/Benchmark_tools# lsattr SRC/plain_zeroed DST/plain_zeroed</b>
	<e>s---i-d-------e----</e> SRC/plain_zeroed
	<e>s---i-d-------e----</e> DST/plain_zeroed
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      To summarize:
    </p>
    <ul>
      <li>user and group ownership are restored</li>
      <li>permission are set correctly</li>
      <li>ACL are preperly restored</li>
      <li>Extended Attributes also</li>
      <li>file system specific attributes are too</li>
      <li>hard links are restored</li>
    </ul>
    <p>
      So what? Let's rerun <code>du</code> file by file:
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# du -B1 SRC/* DST/*</b>
	8192    SRC/SUB
	4096    SRC/dev
	0       SRC/fd1
	0       SRC/null
	<e>1048576 SRC/plain_zeroed</e>
	1052672 SRC/random
	8192    DST/SUB
	4096    DST/dev
	0       DST/fd1
	0       DST/null
	<e>4096    DST/plain_zeroed</e>
	1052672 DST/random
	<b>root@terre:/mnt/localdisk/Benchmark_tools# ls -l SRC/plain_zeroed DST/plain_zeroed</b>
	-rw-rwxr--+ 1 root root <e>1048576</e> Oct 21 18:40 DST/plain_zeroed
	-rw-rwxr--+ 1 root root <e>1048576</e> Oct 21 18:40 SRC/plain_zeroed
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      OK here is the explanation: <code>plain_zeroed</code> file was using 1048576 bytes of disk space in SRC
      but consumes only 4096 bytes in DST, but as its file size is still officially 1048576, it has become now a sparse file.
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# diff -s SRC/plain_zeroed DST/plain_zeroed</b>
	Files SRC/plain_zeroed and DST/plain_zeroed are <e>identical</e>
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>

    <p>
      But nothing changes from the user point of view, the restoration process with dar just optimized
      the space usage.
    </p>
    <p>
      Let's continue checking the inode dates. As you know, Unix inode have several dates:
      </p>
    <ul>
      <li><b>atime</b>, the access time, gives the last time the file's data has been accessed (read)</li>
      <li><b>mtime</b>, the modification time, gives the last time the file's data has been modified (wrote)</li>
      <li><b>ctime</b>, the change time, gives the last time the file's metadata in other word the inode properties (ownership, ACL, permissions, dates, ...) have been modified</li>
      <li><b>btime</b>, the birth time or yet creation time, gives the time the file has been created on the current filesystem, this date is not present on all Unix system</li>
    </ul>

    <p>
      The <code>ls -iRl</code> command we used so far does only show the <i>mtime</i> date moreover with
      a time accuracy of only one minute, while modern systems provide nanosecond precision. For that
      reason we will use the <code>stat</code> command instead to have all dates at the system time accuracy:
    </p>

    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# stat SRC/random DST/random</b>
	File: SRC/random
	Size: 1048576         Blocks: 2048       IO Block: 4096   regular file
	Device: 802h/2050d      Inode: 414840      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (65534/  nobody)   Gid: (    0/    root)
	<e>Access: 2020-10-22 12:13:01.813319506 +0200</e>
	<e>Modify: 2020-10-22 12:12:57.765328555 +0200</e>
	<e class=red>Change: 2020-10-22 12:12:59.805323991 +0200</e>
	Birth: -
	File: DST/random
	Size: 1048576         Blocks: 2048       IO Block: 4096   regular file
	Device: 802h/2050d      Inode: 414889      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (65534/  nobody)   Gid: (    0/    root)
	<e>Access: 2020-10-22 12:13:01.813319506 +0200</e>
	<e>Modify: 2020-10-22 12:12:57.765328555 +0200</e>
	<e class=red>Change: 2020-10-22 12:14:34.877131738 +0200</e>
	Birth: -
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>

    <p>
      From the above output we see that:
    </p>
    <ul>
      <li>atime is restored</li>
      <li>mtime is restored</li>
      <li>ctime is not restored</li>
    </ul>

    <p>
      As we targeted this benchmark mainly for Linux which has not yet the <code>btime</code> available
      (Well some Linux <a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems#Metadata">file systems</a> support
      <i>btime</i> but its access is not yet fully available to applications), we will thus momentarily change to a BSD system
      to play with <code>btime</code>. BSD systems include MACOS X, FreeBSD, NetBSD, butterflyBSD,... we will use FreeBSD here.
      Under FreeBSD, the <code>stat</code> command is not as easy to read as under Linux, however it is
      very flexible which we will leverage to mimic the Linux output:
    </p>

    <div class=code><code>
	<b>root@FreeBSD:~denis # which mystat</b>
	mystat:          aliased to <e>stat -f "%N%nAccess: %Sa%nModify: %Sm%nChange: %Sc%nBirth: %SB%n" !*</e>
	<b>root@FreeBSD:~denis # mystat SRC/random</b>
	SRC/random
	Access: Oct 27 13:28:41 2020
	Modify: Oct 22 15:34:07 2020
	Change: Oct 22 15:34:09 2020
	<e>Birth: Oct 22 15:34:07 2020</e>
	<b>root@FreeBSD:~denis # dar -c backup -R SRC -q</b>
	<b>root@FreeBSD:~denis # mkdir DST</b>
	<b>root@FreeBSD:~denis # dar -x backup -R DST -q</b>
	<b>root@FreeBSD:~denis # mystat DST/random</b>
	DST/random
	Access: Oct 27 13:28:41 2020
	Modify: Oct 22 15:34:07 2020
	Change: Oct 27 13:31:50 2020
	<e>Birth: Oct 22 15:34:07 2020</e>
	<b>root@FreeBSD:~denis #</b>
    </code></div>

    <p>
      In conclusion <i>dar</i> also saves and restores properly <code>btime</code>
    </p>


    <h4>Rsync</h4>
    <p>
      Let's do the same we did previously using <b>rsync</b>. We start by copying <code>SRC</code> directory to <code>DST</code>:
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# chattr -i DST/plain_zeroed</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# rm -rf DST</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# mkdir DST</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# rsync -arvHAXS SRC/* DST</b>
	sending incremental file list
	created directory DST
	fd1
	null
	pipe
	plain_zeroed
	random
	SUB/
	SUB/hard_linked_pipe => pipe
	SUB/hard_linked_socket
	SUB/hard_linked_sparse_file
	SUB/symlink-broken -> random
	SUB/symlink-valid -> ../random
	dev/
	dev/log => SUB/hard_linked_socket
	sparse_file => SUB/hard_linked_sparse_file

	sent 12,340,852 bytes  received 198 bytes  24,682,100.00 bytes/sec
	total size is 22,577,173  speedup is 1.83
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      First note, the backup and restoration is done in one step, where <i>dar</i> was decorelating the backup operation
      from the restoration operation. The resulting backup needs not software to be restored (<code>DST</code>
      is a copy of <code>SRC</code>). For dar to reach the same result (without using storage for the backup) this
      implies two dar commands: <code> dar -c - -R SRC | dar -x - --sequential-read -R DSR</code>. The situation is
      similar with <code>tar</code>, you need two commands to performe the same task: <code>tar -cf - | tar -xf -</code>
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# du -s SRC DST</b>
	2056    SRC
	<e>1028</e>    DST
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      Here too, the restored data uses less space than the original data, sparse file have been taken into
      account (need specifying -S option) and space optimization of non sparse file is performed.
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# ls -iRl SRC DST</b>
	DST:
	total 12060
	414843 drwxr-xr-x  2 root   root     4096 Oct 28 11:09 SUB
	414844 drwxr-xr-x  2 root   root     4096 Oct 22 11:09 dev
	414840 brw-r--r--  1 root   root     2, 1 Oct 28 11:09 fd1
	414841 crw-r--r--  1 root   root     3, 1 Oct 28 11:09 null
	<e class=red>414842</e> prw-r--r--  2 root   root        0 Oct 28 11:09 pipe
	414848 -rw-rwxr--+ 1 root   root  1048576 Oct 28 11:09 plain_zeroed
	414849 -rw-r--r--  1 nobody root  1048582 Oct 28 11:09 random
	<e>414850</e> -rw-r--r--  2 root   root 10240000 Oct 28 11:09 sparse_file

	DST/SUB:
	total 10000
	<e class=red>414842</e> prw-r--r-- 2 root root          0 Oct 28 11:09 hard_linked_pipe
	<e class=blue>414845</e> srw-rw-rw- 2 root root          0 Oct 12 23:00 hard_linked_socket
	<e>414850</e> -rw-r--r-- 2 root root   10240000 Oct 28 11:09 hard_linked_sparse_file
	414846 lrwxrwxrwx 1 root root          6 Oct 28 11:09 symlink-broken -> random
	414847 lrwxrwxrwx 1 bin  daemon        9 Oct 28 11:09 symlink-valid -> ../random

	DST/dev:
	total 0
	<e class=blue>414845</e> srw-rw-rw- 2 root root 0 Oct 12 23:00 log

	SRC:
	total 2064
	411386 drwxr-xr-x  2 root   root     4096 Oct 28 11:09 SUB
	414836 drwxr-xr-x  2 root   root     4096 Oct 22 11:09 dev
	414835 brw-r--r--  1 root   root     2, 1 Oct 28 11:09 fd1
	414834 crw-r--r--  1 root   root     3, 1 Oct 28 11:09 null
	414832 prw-r--r--  2 root   root        0 Oct 28 11:09 pipe
	414826 -rw-rwxr--+ 1 root   root  1048576 Oct 28 11:09 plain_zeroed
	414827 -rw-r--r--  1 nobody root  1048582 Oct 28 11:09 random
	414828 -rw-r--r--  2 root   root 10240000 Oct 28 11:09 sparse_file

	SRC/SUB:
	total 4
	414832 prw-r--r-- 2 root root          0 Oct 28 11:09 hard_linked_pipe
	414837 srw-rw-rw- 2 root root          0 Oct 12 23:00 hard_linked_socket
	414828 -rw-r--r-- 2 root root   10240000 Oct 28 11:09 hard_linked_sparse_file
	414830 lrwxrwxrwx 1 root root          6 Oct 28 11:09 symlink-broken -> random
	414831 lrwxrwxrwx 1 bin  daemon        9 Oct 28 11:09 symlink-valid -> ../random

	SRC/dev:
	total 0
	414837 srw-rw-rw- 2 root root 0 Oct 12 23:00 log
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      All files are present in <code>DST</code> and use the expected space usage, as reported by the <code>ls</code>.
      We can also see that all three hard linked inode (plain file, socket and named pipe) are restored properly.
      So we can suspect the cause of the size difference to be linked with sparse files:
    </p>
    <p>
      Let's now check file's metadata:
    </p>
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# getfacl SRC/plain_zeroed DST/plain_zeroed</b>
	# file: SRC/plain_zeroed
	# owner: root
	# group: root
	user::rw-
	<e>user:nobody:rwx</e>
	group::r--
	mask::rwx
	other::r--

	# file: DST/plain_zeroed
	# owner: root
	# group: root
	user::rw-
	<e>user:nobody:rwx</e>
	group::r--
	group::rwx
	other::r--

	<b>root@terre:/mnt/localdisk/Benchmark_tools# getfattr -d SRC/plain_zeroed DST/plain_zeroed</b>
	# file: SRC/plain_zeroed
	<e>user.hello="hello world!!!"</e>

	# file: DST/plain_zeroed
	<e>user.hello="hello world!!!"</e>
	<br/>

	<b>root@terre:/mnt/localdisk/Benchmark_tools# lsattr SRC/plain_zeroed DST/plain_zeroed</b>
	<e class=red>s---i-d-------e----</e> SRC/plain_zeroed
	<e class=red>--------------e----</e> DST/plain_zeroed
	<b>root@terre:/mnt/localdisk/Benchmark_tools#stat SRC/random DST/random</b>
	File: SRC/random
	Size: 1048582         Blocks: 2056       IO Block: 4096   regular file
	Device: 802h/2050d      Inode: 414827      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (65534/  nobody)   Gid: (    0/    root)
	<e class=red>Access: 2020-10-28 11:09:59.977926733 +0100</e>
	<e>Modify: 2020-10-28 11:09:57.973931318 +0100</e>
	<e class=red>Change: 2020-10-28 11:09:57.973931318 +0100</e>
	Birth: -
	File: DST/random
	Size: 1048582         Blocks: 2056       IO Block: 4096   regular file
	Device: 802h/2050d      Inode: 414849      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (65534/  nobody)   Gid: (    0/    root)
	<e class=red>Access: 2020-10-28 12:07:53.622841733 +0100</e>
	<e>Modify: 2020-10-28 11:09:57.973931318 +0100</e>
	<e class=red>Change: 2020-10-28 12:07:53.622841733 +0100</e>
	Birth: -
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      So in summary:
    </p>
    <ul>
      <li>Permission are restored,</li>
      <li>user and group ownership are restored too,</li>
      <li>mtime is restored,</li>
      <li>File ACL are restored,</li>
      <li>Extended Attributes are restored</li>
    </ul>
    <p>
      But
    </p>
    <ul>
      <li>filesystem specific attributes are not restored,</li>
      <li>atime is not restored,</li>
      <li>ctime is not restored</li>
    </ul>

    <p>
      For <b>btime</b> as we did before, let's test under a FreeBSD system:
    </p>

    <div class=code><code>
	<b>root@FreeBSD:~denis # rm -rf DST</b>
	<b>root@FreeBSD:/home/denis # which mystat</b>
	mystat:          aliased to stat -f "%N%nAccess: %Sa%nModify: %Sm%nChange: %Sc%nBirth: %SB%n" !*
	<b>root@FreeBSD:/home/denis # mystat SRC/random</b>
	SRC/random
	Access: Oct 27 14:27:59 2020
	Modify: Oct 22 15:34:07 2020
	Change: Oct 22 15:34:09 2020
	<e>Birth: Oct 22 15:34:07 2020</e>
	root@FreeBSD:/home/denis # mkdir DST
	root@FreeBSD:/home/denis # rsync -arv SRC/* DST
	sending incremental file list
	fd1
	null
	pipe
	plain_zeroed
	random
	sparse_file
	SUB/
	SUB/hard_linked_socket
	SUB/hard_linked_sparse_file
	SUB/symlink-broken -> random
	SUB/symlink-valid -> ../random
	dev/
	dev/log -> /var/run/log

	sent 22,583,283 bytes  received 129 bytes  45,166,824.00 bytes/sec
	total size is 22,577,179  speedup is 1.00
	root@FreeBSD:/home/denis # mystat DST/random
	DST/random
	Access: Oct 27 14:28:53 2020
	Modify: Oct 22 15:34:07 2020
	Change: Oct 27 14:28:53 2020
	<e>Birth: Oct 22 15:34:07 2020</e>
	<b>root@FreeBSD:/home/denis #</b>
    </code></div>
    <p>
      So, birthtime is properly restored.
    </p>

    <h4>Tar</h4>

    <p>
      As done with previously, let's save and restore the <code>SRC</code> directory to <code>DST</code>... Note that by default
      no sparse file is taken into account (where from the <code>-S option</code>), no acl (<code>--acl</code>) no Extended Attributes
      (<code>--xattrs</code>). The
      <i>tar</i> command-line is thus long for these reasons.
    </p>

    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# rm -rf DST</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# cd SRC</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools/SRC# tar --acl --xattrs -cSf ../backup.tar *</b>
	tar: SUB/hard_linked_socket: socket ignored
	tar: dev/log: socket ignored
	<b>root@terre:/mnt/localdisk/Benchmark_tools/SRC# cd ../</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# mkdir DST</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# cd DST</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools/DST# tar --acl --xattrs -xSf ../backup.tar</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools/DST# cd ..</b>
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>

    <p>
      ...and compare the restored data with the original:
    </p>

    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# du -s SRC DST</b>
	2068    SRC
	<e>2068</e>    DST
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>

    <p>
      The sparse file has been properly restored (thanks to the <code>-S option</code> for that) but not space optimization
      has been performed.
    </p>

    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# ls -iRl SRC DST</b>
	DST:
	total 12060
	414841 drwxr-xr-x 2 root   root     4096 Oct 28 11:09 SUB
	414846 drwxr-xr-x 2 root   root     4096 Oct 22 11:09 dev
	414847 brw-r--r-- 1 root   root     2, 1 Oct 28 11:09 fd1
	414848 crw-r--r-- 1 root   root     3, 1 Oct 28 11:09 null
	414849 prw-r--r-- <e class=red>1</e> root   root        0 Oct 28 11:09 pipe
	414850 -rw-rwxr-- 1 root   root  1048576 Oct 28 11:09 plain_zeroed
	414852 -rw-r--r-- 1 nobody root  1048582 Oct 28 11:09 random
	<e>414843</e> -rw-r--r-- 2 root   root 10240000 Oct 28 11:09 sparse_file

	DST/SUB:
	total 10000
	414845 prw-r--r-- 1 root root          0 Oct 28 11:09 hard_linked_pipe
	<e>414843</e> -rw-r--r-- 2 root root   10240000 Oct 28 11:09 hard_linked_sparse_file
	414842 lrwxrwxrwx 1 root root          6 Oct 28 11:09 symlink-broken -> random
	414844 lrwxrwxrwx 1 bin  daemon        9 Oct 28 11:09 symlink-valid -> ../random

	DST/dev:
	total 0

	SRC:
	total 2064
	411386 drwxr-xr-x  2 root   root     4096 Oct 28 11:09 SUB
	414836 drwxr-xr-x  2 root   root     4096 Oct 22 11:09 dev
	414835 brw-r--r--  1 root   root     2, 1 Oct 28 11:09 fd1
	414834 crw-r--r--  1 root   root     3, 1 Oct 28 11:09 null
	414832 prw-r--r--  <e class=red>2</e> root   root        0 Oct 28 11:09 pipe
	414826 -rw-rwxr--+ 1 root   root  1048576 Oct 28 11:09 plain_zeroed
	414827 -rw-r--r--  1 nobody root  1048582 Oct 28 11:09 random
	414828 -rw-r--r--  2 root   root 10240000 Oct 28 11:09 sparse_file

	SRC/SUB:
	total 4
	414832 prw-r--r-- 2 root root          0 Oct 28 11:09 hard_linked_pipe
	<e class=red>414837 srw-rw-rw- 2 root root          0 Oct 12 23:00 hard_linked_socket</e>
	414828 -rw-r--r-- 2 root root   10240000 Oct 28 11:09 hard_linked_sparse_file
	414830 lrwxrwxrwx 1 root root          6 Oct 28 11:09 symlink-broken -> random
	414831 lrwxrwxrwx 1 bin  daemon        9 Oct 28 11:09 symlink-valid -> ../random

	SRC/dev:
	total 0
	<e class=red>414837 srw-rw-rw- 2 root root 0 Oct 12 23:00 log</e>
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>

    <p>
      The warning was not vain, <code>SUB/hard_linked_socket</code> and <code>log</code> are missing in <code>DST</code>.
      This is however a minor problem as usually unix sockets get recreated by the process using them. However
      we might have some permission and ownership to set back, by hand. A possible use case is <code>syslog</code> daemon,
      when let available for a chrooted process or container (MTA, or other network service).
    </p>
    <p>
      The second problem is a bit more annoying: the hard linked fifo (aka named pipe)
      is silently restored as two independent named pipes (the inode number are different in the first column
      for <code>pipe</code> and <code>SUB/hard_linked_pipe</code> and their respective link count was <code>2</code>
      in <code>SRC</code> but is now <code>1</code> in <code>DST</code>. If two processes in different namespaces or
      chrooted environment, exchange data by mean of such hardlinked pipe, after restoration, if you are not
      aware of this restriction, it will be difficult to identify why the two process are just locked out, one
      waiting for data that will never come from the pipe, the other stuck for the pipe to be read.
    </p>

    <p>
      Let's continue by checking the file's metadata:
    </p>

    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# getfacl SRC/plain_zeroed DST/plain_zeroed</b>
	# file: SRC/plain_zeroed
	# owner: root
	# group: root
	user::rw-
	<e>user:nobody:rwx</e>
	group::r--
	mask::rwx
	other::r--

	# file: DST/plain_zeroed
	# owner: root
	# group: root
	user::rw-
	<e>user:nobody:rwx</e>
	group::r--
	mask::rwx
	other::r--

	root@terre:/mnt/localdisk/Benchmark_tools# getfattr -d SRC/plain_zeroed DST/plain_zeroed
	# file: SRC/plain_zeroed
	<e>user.hello="hello world!!!"</e>

	# file: DST/plain_zeroed
	<e>user.hello="hello world!!!"</e>

	<b>root@terre:/mnt/localdisk/Benchmark_tools# lsattr SRC/plain_zeroed DST/plain_zeroed</b>
	<e class=red>s---i-d-------e----</e> SRC/plain_zeroed
	<e class=red>--------------e----</e> DST/plain_zeroed
	<b>root@terre:/mnt/localdisk/Benchmark_tools#</b>
    </code></div>
    <p>
      Note that without <code>--xattrs</code> at creation time the timestamp accuracy of <i>tar</i>
      is 1 second:
    <div class=code><code>
	<b>root@terre:/mnt/localdisk/Benchmark_tools# stat SRC/random DST/random</b>
	File: SRC/random
	Size: 1048576         Blocks: 2048       IO Block: 4096   regular file
	Device: 802h/2050d      Inode: 414841      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (65534/  nobody)   Gid: (    0/    root)
	<e class=red>Access: 2020-10-27 14:03:46.064046436 +0100</e>
	<e>Modify: 2020-10-27 14:03:42.016050420 +0100</e>
	<e class=red>Change: 2020-10-27 14:03:44.048048418 +0100</e>
	Birth: -
	File: DST/random
	Size: 1048576         Blocks: 2048       IO Block: 4096   regular file
	Device: 802h/2050d      Inode: 414890      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (65534/  nobody)   Gid: (    0/    root)
	<e class=red>Access: 2020-10-27 19:08:14.932424226 +0100</e>
	<e>Modify: 2020-10-27 14:03:42</e>.<e class=red>000000000 +0100</e>
	<e class=red>Change: 2020-10-27 19:08:14.932424226 +0100</e>
	Birth: -
	root@terre:/mnt/localdisk/Benchmark_tools#
    </code></div>

    <p>
      From the above output we see that:
    </p>
    <ul>
      <li>permission are restored,</li>
      <li>user and group ownership are restored too,</li>
      <li>mtime is restored but it needs <code>--xattrs</code> to take into account today's system common time accuracy of one nanosecond</li>
      <li>ACL are restored,</li>
      <li>Extended Attributes are restored</li>
    </ul>

    <p>
      But
    </p>

    <ul>
      <li>filesystem attributes are not restored,<li>
      <li>atime is not restored,</li>
      <li>ctime is not restored</li>
    </ul>

    <p>
      For the last date, <b>birthtime</b> again we will perform the test under FreeBSD:
    </p>

    <div class=code><code>
	<b>root@FreeBSD:~denis # which mystat</b>
	mystat:          aliased to stat -f "%N%nAccess: %Sa%nModify: %Sm%nChange: %Sc%nBirth: %SB%n" !*
	<b>root@FreeBSD:~denis # mystat SRC/random</b>
	SRC/random
	Access: Oct 27 19:40:13 2020
	Modify: Oct 22 15:34:07 2020
	Change: Oct 22 15:34:09 2020
	<e>Birth: Oct 22 15:34:07 2020</e>
	<b>root@FreeBSD:~denis # cd SRC</b>
	<b>root@FreeBSD:~denis/SRC # gtar -cf ../backup.tar random</b>
	<b>root@FreeBSD:~denis/SRC # cd ..</b>
	<b>root@FreeBSD:~denis # mkdir DST</b>
	<b>root@FreeBSD:~denis # cd DST</b>
	<b>root@FreeBSD:~denis/DST # tar -xf ../backup.tar</b>
	<b>root@FreeBSD:~denis/DST # cd ..</b>
	<b>root@FreeBSD:~denis # mystat DST/random</b>
	DST/random
	Access: Oct 28 15:43:30 2020
	Modify: Oct 22 15:34:07 2020
	Change: Oct 28 15:43:30 2020
	<e>Birth: Oct 22 15:34:07 2020</e>
	<b>root@FreeBSD:~denis #</b>
    </code></div>

    <p>
      <i>gtar</i> saved and restored the birthtime
    </p>





    <h3>Feature set</h3>

    <h4>Historization</h4>
    <p>
      To evaluate this feature, in a first time we will create two files <i>A.txt</i> and <i>B.txt</i>
      and make a first backup. Then we will remove <i>A.txt</i> and add <i>C.txt</i> and make
      a second backup. We should be able to restore the data in both states (A+B and B+C). To do that, we
      will use the following script.
    </p>

    <div class=code><code>
	#!/bin/bash

	if [ -z "$1" -o -z "$2" ] ; then
	  echo "usage: $0 &lt;dir&gt; {phase1 | phase2}"
	  exit 1
	fi

	dir="$1"
	phase="$2"

	case "$phase" in

	phase1)
	  if [ -e "$dir" ] ; then
	    echo "$dir exists, remove it first"
	    exit 2
	  fi
	  mkdir "$dir"
	  echo "Hello World!" &gt; "$dir/A.txt"
	  echo "Bonjour tout le monde !" &gt; "$dir/B.txt"
	;;

	phase2)
	  if [ ! -d "$dir" ] ; then
	    echo "$dir does not exist or is not a directory, run phase1 first"
	    exit 2
	  fi
  	  rm -f "$dir/A.txt"
	  echo "Buongiorno a tutti !" &gt; "$dir/C.txt"
	;;

	*)
	  echo "unknown phase"
	  exit 2
	;;
	esac
    </code></div>

    <h5>Dar</h5>

    <div class=code><code>
	root@terre:/mnt/memdisk# rm -rf SRC
	root@terre:/mnt/memdisk# ./historization_feature SRC phase1
	root@terre:/mnt/memdisk# dar -c full -g SRC -q
	root@terre:/mnt/memdisk# ./historization_feature SRC phase2
	root@terre:/mnt/memdisk# dar -c diff -A full -g SRC -q
	root@terre:/mnt/memdisk# mkdir DST
	root@terre:/mnt/memdisk# dar -x full -R DST -q
	root@terre:/mnt/memdisk# ls -lR DST
	DST:
	total 0
	drwxr-xr-x 2 root root 80 Nov  6 18:37 SRC

	DST/SRC:
	total 8
	-rw-r--r-- 1 root root 13 Nov  6 18:37 <e>A.txt</e>
	-rw-r--r-- 1 root root 24 Nov  6 18:37 <e>B.txt</e>
	root@terre:/mnt/memdisk# dar -x diff -R DST -w -q
	root@terre:/mnt/memdisk# ls -lR DST
	DST:
	total 0
	drwxr-xr-x 2 root root 80 Nov  6 18:38 SRC

	DST/SRC:
	total 8
	-rw-r--r-- 1 root root 24 Nov  6 18:37 <e>B.txt</e>
	-rw-r--r-- 1 root root 21 Nov  6 18:38 <e>C.txt</e>
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      Historization is present, we can get back from backup both saved states
    </p>
    <p>
      In complement <i>dar</i> proposes a manager <i>dar_manager</i> to easily locate file's status between the archives
      the database has been feeded with, as well as the file's data present in each archive:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar_manager -C base.dmd
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -A full
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -A diff
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -f SRC/A.txt
        1       Fri Nov  6 18:37:51 2020  saved                                 absent
        2       Fri Nov  6 18:38:04 2020  removed                               absent
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -f SRC/B.txt
        1       Fri Nov  6 18:37:51 2020  saved                                 absent
        2       Fri Nov  6 18:37:51 2020  present                               absent
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -f SRC/C.txt
        2       Fri Nov  6 18:38:04 2020  saved                                 absent
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -l

	dar path        :
	dar options     :
	database version: 5
	compression used: gzip

	archive #   |    path      |    basename
	------------+--------------+---------------
        1       .       full
        2       .       diff
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -u 1
	[ Saved ][       ]  SRC/B.txt
	[ Saved ][       ]  SRC/A.txt
	root@terre:/mnt/memdisk# dar_manager -B base.dmd -u 2
	[ Saved ][       ]  SRC
	[ Saved ][       ]  SRC/C.txt
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      <i>dar_manager</i> can even take for you the actions to invoke <i>dar</i> as many time as necessary
      get the file's status of a given date for a given set of subset of the saved files:
    </p>

    <div class=code><code>
	root@terre:/mnt/memdisk# dar_manager -v -B base.dmd -e "-R DST -w" -r SRC
	Decompressing and loading database to memory...
	Looking in archives for requested files, classifying files archive by archive...
	Checking chronological ordering of files between the archives...
	File recorded as removed at this date in database: SRC/A.txt
	CALLING DAR: restoring 1 files from archive ./full using anonymous pipe to transmit configuration to the dar process
	Arguments sent through anonymous pipe are:
	dar -x ./full -R DST -w -g SRC/B.txt


	--------------------------------------------
	2 inode(s) restored
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	1 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 3
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	CALLING DAR: restoring 2 files from archive ./diff using anonymous pipe to transmit configuration to the dar process
	Arguments sent through anonymous pipe are:
	dar -x ./diff -R DST -w -g SRC -g SRC/C.txt
	Error while restoring /mnt/memdisk/DST/SRC/A.txt : Cannot remove non-existent file from filesystem: /mnt/memdisk/DST/SRC/A.txt


	--------------------------------------------
	2 inode(s) restored
	including 0 hard link(s)
	1 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	1 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 4
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	Final memory cleanup...
	All files asked could not be restored
	DAR sub-process has terminated with exit code 5 Continue anyway ? [return = YES | Esc = NO]
	Continuing...
	root@terre:/mnt/memdisk# ls -lR DST
	DST:
	total 0
	drwxr-xr-x 2 root root 80 Nov  6 18:38 SRC

	DST/SRC:
	total 8
	-rw-r--r-- 1 root root 24 Nov  6 18:37 <e>B.txt</e>
	-rw-r--r-- 1 root root 21 Nov  6 18:38 <e>C.txt</e>
	root@terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# ./historization_feature SRC phase1
	root@terre:/mnt/memdisk# rsync -arvHAX SRC DST
	sending incremental file list
	created directory DST
	SRC/
	SRC/A.txt
	SRC/B.txt

	sent 229 bytes  received 84 bytes  626.00 bytes/sec
	total size is 37  speedup is 0.12
	root@terre:/mnt/memdisk# ./historization_feature SRC phase2
	root@terre:/mnt/memdisk# rsync -arvHAX SRC DST
	sending incremental file list
	SRC/
	SRC/C.txt

	sent 172 bytes  received 39 bytes  422.00 bytes/sec
	total size is 45  speedup is 0.21
	root@terre:/mnt/memdisk# ls -l
	total 4
	drwxr-xr-x 3 root root  60 Nov  6 17:06 DST
	drwxr-xr-x 2 root root  80 Nov  6 17:06 SRC
	-rwxr--r-- 1 root root 589 Nov  6 16:32 historization_feature
	root@terre:/mnt/memdisk# ls -l DST
	total 0
	drwxr-xr-x 2 root root 100 Nov  6 17:06 SRC
	root@terre:/mnt/memdisk# ls -l DST/SRC
	total 12
	<e>-rw-r--r-- 1 root root 13 Nov  6 17:05 A.txt</e>
	<e>-rw-r--r-- 1 root root 24 Nov  6 17:05 B.txt</e>
	<e>-rw-r--r-- 1 root root 21 Nov  6 17:06 C.txt</e>
	root@terre:/mnt/memdisk# rsync -arvHAX --delete SRC DST
	sending incremental file list
	deleting SRC/A.txt

	sent 101 bytes  received 26 bytes  254.00 bytes/sec
	total size is 45  speedup is 0.35
	root@terre:/mnt/memdisk# ls -l DST/SRC
	total 8
	<e>-rw-r--r-- 1 root root 24 Nov  6 17:05 B.txt</e>
	<e>-rw-r--r-- 1 root root 21 Nov  6 17:06 C.txt</e>
	root@terre:/mnt/memdisk#
    </code></div>

    <p>
      the "backup" contains all three files, <i>A.txt</i>, <i>B.txt</i>
      and <i>C.txt</i> while the first and the later never existed at the
      same time. Such backup does not allow to have neither the state of
      the <i>phase1</i> nor the state of the <i>phase2</i>.
    </p>
    <p>
      We added the <code>--delete</code> option and as result we got
      to be the <i>phase2</i> state. But then we cannot restore to the <i>phase1</i> state as the
      file <i>A.txt</i> has been deleted from the backup.
    </p>
    <p>
      To have both states with <i>rsync</i>, we should call rsync to a different destination directory
      at each new backup, which would consume a lot of space and would also defeats one the main
      feature of <i>rsync</i> which is its ability to synchronize two directories exchanging only
      the minimal information that was modified.
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# rmdir SRC
	root@terre:/mnt/memdisk# ./historization_feature SRC phase1
	root@terre:/mnt/memdisk# tar --listed-incremental=snapshot.file -cf full.tar SRC
	root@terre:/mnt/memdisk# ./historization_feature SRC phase2
	root@terre:/mnt/memdisk# tar --listed-incremental=snapshot.file -cf diff.tar SRC
	root@terre:/mnt/memdisk# mkdir DST
	root@terre:/mnt/memdisk# cd DST
	root@terre:/mnt/memdisk/DST# tar --listed-incremental=snapshot.file -xf ../full.tar
	root@terre:/mnt/memdisk/DST# ls -l SRC
	total 8
	<e>-rw-r--r-- 1 root root 13 Nov  6 18:20 A.txt</e>
	<e>-rw-r--r-- 1 root root 24 Nov  6 18:20 B.txt</e>
	root@terre:/mnt/memdisk/DST# tar --listed-incremental=snapshot.file -xf ../diff.tar
	root@terre:/mnt/memdisk/DST# ls -l SRC
	total 8
	<e>-rw-r--r-- 1 root root 24 Nov  6 18:20 B.txt</e>
	<e>-rw-r--r-- 1 root root 21 Nov  6 18:21 C.txt</e>
	root@terre:/mnt/memdisk/DST#
    </code></div>

    <p>
      We could restore from backup both the phase1 and phase2 status, historization is available with tar.
    </p>


    <h4>Data filtering by directory</h4>

    <h5>Dar</h5>
    <p>
      We want to save <code>/lib</code> except the content of <code>/lib/modules</code>:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R /lib -P modules -vs -q
	<e>Skipping file: /lib/modules</e>
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      What if we want to exclude all of to exclude <code>/lib/module</code> except
      <code>/lib/module/4.19.0-12-amd64</code>?
    </p>

    <div class=code><code>
	root@terre:/mnt/memdisk# rm backup.1.dar
	rm: remove regular file 'backup.1.dar'? y
	root@terre:/mnt/memdisk# dar -c backup -R /lib -am -P modules -g modules/4.19.0-12-amd64 -vs -q
	<e>Skipping file: /lib/modules/4.19.0-11-amd64</e>
	<e>Skipping file: /lib/modules/4.19.0-10-amd64</e>
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      OK, we can mix included directories and excluded directories
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# mkdir DST
	root@terre:/mnt/memdisk# rsync -arHAXS --exclude /lib/modules /lib DST
	root@terre:/mnt/memdisk# ls -ld DST/lib/m*
	drwxr-xr-x 2 root root 80 Jun 11 23:33 DST/lib/modprobe.d
	root@terre:/mnt/memdisk#
	root@terre:/mnt/memdisk# ls -l DST/lib/modules
	ls: cannot access <e>'DST/lib/modules': No such file or directory</e>
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      We could exclude <code>/lib/modules</code> as expected. As previously, let's exclude it
      except <code>/lib/modules/4.19.0-12-amd64</code>:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# rsync -arHAXS -f "+ /lib/modules" -f "- /lib/modules/4.19.0-12-amd64"  /lib DST
	root@terre:/mnt/memdisk# la DST/lib/modules/
	total 0
	drwxr-xr-x  4 root root  80 Oct 22 10:33 .
	drwxr-xr-x 19 root root 420 Oct 22 11:20 ..
	<e>drwxr-xr-x  3 root root 280 Aug  8 12:58 4.19.0-10-amd64</e>
	<e>drwxr-xr-x  3 root root 280 Oct 12 11:25 4.19.0-11-amd64</e>
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      OK, we can mix included directories and excluded directories
    </p>

    <h5>Tar</h5>
    <p>
      Let's save /lib and excluding /lib/module again:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar --exclude /lib/modules -cf backup.tar /lib
	tar: Removing leading `/' from member names
	root@terre:/mnt/memdisk# tar -tf backup.tar | grep modules
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      Now let's exclude <code>/lib/modules</code> except <code>/lib/modules/4.19.0-12-amd64</code>:
    <p>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar -cf backup.tar /lib/modules/4.19.0-12-amd64/ --exclude /lib/modules /lib
	tar: Removing leading `/' from member names
	tar: Removing leading `/' from hard link targets
	root@terre:/mnt/memdisk# tar -tf backup.tar | wc -l
	6017
	root@terre:/mnt/memdisk# tar -tf backup.tar | grep -v "lib/modules/4.19.0-12-amd64" | wc -l
	1626
	root@terre:/mnt/memdisk# tar -tf backup.tar | grep "lib/modules/4.19.0-12-amd64" | wc -l
	4391
	root@terre:/mnt/memdisk# tar -tf backup.tar | grep "lib/modules" | wc -l
	4391
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      The backup contains a total of 6017 entries, 1626 are out of the <code>lib/modules/4.19.0-12-amd64</code>
      directory, the rest is all in that previous directory, nothing else is found in <code>lib/modules</code>
      while there was <code>lib/modules/4.19.0-11-amd64</code> and <code>lib/modules/4.19.0-10-amd64</code>
      subdirectory. We can thus mix included and included directories.
    </p>

    <h4>Data filtering by filename</h4>

    <h5>Dar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R /lib -X "*.ko"


	--------------------------------------------
	4122 inode(s) saved
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	<e>10677 inode(s) ignored (excluded by filters)</e>
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 14799
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 3945 inode(s)
	--------------------------------------------
	root@terre:/mnt/memdisk# mkdir DST
	root@terre:/mnt/memdisk# dar -x backup -R DST --fsa-scope none


	--------------------------------------------
	4122 inode(s) restored
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 4122
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	root@terre:/mnt/memdisk# find DST -name "*.ko" -ls
	root@terre:/mnt/memdisk#
    </code></div>

    <p>
      we would exclude all file having the <code>ko</code> extension, what if we do not
      want to exclude those that start with <code>ext</code>?
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R /lib -am -X "*.ko" -I "ext*"


	--------------------------------------------
	4128 inode(s) saved
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	10671 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 14799
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 3951 inode(s)
	--------------------------------------------
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# mkdir DST
	root@terre:/mnt/memdisk# dar -x backup -R DST --fsa-scope none -q
	root@terre:/mnt/memdisk# find DST -name "*.ko" -print
	DST/modules/4.19.0-10-amd64/kernel/fs/ext4/ext4.ko
	DST/modules/4.19.0-10-amd64/kernel/drivers/extcon/extcon-core.ko
	DST/modules/4.19.0-11-amd64/kernel/fs/ext4/ext4.ko
	DST/modules/4.19.0-11-amd64/kernel/drivers/extcon/extcon-core.ko
	DST/modules/4.19.0-12-amd64/kernel/fs/ext4/ext4.ko
	DST/modules/4.19.0-12-amd64/kernel/drivers/extcon/extcon-core.ko
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      OK, we got what we wanted
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# rsync -arHAXS -f "- *.ko"  /lib DST
	root@terre:/mnt/memdisk# find DST -name "*.ko" -print
	root@terre:/mnt/memdisk# ls DST
	lib
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      Same as previously, we don't want to exclude <code>ko</code> files starting by <code>ext</code>:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# rsync -arHAXS -f "+ ext*" -f "- *.ko" /lib DST
	root@terre:/mnt/memdisk# find DST -name "*.ko" -print
	DST/lib/modules/4.19.0-12-amd64/kernel/fs/ext4/ext4.ko
	DST/lib/modules/4.19.0-12-amd64/kernel/drivers/extcon/extcon-core.ko
	DST/lib/modules/4.19.0-11-amd64/kernel/fs/ext4/ext4.ko
	DST/lib/modules/4.19.0-11-amd64/kernel/drivers/extcon/extcon-core.ko
	DST/lib/modules/4.19.0-10-amd64/kernel/fs/ext4/ext4.ko
	DST/lib/modules/4.19.0-10-amd64/kernel/drivers/extcon/extcon-core.ko
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      OK, we got what we wanted
    </p>

    <h5>Tar</h5>
    <p>Same as previously, let's filter out kernel object files</p>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar -cf backup.tar --exclude "*.ko" /lib
	tar: Removing leading `/' from member names
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# mkdir DST
	root@terre:/mnt/memdisk# cd DST
	root@terre:/mnt/memdisk/DST# tar -xf ../backup.tar
	root@terre:/mnt/memdisk/DST# find . -name "*.ko" -print
	root@terre:/mnt/memdisk/DST#
    </code></div>
    <p>Now, we want to keep only those kernel object files starting with <code>ext</code></p>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar -cf backup.tar "ext*" --exclude "*.ko" /lib
	tar: ext*: Cannot stat: No such file or directory
	tar: Removing leading `/' from member names
	tar: Removing leading `/' from hard link targets
	tar: Exiting with failure status due to previous errors
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      Well, argument passed out of option do not seem expanded by tar thus using mask is not
      possible to include some pattern. It seems the only option is to use file listing, thing
      we will evaluate below.
    </p>

    <h4>Data filtering by filesystem</h4>

    <p>
      We will use a tmpfs filesystem mounted twice thanks to mount's --bind option. The objective
      is first to save every thing except a few given filesystems, or only one or save inside a few
      given filesystems. Here is the preparation phase:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# mkdir SRC
	root@terre:/mnt/memdisk# mkdir SRC/D1 SRC/D2 SRC/D3
	root@terre:/mnt/memdisk# mount -t tmpfs tmpfs SRC/D1
	root@terre:/mnt/memdisk# mount --bind SRC/D1 SRC/D2
	root@terre:/mnt/memdisk# mount -t tmpfs tmpfs SRC/D3
	root@terre:/mnt/memdisk# ls SRC/D1 SRC/D2
	SRC/D1:

	SRC/D2:
	root@terre:/mnt/memdisk# echo "Hello World" > SRC/D1/file.txt
	root@terre:/mnt/memdisk# ls SRC/D1 SRC/D2
	SRC/D1:
	file.txt

	SRC/D2:
	file.txt
	root@terre:/mnt/memdisk# echo "give me your data, I'll tell your needs and what to buy" > SRC/gafam.com
	root@terre:/mnt/memdisk# echo "sight" > SRC/D3/democracy.org
	root@terre:/mnt/memdisk#
    </code></div>

    <h5>Dar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R SRC -MX:/mnt/memdisk/SRC/D1 -vs -vt -q
	Adding folder to archive: /mnt/memdisk/SRC/D3
	Adding file to archive: /mnt/memdisk/SRC/D3/democracy.org
	Adding file to archive: /mnt/memdisk/SRC/gafam.com
	Skipping file: /mnt/memdisk/SRC/D2
	Skipping file: /mnt/memdisk/SRC/D1
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      We could exclude a filesystem, and its second appearance in D2 was also excluded,
      whithout having to mention it. Let's include only <code>D1</code> now:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# rm -f backup.1.dar
	root@terre:/mnt/memdisk# dar -c backup -R SRC -MI:/mnt/memdisk/SRC/D1 -vs -vt -q
	Skipping file: /mnt/memdisk/SRC/D3
	Adding file to archive: /mnt/memdisk/SRC/gafam.com
	Adding folder to archive: /mnt/memdisk/SRC/D2
	Adding file to archive: /mnt/memdisk/SRC/D2/file.txt
	Adding folder to archive: /mnt/memdisk/SRC/D1
	Adding file to archive: /mnt/memdisk/SRC/D1/file.txt
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      OK, we got what we wanted
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# rsync -arvHAXS --one-file-system SRC DST
	sending incremental file list
	created directory DST
	SRC/
	SRC/gafam.com
	SRC/D1/
	SRC/D2/
	SRC/D3/

	sent 283 bytes  received 77 bytes  720.00 bytes/sec
	total size is 56  speedup is 0.16
	root@terre:/mnt/memdisk#
    </code></div>

    <p>
      <i>rsync</i> has ony one option about filesystems, it sticks recursion to the filesystem
      of the source directory, we cannot exclude specifically some filesystems, they are all excluded,
      and we cannot include specifically some filesystems, none is excluded (default behavior without this option)
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar -cvf backup.tar --one-file-system SRC
	SRC/
	SRC/D3/
	tar: SRC/D3/: file is on a different filesystem; not dumped
	SRC/gafam.com
	SRC/D2/
	tar: SRC/D2/: file is on a different filesystem; not dumped
	SRC/D1/
	tar: SRC/D1/: file is on a different filesystem; not dumped
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      <i>tar</i> does not behaves better than rsync on that topic
    </p>

    <h4>Data filtering by tag</h4>
    <p>
      by tag we mean any mark the user can add to a file that will drive its fate when backup will be done.
      The most common is the <i>dump</i> flag, but it is not always available, using some other mechanisms
      (Extended Attributes,...) can be an interesting alternative.
    </p>

    <h5>Dar</h5>
    <div class=code><code>
	root@terre:/var/tmp# mkdir SRC
	root@terre:/var/tmp# echo "Hello" > file1.txt
	root@terre:/var/tmp# echo "World" > file2.txt
	root@terre:/var/tmp# chattr <e class=blue>+d</e> file1.txt
	root@terre:/var/tmp# setfattr -n <e>user.no_dump</e> file2.txt
	root@terre:/var/tmp# mv file1.txt file2.txt SRC
	root@terre:/var/tmp# dar -c backup -w -R SRC  <e class=blue>--nodump</e> -vt -q
	<e>Adding file to archive: /var/tmp/SRC/file2.txt</e>
	Saving Extended Attributes for /var/tmp/SRC/file2.txt
	Saving Filesystem Specific Attributes for /var/tmp/SRC/file2.txt
	root@terre:/var/tmp# dar -c backup -w -R SRC  <e>--exclude-by-ea=user.no_dump</e> -vt -q
	<e class=blue>Adding file to archive: /var/tmp/SRC/file1.txt</e>
	Saving Filesystem Specific Attributes for /var/tmp/SRC/file1.txt
	root@terre:/var/tmp#
    </code></div>
    <p>
      We have two mechanisms, one based on the <i>dump</i> flag and an arbitrary extended attribute.
      However <i>dar</i> only supports exclusion of file, not inclusion for backup based on a tag.
    </p>

    <h5>Rsync</h5>
    <p>
      <i>rsync</i> does not seem to be able to filter based on an arbitrary mark
    </p>

    <h5>Tar</h5>
    <p>
      <i>rsync</i> does not seem to be able to filter based on an arbitrary mark
    </p>

    <h4>Data filtering by files listing</h4>

    <p>
      We build a file listing and expect to either have only those file saved
      or excluded from the performed backup. Here is the listing preparation:
    </p>

    <div class=code><code>
	root@terre:/mnt/memdisk# find /lib -name "*.ko" -o -print  > include.txt
	root@terre:/mnt/memdisk# wc -l include.txt
	4123 include.txt
	root@terre:/mnt/memdisk# find /lib -name "*.ko" -print  > exclude.txt
	root@terre:/mnt/memdisk# wc -l exclude.txt
	10677 exclude.txt
	root@terre:/mnt/memdisk#
    </code></div>

    <h5>Dar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R /lib -[ include.txt


	--------------------------------------------
	<e>4122 inode(s) saved</e>
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	<e>10677 inode(s) ignored (excluded by filters)</e>
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 14799
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 3945 inode(s)
	--------------------------------------------
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      file inclusion is available, let's see file exclusion:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R /lib -] exclude.txt


	--------------------------------------------
	<e>4122 inode(s) saved</e>
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	<e>10677 inode(s) ignored (excluded by filters)</e>
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 14799
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 3945 inode(s)
	--------------------------------------------
	root@terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# rsync -aHAXS --files-from=include.txt / DST
	root@terre:/mnt/memdisk# find DST -print | wc -l
	4124
	root@terre:/mnt/memdisk# find DST -name "*.ko" -print
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      file inclusion is available. However if we can exclude a list of pattern
      defined in a file, we cannot exclude a list of files. We should prepend each
      entry by "- " seen the filtering syntax of rsync:
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# sed -r 's/^/- /' exclude.txt  > rsync-exclude.txt
	root@terre:/mnt/memdisk# rm -rf DST
	root@terre:/mnt/memdisk# rsync -aHAXS --exclude-from=rsync-exclude.txt /lib DST
	root@terre:/mnt/memdisk# find DST -print | wc -l
	4124
	root@terre:/mnt/memdisk# find DST -name "*.ko" -print | wc -l
	0
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      So we are good
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar -cvf backup.tar --files-from=include.txt | wc -l
	tar: Removing leading `/' from member names
	98017
	root@terre:/mnt/memdisk# tar -tf backup.tar | grep .ko | wc -l
	73392
	root@terre:/mnt/memdisk# grep .ko include.txt | wc -l
	3
	root@terre:/mnt/memdisk# grep .ko include.txt
	/lib/modules/4.19.0-12-amd64/kernel/sound/pci/korg1212
	/lib/modules/4.19.0-11-amd64/kernel/sound/pci/korg1212
	/lib/modules/4.19.0-10-amd64/kernel/sound/pci/korg1212
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      the include.txt file does not contain any file with the ko extension, however <i>tar</i>
      saved all of them. Reading back the man page concerning this --files-from option
      <i>The names read are handled the same way as command line arguments</i> explains that
      in the listing where all <code>"*.ko"</code> files have been removed, remain their parent
      directory, which implies saving all its content. In consequence we must not list
      directories only their content (which will drop not allow saving empty directories).
      Let's modify the include.txt file that way:
    </p>
    <div class=code><code>
	find /lib -type d -o -name "*.ko" -o -print  > tar-include.txt
	root@terre:/mnt/memdisk# tar -cvf backup.tar --files-from=tar-include.txt | wc -l
	tar: Removing leading `/' from member names
	1532
	root@terre:/mnt/memdisk# tar -tvf backup.tar | grep "*.ko"
	root@terre:/mnt/memdisk# wc -l tar-include.txt
	1532 tar-include.txt
	root@terre:/mnt/memdisk# wc -l include.txt
	4123 include.txt
    </code></div>
    <p>
      the difference if between 1532 entries saved by <i>tar</i> compared to the
      4123 saved by <i>rsync</i> or <i>dar</i> comes from the many empty directories
      that have cannot be saved as such by <i>tar</i> using this method
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk# tar -cvf backup.tar --exclude-from=exclude.txt /lib | wc -l
	tar: Removing leading `/' from member names
	4123
	root@terre:/mnt/memdisk# wc -l exclude.txt
	10677 exclude.txt
	root@terre:/mnt/memdisk# tar -tf backup.tar | egrep "\.ko$"
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      The file listing exclusion works as expected
    </p>

    <h4>Slicing</h4>

    <p>
      For this test we will backup the content of /usr/bin of the running system.
      We select a slice size smaller than the biggest file under backup. The use case for
      slicing implies compression (remote storage, cloud storage, limited removable
      media storage...).
    </p>

    <div class=code><code>
	root@terre:/mnt/memdisk# ls -lh --sort=size /usr/bin | tac | tail
	-rwxr-xr-x 1 root   root       8.0M Dec 18  2018 luajittex
	-rwxr-xr-x 1 root   root       8.1M Dec 18  2018 luatex53
	-rwxr-xr-x 1 root   root       8.1M Dec 18  2018 luatex
	-rwxr-xr-x 1 root   root       8.2M May 27  2019 wireshark
	-rwxr-xr-x 1 root   root        12M Dec 21  2018 kstars
	-rwxr-xr-x 1 root   root        15M Mar 12  2018 doxygen
	-rwxr-xr-x 1 root   root        16M Jan  4  2019 stellarium
	-rwxr-xr-x 1 root   root        19M Oct 12 19:46 mysql_embedded
	-rwxr-xr-x 1 root   root        <e>39M</e> Sep  5  2019 emacs-gtk
	total 430M
	root@terre:/mnt/memdisk#
    </div></code>

    <h5>Dar</h5>

    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R /usr/bin -z6 <e>-s 20M</e> -q
	terre:/mnt/memdisk# ls -lh backup.*
	-rw-r--r-- 1 root root  <e>20M</e> Nov 13 11:30 backup.1.dar
	-rw-r--r-- 1 root root  20M Nov 13 11:30 backup.2.dar
	-rw-r--r-- 1 root root  20M Nov 13 11:30 backup.3.dar
	-rw-r--r-- 1 root root  20M Nov 13 11:30 backup.4.dar
	-rw-r--r-- 1 root root  20M Nov 13 11:30 backup.5.dar
	-rw-r--r-- 1 root root  20M Nov 13 11:30 backup.6.dar
	-rw-r--r-- 1 root root  20M Nov 13 11:30 backup.7.dar
	-rw-r--r-- 1 root root <e>7.7M</e> Nov 13 11:30 backup.8.dar
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# dar -x backup -R DST -g emacs-gtk <e>-E "echo openning slice %p/%b.%N.%e"</e>
	<e>openning slice /mnt/memdisk/backup.8.dar</e>
	<e>openning slice /mnt/memdisk/backup.4.dar</e>
	<e>openning slice /mnt/memdisk/backup.5.dar</e>
	Restoration of FSA for /mnt/memdisk/DST/emacs-gtk aborted: Failed reading existing extX family FSA: Inappropriate ioctl for device
	Restoration of linux immutable FSA for /mnt/memdisk/DST/emacs-gtk aborted: Failed reading existing extX family FSA: Inappropriate ioctl for device


	--------------------------------------------
	1 inode(s) restored
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	2591 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 2592
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# diff DST/emacs-gtk /usr/bin/emacs-gtk
	memdiskerre:/mnt/memdisk# echo $?
	0
	terre:/mnt/memdisk#
    </code></div>

    <p>
      We can also specify a different size for the first slice, this was used in the past
      to fulfill a disk partially filled by a previous incremental backup when saving onto CD-RW
      and DVD-RW, but that may still make sense when using USB keys or any other removable media.
    </p>

    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R /usr/bin <e class=blue>-s 20M</e> <e>-S 1M</e> -q --min-digit 3
	root@terre:/mnt/memdisk# ls -lh
	total 361M
	-rw-r--r-- 1 root root <e>1.0M</e> Nov  6 18:57 backup.001.dar
	-rw-r--r-- 1 root root  <e class=blue>20M</e> Nov  6 18:57 backup.002.dar
	-rw-r--r-- 1 root root  <e class=blue>20M</e> Nov  6 18:57 backup.003.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.004.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.005.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.006.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.007.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.008.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.009.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.010.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.011.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.012.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.013.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.014.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.015.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.016.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.017.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.018.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:57 backup.019.dar
	root@terre:/mnt/memdisk# dar -c backup -R /usr/bin -s 20M <e>-S 200M</e> -q --min-digit 3
	root@terre:/mnt/memdisk# ls -lh
	total 361M
	-rw-r--r-- 1 root root <e>200M</e> Nov  6 18:58 backup.001.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.002.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.003.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.004.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.005.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.006.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.007.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.008.dar
	-rw-r--r-- 1 root root  20M Nov  6 18:59 backup.009.dar
	-rw-r--r-- 1 root root 913K Nov  6 18:59 backup.010.dar
	root@terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <p>
      rsync cannot split any file in slices, and it does not generate any backup, but it copies files.
      You cannot thus split in slices an tar archive in the hope to not download all of them to restore
      a particular file.
    </p>

    <h5>Tar</h5>

    <div class=code><code>
    	terre:/mnt/memdisk# tar -czf backup.tar -M -L 20480 /usr/bin
	<e class=red>tar: Cannot use multi-volume compressed archives</e>
	Try 'tar --help' or 'tar --usage' for more information.
	root@terre:/mnt/memdisk#
    </code></div>

    <p>
      As reported by <i>tar</i> above, if a multi-volume support exists, it is quite restrictive as
      one cannot use compression at the same time.
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# tar -cf backup -M -L 20480 /usr/bin
	tar: Removing leading `/' from member names
	<e class=red>Prepare volume #2 for 'backup' and hit return:</e>
	tar: Removing leading `/' from hard link targets
	<e class=red>Prepare volume #3 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #4 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #5 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #6 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #7 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #8 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #9 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #10 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #11 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #12 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #13 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #14 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #15 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #16 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #17 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #18 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #19 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #20 for 'backup' and hit return:</e>
	<e class=red>Prepare volume #21 for 'backup' and hit return:</e>
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# ls -l backup*
	-rw-r--r-- 1 root root 19527680 Nov 13 11:40 backup
	terre:/mnt/memdisk#
    </code></div>

    <p>
      But even without compression, <i>tar</i> is still restrictive: it does not produce
      different files, you have each new volume around and <code>hit return</code> at each time.
      <br/>
      Note also that without compression, the space required passes
      from 8 volumes with <i>dar</i> to 21 volumes with <i>tar</i>.
    </p>
    <p>
      The multi-volume support for <i>tar</i> seems well defined for
      local tape removable devices, but will cost more than twice more
      tape than what you can do with <i>dar</i> even if tape media
      is your only target. Here is an example with <i>dar</i> on how
      to write to mutli-volume and compressed backup to tape and pause
      between each volume:
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# <e>dar</e> -c backup -R /usr/bin -z6 -s 20M <e class=green>-E "echo writing volume %N to tape"</e> <e>-E "cat < %p/%b.%N.%e > /dev/mt"</e> <e class=blue>-p</e>
	class=green>writing volume 1 to tape
	Finished writing to file 1, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 2 to tape
	Finished writing to file 2, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 3 to tape
	Finished writing to file 3, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 4 to tape
	Finished writing to file 4, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 5 to tape
	Finished writing to file 5, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 6 to tape
	Finished writing to file 6, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 7 to tape
	Finished writing to file 7, ready to continue ?  [return = YES | Esc = NO]
	Continuing...
	writing volume 8 to tape


	--------------------------------------------
	2592 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2592
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2152 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk#
    </code></div>

    <h4>Symmetric encryption</h4>

    <p>
      Encryption has for target relatively long term lifetime, having compression at the same
      time to increase security as it increases data "randomness" of the data to cipher. So we will use both in our tests (gzip with a compresion level of 6).
    </p>
    <p>
      A point to pay attention concerns the way the password/passphrase can be provided. Putting this
      to the command-line could let other users on this same system read it. Having interactive
      prompt is better as well as having the password set in a read access restricted file, which
      in addition allows automation.
    </p>

    <h5>Dar</h5>
    <div class=code><code>
	root@terre:/mnt/memdisk# dar -c backup -R / -g usr/bin -K aes256: -q -z6
	Archive backup <e>requires a password:</e>
	Please <e>confirm your password:</e>
	root@terre:/mnt/memdisk# dar -l backup -q
	Archive backup <e>requires a password:</e>
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	Archive version format               : 11
	Compression algorithm used           : <e>gzip</e>
	Compression block size used          : 0
	Symmetric key encryption used        : <e>AES 256</e>
	Asymmetric key encryption used       : none
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : N/A
	KDF iteration count                  : <e>10000</e>
	KDF hash algorithm                   : <e>argon2</e>
	<e>Salt</e> size                            : 32 bytes
	Catalogue size in archive            : 101907 bytes

	Archive is composed of 1 file(s)
	File size: 155070897 bytes
	The global data compression ratio is:   64%

	CATALOGUE CONTENTS :

	total number of inode : 2589
	fully saved           : 2589
	binay delta patch     : 0
	inode metadata only   : 0
	distribution of inode(s)
	- directories        : 2
	- plain files        : 2152
	- symbolic links     : 435
	- named pipes        : 0
	- unix sockets       : 0
	- character devices  : 0
	- block devices      : 0
	- Door entries       : 0
	hard links information
	- number of inode with hard link           : 5
	- number of reference to hard linked inodes: 10
	destroyed entries information
	0 file(s) have been record as destroyed since backup of reference

	root@terre:/mnt/memdisk# touch pass.dcf
	root@terre:/mnt/memdisk# chmod go-rwx pass.dcf
	root@terre:/mnt/memdisk# cat >> pass.dcf
	-K "aes256:hello world!"
	root@terre:/mnt/memdisk# ls -l pass.dcf
	-rw------- 1 root root 25 Nov  9 11:37 pass.dcf
	root@terre:/mnt/memdisk# rm backup.1.dar
	rm: remove regular file 'backup.1.dar'? y
	root@terre:/mnt/memdisk# dar -c backup -R / -g usr/bin -B pass.dcf -q -z6
	root@terre:/mnt/memdisk# dar -l backup -q -B pass.dcf
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	Archive version format               : 11
	Compression algorithm used           : gzip
	Compression block size used          : 0
	Symmetric key encryption used        : AES 256
	Asymmetric key encryption used       : none
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : N/A
	KDF iteration count                  : 10000
	KDF hash algorithm                   : argon2
	Salt size                            : 32 bytes
	Catalogue size in archive            : 102310 bytes

	Archive is composed of 1 file(s)
	File size: 155132433 bytes
	The global data compression ratio is:   64%

	CATALOGUE CONTENTS :

	total number of inode : 2589
	fully saved           : 2589
	binay delta patch     : 0
	inode metadata only   : 0
	distribution of inode(s)
	- directories        : 2
	- plain files        : 2152
	- symbolic links     : 435
	- named pipes        : 0
	- unix sockets       : 0
	- character devices  : 0
	- block devices      : 0
	- Door entries       : 0
	hard links information
	- number of inode with hard link           : 5
	- number of reference to hard linked inodes: 10
	destroyed entries information
	0 file(s) have been record as destroyed since backup of reference

	root@terre:/mnt/memdisk#

    </code></div>
    <p>
      We can provide password either on command-line (not recommended), prompted by dar once launched
      or from a protected configuration file. In the following we add slicing to encryption to see
      whether or not <i>dar</i> deciphers the whole backup to recover a single file:
    </p>

    <div class=code><code>
	root@terre:/mnt/localdisk# rm -rf backup.*
	root@terre:/mnt/localdisk# dar -c backup -R / -g usr/bin -K aes256: -s 1M -q -z6
	Archive backup requires a password:
	Please confirm your password:
	root@terre:/mnt/localdisk# ls -l backup.* | wc -l
	<e>148</e>
	root@terre:/mnt/localdisk# dar -x backup -g usr/bin/emacs-gtk -E "echo openning slice %b.%N.%e" -q
	openning slice backup.148.dar
	Archive backup requires a password:
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	<e>openning slice backup.1.dar</e>
	<e>openning slice backup.80.dar</e>
	<e>openning slice backup.81.dar</e>
	<e>openning slice backup.82.dar</e>
	<e>openning slice backup.83.dar</e>
	<e>openning slice backup.84.dar</e>
	root@terre:/mnt/localdisk#
    </code></div>
    <p>
      As seen above, dar does not need to uncipher nor uncompress the whole backup to recover a single file, the use
      of slicing let us see which slice it accessed to, but the behavior is the same without
      slicing and can be measure by the execution time (see the performance tests logs).
    </p>

    <h5>Rsync</h5>
    <p>
      <i>rsync</i> cannot cipher data, it can rely on ssh to cipher the data over the network
      but data is finally always stored in clear text.
    </p>

    <h5>Tar</h5>

    <p>
      There is no native support for ciphering with <i>tar</i>. You can however pipe <i>tar</i>'s output
      to openssl to cipher the generated backup on fly as a whole.
    </p>
    <div class=code><code>
	root@terre:/mnt/memdisk#  tar -czf - /usr/bin | openssl enc -e -aes256 -out backup.tar.gz.crypted
	tar: Removing leading `/' from member names
	enter aes-256-cbc encryption password:
	Verifying - enter aes-256-cbc encryption password:
	<e>*** WARNING : deprecated key derivation used.</e>
	<e>Using -iter or -pbkdf2 would be better.</e>
	tar: Removing leading `/' from hard link targets
	root@terre:/mnt/memdisk# openssl enc -d -aes256 -in backup.tar.gz.crypted | tar -xz
	enter aes-256-cbc decryption password:
	<e>*** WARNING : deprecated key derivation used.</e>
	<e>Using -iter or -pbkdf2 would be better.</e>
	root@terre:/mnt/memdisk# tar -czf - /usr/bin | openssl enc -e -aes256 -out backup.tar.gz.crypted -pass file:pass.txt
	tar: Removing leading `/' from member names
	<e>*** WARNING : deprecated key derivation used.</e>
	<e>Using -iter or -pbkdf2 would be better.</e>
	tar: Removing leading `/' from hard link targets
	root@terre:/mnt/memdisk# openssl enc -d -aes256 -in backup.tar.gz.crypted -pass file:pass.txt | tar -xz
	<e>*** WARNING : deprecated key derivation used.</e>
	<e>Using -iter or -pbkdf2 would be better.</e>
	root@terre:/mnt/memdisk#
    </code></div>
    <p>
      with openssl, <i>tar</i> has both the ability to provide the password/passphrase from an interactive prompt and from a protected file.
      However you will have to remember which algorithm you used in adition to the passphrase. The ciphering being done
      as a whole, you will have to decipher the whole backup even to just restore a single file.
      If the backup is large, this may take a long time and may require to download a lot of stuff from a remote storage.
    </p>
    <p>
      We see that ciphering with <i>tar</i> is possible at the cost of some complex command-line. But this is
      error-prone as we see the shown warning that the key derivation function is deprecated and we should switch to
      another one. Moreover you will have to remember which key derivation function and its parameters in addition to the
      passphrase you provided and in addition to the ciphering algorithm used.
    </p>
    <p>
      <u>Note:</u> you can also use <i>openssl</i> with <i>dar</i> as we did for <i>tar</i> but it brings all the drawbacks we saw with <i>tar</i>
    </p>

    <h4>Asymmetric encryption</h4>

    <p>
      The objective is to create a backup ciphered using GnuPG public/private key pair, restore the whole backup and
      restore a single file from it. We will also use compression (gzip level 6) as it may make sense for the
      corresponding use cases (data exchange over Internet for example).
    </p>
    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -K gnupg::root@terre.systeme-solaire.espace -R SRC -z6 -q
	terre:/mnt/memdisk# dar -l backup -q
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	Archive version format               : 11
	Compression algorithm used           : <e>gzip</e>
	Compression block size used          : 0
	Symmetric key encryption used        : <e>AES 256</e>
	Asymmetric key encryption used       : <e>gnupg</e>
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : N/A
	Catalogue size in archive            : 68669 bytes

	Archive is composed of 1 file(s)
	File size: 158261425 bytes
	The global data compression ratio is:   64%

	CATALOGUE CONTENTS :

	total number of inode : 2593
	fully saved           : 2593
	binay delta patch     : 0
	inode metadata only   : 0
	distribution of inode(s)
	- directories        : 1
	- plain files        : 2157
	- symbolic links     : 435
	- named pipes        : 0
	- unix sockets       : 0
	- character devices  : 0
	- block devices      : 0
	- Door entries       : 0
	hard links information
	- number of inode with hard link           : 0
	- number of reference to hard linked inodes: 0
	destroyed entries information
	0 file(s) have been record as destroyed since backup of reference

	terre:/mnt/memdisk# ls -l backup.1.dar
	-rw-r--r-- 1 root root 158261425 Nov  9 16:04 backup.1.dar
	terre:/mnt/memdisk#
    </code></div>

    <p>
      As displayed in the backup header output above the underlying encryption is a symmetric encryption
      (AES 256 by default), but the AES key is stored ciphered using the private key of the backup recipient
      which email address is provided (or email adresses, if more than one
      recipient is expected). This key is randomly chosen by dar and stored ciphered in the archive header.
      Thus the overall behavior, performance and security of GnuPG withing dar is equivalent
      to the one of the symmetrical algorithm chosen, with the ability to quickly restore some or all files
      from an archive, and not waiting/downloading first the whole backup to unciphered it.
    </p>
    <p>
      Seen above no password or passphrase is asked as the recipient email is ourselves
      (root@terre.systeme-solaire.espace). Let's cipher for another recipient:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -K <e class=blue>gnupg::dar.linux@free.fr</e> -R SRC -z6 -q -w
	terre:/mnt/memdisk# ls -l backup.1.dar
	-rw-r--r-- 1 root root <e>158230913</e> Nov  9 16:22 backup.1.dar
	terre:/mnt/memdisk# dar -l backup -q
	FATAL error, aborting operation: Unexpected error reported by GPGME: <e>No secret key</e>
	terre:/mnt/memdisk# dar -c backup -K <e class=blue>gnupg::dar.linux@free.fr,root@terre.systeme-solaire.espace</e> -R SRC -z6 -q -w
	terre:/mnt/memdisk# dar -l backup -q
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	Archive version format               : 11
	Compression algorithm used           : gzip
	Compression block size used          : 0
	Symmetric key encryption used        : AES 256
	Asymmetric key encryption used       : gnupg
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : N/A
	Catalogue size in archive            : 68624 bytes

	Archive is composed of 1 file(s)
	File size: 158252223 bytes
	The global data compression ratio is:   64%

	CATALOGUE CONTENTS :

	total number of inode : 2593
	fully saved           : 2593
	binay delta patch     : 0
	inode metadata only   : 0
	distribution of inode(s)
	- directories        : 1
	- plain files        : 2157
	- symbolic links     : 435
	- named pipes        : 0
	- unix sockets       : 0
	- character devices  : 0
	- block devices      : 0
	- Door entries       : 0
	hard links information
	- number of inode with hard link           : 0
	- number of reference to hard linked inodes: 0
	destroyed entries information
	0 file(s) have been record as destroyed since backup of reference

	terre:/mnt/memdisk#
    </code></div>
    <p>
      Here we saw that ciphering for a recipient different than ourself does not allow us to read the resulting backup,
      however we can define several recipients and if we add ourself, we can read the backup as well as our primary
      recipients.
    </p>

    <h5>Rsync</h5>

    <i>rsync</i> is not able to perform asymmetric encryption of backed up files.

    <h5>Tar</h5>
    <p>
      <i>Tar</i> cannot hold asymmetrical encryption alone, as for symmetrical encryption we must use an external tool
      that performes the ciphering operation outside the backup.
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# tar -czf - SRC | gpg --encrypt --recipient <e class=blue>root@terre.systeme-solaire.espace</e> --output backup.tar.gz.gpg
	terre:/mnt/memdisk# ls -l backup.tar.gz.gpg
	-rw-r--r-- 1 root root <e>155337814</e> Nov  9 16:45 backup.tar.gz.gpg
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# gpg --decrypt backup.tar.gz.gpg | tar -xzf -
	gpg: encrypted with 3072-bit RSA key, ID 97E13D38B007DF30, created 2020-08-08
	"root@terre &lt;root@terre.systeme-solaire.espace&gt;"
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# tar -czf - SRC | gpg --encrypt --recipient <e class=blue>dar.linux@free.fr</e> --output backup.tar.gz.gpg
	terre:/mnt/memdisk#  gpg --decrypt backup.tar.gz.gpg | tar -xzf -
	gpg: encrypted with 4096-bit RSA key, ID DB0A2141A4D96ECA, created 2012-09-13
	"Denis Corbin (http://dar.linux.free.fr/) &lt;dar.linux@free.fr&gt;"
	gpg: decryption failed: <e>No secret key</e>

	gzip: stdin: unexpected end of file
	tar: Child returned status 1
	tar: Error is not recoverable: exiting now
	terre:/mnt/memdisk#terre:/mnt/memdisk# tar -czf - SRC | gpg --encrypt --recipient <e class=blue>dar.linux@free.fr</e> \
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--recipient <e class=blue>root@terre.systeme-solaire.espace</e> --output backup.tar.gz.gpg
	terre:/mnt/memdisk#  gpg --decrypt backup.tar.gz.gpg | tar -xzf -
	gpg: encrypted with 4096-bit RSA key, ID DB0A2141A4D96ECA, created 2012-09-13
	"Denis Corbin (http://dar.linux.free.fr/) &lt;dar.linux@free.fr&gt;"
	gpg: encrypted with 3072-bit RSA key, ID 97E13D38B007DF30, created 2020-08-08
	"root@terre &lt;root@terre.systeme-solaire.espace&gt;"
	terre:/mnt/memdisk#
    </code></div>

    <p>
      Same as for symmetric encryption, the fact that the whole backup is ciphered at once implies to download
      back the whole backup even to recover just one file.
    </p>



    <h4>Protection against plain-text attack</h4>

    <h5>Dar</h5>

    <div class=code><code>
	devuan:/mnt/memdisk# time dar -c backup -K "aes256:hello world!" -at -1 0 -R SRC -q -w
	9.782u 3.413s <e>0:06.28</e> 210.0%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# la backup.1.dar
	-rw-r--r-- 1 root root 1572<e>706497</e> Nov  9 14:50 backup.1.dar
	devuan:/mnt/memdisk# time dar -c backup -K "aes256:hello world!" -at -1 0 -R SRC -q -w
	9.173u 2.845s <e>0:05.50</e> 218.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# la backup.1.dar
	-rw-r--r-- 1 root root 1572<e>655217</e> Nov  9 14:50 backup.1.dar
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      When ciphering the same data several times (with symmetric or asymmetric encryption),
      the resulting backup size changes each time. This is due to the garbage (the elastic
      buffer) dar adds at the beginnning and at the end of the data to cipher. This way,
      even if a dar backup has well known structure it is not easy to know precisely where
      they are positionned in the backup file, which makes plain-text attack much more difficult
      to succeed if even possible in a reasonable time.
    </p>


    <h5>Rsync</h5>
    <p>
      <i>rsync</i> does not provide any way to cipher the backup, it is thus not concerned by
      protecting against plain-text attack.
    </p>

    <h5>Tar</h5>
    <div class=code><code>
      devuan:/mnt/memdisk/SRC# time ../tar.backup ../backup.tar.crypted usr
      4.112u 2.343s 0:04.72 136.6%    0+0k 0+0io 0pf+0w
      devuan:/mnt/memdisk/SRC# ls -l ../bac
      backup.1.dar        backup.tar.crypted
      devuan:/mnt/memdisk/SRC# ls -l ../backup.tar.crypted
      -rw-r--r-- 1 root root <e>1603594272</e> Nov  9 14:56 ../backup.tar.crypted
      devuan:/mnt/memdisk/SRC# time ../tar.backup ../backup.tar.crypted usr
      3.952u 2.564s 0:04.79 135.9%    0+0k 0+0io 0pf+0w
      devuan:/mnt/memdisk/SRC# ls -l ../backup.tar.crypted
      -rw-r--r-- 1 root root <e>1603594272</e> Nov  9 14:56 ../backup.tar.crypted
      devuan:/mnt/memdisk/SRC#
    </code></div>
    <p>
      <i>tar</i> by itself does not provide any ciphering mechanism, however you can
      cipher the <i>tar</i> generated backups with external tool (for example <i>openssl</i>
      for symmetric encryption or <i>gpg</i> for asymmetric encryption). However none
      of these mechanism protect against plain-text attack: tar backup have somehow
      predictable header contents.
    </p>

    <h4>Key Derivation Function</h4>

    <h5>Dar</h5>

    <p>
      <i>dar</i> uses <code>argon2</code> by default, with 10,000 iterations. It can
      also use pkcs5 v2 (pbkdf2) with md5, sha1 or sha512 algorithm. The user
      is able to set the KDF function and iteration count, so we are able to measure
      the execution time variation added by the iteration count (taking into account that the data to cipher also
      changes depending on the amount of random garbage <i>dar</i> wraps it with):
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>100k</e>:<e class=blue>sha1</e> -w -q
	4.904u 0.572s <e>0:05.49</e> 99.6%     0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>500k</e>:sha1 -w -q
	5.805u 0.272s <e>0:06.08</e> 99.8%     0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>1M</e>:sha1 -w -q
	6.852u 0.308s <e>0:07.18</e> 99.5%     0+0k 0+0io 0pf+0w
	time dar -c backup -R SRC -K aes:hello --kdf-param 10k:argon2 -w -q
	5.092u 0.870s 0:03.50 170.2%    0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>10k</e>:<e class=blue>argon2</e> -w -q
	5.232u 0.760s <e>0:03.54</e> 169.2%    0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>20k</e>:argon2 -w -q
	5.778u 0.822s <e>0:04.14</e> 159.1%    0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>100k</e>:argon2 -w -q
	10.613u 0.831s <e>0:09.00</e> 127.1%   0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# time dar -c backup -R SRC -K aes:hello --kdf-param <e>1M:</e>argon2 -w -q
	66.862u 0.666s <e>1:05.14</e> 103.6%   0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>

    <p>
      <i>rsync</i> does not provide any way to cipher the backup, it is not concerned by KDF.
    </p>

    <h5>Tar</h5>

    <p>
      As of today (year 2020) <i>openssl</i> only supports PBKDF2: no support for argon2 is available.
      <a href="https://en.wikipedia.org/wiki/Argon2">Argon2</a> was the winner of the Password Hashing
      Competition in July 2015. <a href="https://en.wikipedia.org/wiki/PBKDF2">PBKDF2</a> has been
      published by the IETF in September 2000 with the
      <a href="https://tools.ietf.org/html/rfc2898">RCF 2898</a>

    </p>

    <h4>File change detection</h4>

    <p>
      In order stress each backup software on that aspect, we will use an ugly
      script that loops forever permanently invoking <code>touch</code> on a given file:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# cat always_change
	#!/bin/bash

	if [ -z "$1" ] ; then
	  echo "usage: $0 &lt;filename&gt;"
	  exit 1
	fi

	while /bin/true ; do  touch "$1" ; done
	terre:/mnt/memdisk#
    </code></div>

    <p>
      We create a source tree to backup, containing a file of 1 MiB on which we will
      apply this script:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# mkdir SRC
	terre:/mnt/memdisk# dd if=/dev/zero of=SRC/hello_world bs=10240 count=1024
	1024+0 records in
	1024+0 records out
	10485760 bytes (10 MB, 10 MiB) copied, 0.0107294 s, 977 MB/s
	terre:/mnt/memdisk# ./always_change SRC/hello_world &
	[1] 7433
	terre:/mnt/memdisk# stat SRC/hello_world
	File: SRC/hello_world
	Size: 10485760        Blocks: 20480      IO Block: 4096   regular file
	Device: 1bh/27d Inode: 375588      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
	Access: 2020-11-10 16:34:13.806106695 +0100
	<e>Modify: 2020-11-10 16:34:13.806106695 +0100</e>
	Change: 2020-11-10 16:34:13.806106695 +0100
	Birth: -
	terre:/mnt/memdisk# stat SRC/hello_world
	File: SRC/hello_world
	Size: 10485760        Blocks: 20480      IO Block: 4096   regular file
	Device: 1bh/27d Inode: 375588      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
	Access: 2020-11-10 16:34:14.838104981 +0100
	<e>Modify: 2020-11-10 16:34:14.838104981 +0100</e>
	Change: 2020-11-10 16:34:14.838104981 +0100
	Birth: -
	terre:/mnt/memdisk# jobs
	[1]  + Running                       ./always_change SRC/hello_world
	terre:/mnt/memdisk# ls -l SRC
	total 10240
	-rw-r--r-- 1 root root 10485760 Nov 10 16:34 hello_world
	terre:/mnt/memdisk#
    </code></div>

    <h5>Dar</h5>

    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R SRC -q
	<e>WARNING! File modified while reading it for backup, but no more retry allowed: /mnt/memdisk/SRC/hello_world</e>
	terre:/mnt/memdisk# dar -l backup
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[<e>DIRTY</e>][ ]       [---][  99%][X]  -rw-r--r--   0        0       10 Mio  Tue Nov 10 16:34:55 2020        hello_world
	terre:/mnt/memdisk# dar -x backup -R DST
	<e>File /mnt/memdisk/DST/hello_world has changed during backup and is probably not saved in a valid state ("dirty file"),</e>
	<e>do you want to consider it for restoration anyway? [return = YES | Esc = NO]</e>
	Continuing...


	--------------------------------------------
	1 inode(s) restored
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 1
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk#
    </code></div>

    <p>
      <ul>
	<li>
	  <i>dar</i> detects properly the file change and issues a warning during the backup.
	</li>
	<li>
	  It even retries to save the file several times (3 times by default).
	</li>
	<li>
	  the resulting backup keeps trace of this context by flagging the file as <code>DIRTY</code>
	</li>
	<li>
	  When restoring the data, a warning shows (by default) and the user is requested for confirmation (default behavior)
	</li>
      </ul>
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rsync -arvHAXqz --delete SRC DST
	terre:/mnt/memdisk#
    </code></div>
    <p>
     <i>rsync</i> does not shows anything not behaves differently (no retry).
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# tar -cf backup.tar SRC
	tar: SRC/hello_world: file changed as we read it
	terre:/mnt/memdisk# tar -tvf backup.tar
	drwxr-xr-x root/root         0 2020-11-10 16:33 SRC/
	-rw-r--r-- root/root  10485760 2020-11-10 16:41 SRC/hello_world
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xf ../backup.tar
	terre:/mnt/memdisk/DST# ls -l SRC
	total 10240
	-rw-r--r-- 1 root root 10485760 Nov 10 16:41 hello_world
	terre:/mnt/memdisk/DST#
    </code></div>

    <p>
      <ul>
	<li><i>tar</i> detects properly the file change and issues a warning during the backup.
	</li>
	<li>
	  it does not tries to save the file
	</li>
	<li>
	  the resulting backup keeps no visible trace of this possible data corruption
	</li>
	<li>
	  When restoring the data, no warning issued and the restoration proceed as if the file was saved properly
	</li>
      </ul>

    <h4>Multi-level backup</h4>

    <p>
      For this test we make a full backup of a Linux source tree, then
      rename the <i>Documentation</i> directory as <i>doc</i> and make a
      differential backup of the whole. Renaming files is expected to do at worse
      the same as removing some and adding new ones, whe should not see all data
      saved again:
    </p>

    <h5>Dar</h5>

    <div class=code><code>
	devuan:/mnt/memdisk# du -B1 -s SRC
	<e>1121144832</e>      SRC
	devuan:/mnt/memdisk# dar -c full -R SRC -z6 -q
	devuan:/mnt/memdisk# cd SRC/linux-5.9.2/
	devuan:/mnt/memdisk/SRC/linux-5.9.2# mv Documentation/ doc
	devuan:/mnt/memdisk/SRC/linux-5.9.2# cd ../..
	devuan:/mnt/memdisk# dar -c diff -A full -R SRC -z6 -q
	devuan:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root  <e>17858927</e> Nov  1 18:18 diff.1.dar
	-rw-r--r-- 1 root root <e>219047658</e> Nov  1 18:14 full.1.dar
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# dar -x full -R DST -q
	devuan:/mnt/memdisk# dar -x diff -R DST -q -w
	devuan:/mnt/memdisk# diff -r SRC DST && echo "same data" || echo "different data"
	same data
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      We can see that the restoration of the full and differential backup over it
      lead to the exact same directory tree as the source saved files.
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# rsync -arHAXz --delete --info=stats SRC/* BACKUP

	<e>sent 214,380,105 bytes  received 1,359,591 bytes  9,180,412.60 bytes/sec</e>
	total size is 954,869,250  speedup is 4.43
	devuan:/mnt/memdisk# cd SRC/linux-5.9.2/
	devuan:/mnt/memdisk/SRC/linux-5.9.2# mv Documentation/ doc
	devuan:/mnt/memdisk/SRC/linux-5.9.2# cd ../..
	devuan:/mnt/memdisk# rsync -arHAXz --delete --info=stats SRC/* BACKUP

	<e>sent 12,923,292 bytes  received 680,190 bytes  3,886,709.14 bytes/sec</e>
	total size is 954,869,250  speedup is 70.19
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# rsync -arHAXz --delete --info=stats BACKUP/* DST

	<e class=blue>sent 214,371,610 bytes  received 1,359,603 bytes  9,180,051.62 bytes/sec</e>
	total size is 954,869,250  speedup is 4.43
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      We see that after the modification the amount of data pushed to the backup by <i>rsync</i>
      passes from 214 MiB to only 12 MiB we can consider this as a differential backup, thus this
      part of the multi-level backup aspect is addressed, but we have lost the access to the first
      backup: it has been overwritten by the new one, so we lose history but that's a different feature.
    </p>

    <h5>Tar</h5>

    <div class=code><code>
	devuan:/mnt/memdisk# tar --listed-incremental=snapshot.file -czf full.tar.gz SRC
	devuan:/mnt/memdisk# cd SRC/linux-5.9.2/
	devuan:/mnt/memdisk/SRC/linux-5.9.2# mv Documentation/ doc
	devuan:/mnt/memdisk/SRC/linux-5.9.2# cd ../..
	devuan:/mnt/memdisk# tar --listed-incremental=snapshot.file -czf diff.tar.gz SRC
	devuan:/mnt/memdisk# ls -l
	total 190488
	drwxr-xr-x 3 root root        60 Oct 31 19:37 SRC
	-rw-r--r-- 1 root root   <e>9654445</e> Oct 31 19:49 diff.tar.gz
	-rw-r--r-- 1 root root <e>184036391</e> Oct 31 19:49 full.tar.gz
	-rw-r--r-- 1 root root   <e>1361962</e> Oct 31 19:49 snapshot.file
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# tar --listed-incremental=/dev/null -xf ../full.tar.gz
	devuan:/mnt/memdisk/DST# tar --listed-incremental=/dev/null -xf ../diff.tar.gz
	devuan:/mnt/memdisk/DST# cd ..
	devuan:/mnt/memdisk# diff -r SRC DST/SRC && echo "same data" || echo "different data"
	same data
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      Here too, we got the exact same directory as original and modified data
    </p>


    <h4>Binary Delta</h4>

    <p>
      To evaluate the ability the support for binary delta, we will make a first
      backup of a Debian ISO image, which we will modify by one bit and then
      make a differential backup of it. We expect to see the differential backup not
      resaving the whole file, and though the restoration of the full and differential
      backup matching the modified file.
    </p>

    <h5>Dar</h5>

    <div class=code><code>
	devuan:/mnt/memdisk# dar -c full -z6 -R SRC --delta sig -q
	devuan:/mnt/memdisk# ./bitflip 100000 SRC/debian-10.6.0-amd64-DVD-2.iso
	devuan:/mnt/memdisk# dar -c diff -A full -z6 -R SRC -q
	devuan:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root        <e>643</e> Nov  1 19:45 diff.1.dar
	-rw-r--r-- 1 root root <e>4704429776</e> Nov  1 19:05 full.1.dar
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# dar -x full -R DST -q
	devuan:/mnt/memdisk# dar -x diff -R DST -q
	devuan:/mnt/memdisk# diff -s SRC/debian-10.6.0-amd64-DVD-2.iso DST/debian-10.6.0-amd64-DVD-2.iso
	Files SRC/debian-10.6.0-amd64-DVD-2.iso and DST/debian-10.6.0-amd64-DVD-2.iso are identical
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      For <i>dar</i> the backup we used:
    </p>
    <ul>
      <li>4.3 GiB for the full backup (compression ratio of 0,21 %)</li>
      <li>614 bytes for the differential backup (compression ratio of 99,99998%)</li>
    </ul>

    <h5>Rsync</h5>

    <div class=code><code>
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# rsync -arHAX --info=stats SRC/* DST

	<e>sent 4,688,066,109 bytes  received 35 bytes  284,125,220.85 bytes/sec</e>
	total size is 4,686,921,728  speedup is 1.00
	devuan:/mnt/memdisk# ./bitflip  100000 SRC/debian-10.6.0-amd64-DVD-2.iso
	devuan:/mnt/memdisk# rsync -arHAX --info=stats SRC/* DST

	<e>sent 4,688,066,109 bytes  received 35 bytes  302,455,880.26 bytes/sec</e>
	<e class=red>total size is 4,686,921,728  speedup is 1.00</e>
	devuan:/mnt/memdisk# rsync -arHAXt --info=stats <e class=blue>--no-whole-file</e> SRC/* DST

	<e>sent 342,469 bytes  received 547,803 bytes  30,178.71 bytes/sec</e>
	total size is 4,686,921,728  speedup is 5,264.60
	devuan:/mnt/memdisk# diff -s SRC/debian-10.6.0-amd64-DVD-2.iso DST/debian-10.6.0-amd64-DVD-2.iso
	Files SRC/debian-10.6.0-amd64-DVD-2.iso and DST/debian-10.6.0-amd64-DVD-2.iso are identical
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      We had to use <code>--no-whole-file</code> to see the binary delta in action with
      <i>rsync</i>. This feature is not activated when copying on local disk as it
      does not makes sense (for <i>rsync</i>) because the computation time needed for the
      binary delta takes more time the the byte to byte copy and because <i>rsync</i> does
      not store just the delta (no backup history) but modifies the existing backup.
      Anyway, binary delta is supported (of course!) by <i>rsync</i>.
    </p>

    <h5>Tar</h5>

    <div class=code><code>
	devuan:/mnt/memdisk# tar --listed-incremental=snapshot.file -czf full.tar.gz SRC
	devuan:/mnt/memdisk#  ./bitflip 100000 SRC/debian-10.6.0-amd64-DVD-2.iso
	devuan:/mnt/memdisk# tar --listed-incremental=snapshot.file -czf diff.tar.gz SRC
	devuan:/mnt/memdisk# ls -l
	total 9133304
	drwxr-xr-x 2 root root         40 Oct 31 17:31 SRC
	-rwxr--r-- 1 root root        460 Oct 31 16:34 bitflip
	-rw-r--r-- 1 root root <e class=red>4676243904</e> Oct 31 17:28 diff.tar.gz
	-rw-r--r-- 1 root root <e>4676244172</e> Oct 31 17:24 full.tar.gz
	-rw-r--r-- 1 root root        107 Oct 31 17:28 snapshot.file
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# tar --listed-incremental=/dev/null -xf ../full.tar.gz
	devuan:/mnt/memdisk/DST# tar --listed-incremental=/dev/null -xf ../diff.tar.gz
	devuan:/mnt/memdisk/DST# diff -s ../SRC/debian-10.6.0-amd64-DVD-2.iso SRC/debian-10.6.0-amd64-DVD-2.iso
	Files ../SRC/debian-10.6.0-amd64-DVD-2.iso and SRC/debian-10.6.0-amd64-DVD-2.iso are identical
	devuan:/mnt/memdisk/DST#
    </code></div>

    <p>
      For <i>tar</i> the backup used:
    </p>

    <ul>
      <li>4.3 GiB for full backup (compression ratio of 0,22 %)</li>
      <li>4.3 GiB for the differential backup (compression ratio of 0,22 %)</li>
    </ul>
    <br/>
    <p>
      Binary delta is not supported by <i>tar</i>
    </p>

    <h4>Detection suspicious modifications</h4>

    <p>For this test we will use the following script that rely on the <i>bitflip</i> script
      seen above and try to hide the modifications performed, as a virus, keylogger or rootkit would
      tend to do. We will make a full backup before
      the modification and a differential backup after, then observe the behavior.

      <div class=code><code>
	  terre:/mnt/memdisk# cat hide_change
	  #!/bin/bash

	  if [ -z "$1" ] ; then
	  echo "usage: $0 &lt;filename&gt;"
	  echo "modify one bit and hide the change"
	  exit 1
	  fi

	  atime=`stat "$1" | sed -rn -s 's/^Access:\s+(.*)\+.*/\1/p'`
	  mtime=`stat "$1" | sed -rn -s 's/^Modify:\s+(.*)\+.*/\1/p'`

	  ./bitflip 2 "$1"

	  touch -d "$mtime" "$1"
	  touch -a -d "$atime" "$1"
	  terre:/mnt/memdisk#
      </code></div>

    <p>
      Here follows the script in action, we see no change using <code>ls -l</code>
      while <code>stat</code> shows the exact same information:
      <ul>
	<li>file size</li>
	<li>block used</li>
	<li>Inode number</li>
	<li>permissions</li>
	<li>user and group ownership</li>
	<li>last access time</li>
	<li>last modification time</li>
      </ul>
      The only change concerns the inode change time (ctime) that cannot be set manually
      and signals that some inode properties (but no file content) has changed. This
      condition occurs, when changing the file permission, ownership, extended
      attributes and so on, but should not occur when only file's data has changed.
    </p>

    </p>
    <div class=code><code>
	terre:/mnt/memdisk# mkdir SRC
	terre:/mnt/memdisk# echo "Hello World!" > SRC/file.txt
	terre:/mnt/memdisk# cat SRC/file.txt
	Hello World!
	terre:/mnt/memdisk# ls -l SRC/file.txt
	-rw-r--r-- 1 root root 13 Nov 12 13:13 SRC/file.txt
	terre:/mnt/memdisk# stat SRC/file.txt
	File: SRC/file.txt
	Size: 13              Blocks: 8          IO Block: 4096   regular file
	Device: 1bh/27d Inode: 424690      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
	Access: 2020-11-12 13:13:19.021978762 +0100
	Modify: 2020-11-12 13:13:09.213998852 +0100
	Change: 2020-11-12 13:13:<e>09.213998852</e> +0100
	Birth: -
	terre:/mnt/memdisk# ./hide_change SRC/file.txt
	terre:/mnt/memdisk# ls -l SRC/file.txt
	-rw-r--r-- 1 root root 13 Nov 12 13:13 SRC/file.txt
	terre:/mnt/memdisk# stat SRC/file.txt
	File: SRC/file.txt
	Size: 13              Blocks: 8          IO Block: 4096   regular file
	Device: 1bh/27d Inode: 424690      Links: 1
	Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
	Access: 2020-11-12 13:13:19.021978762 +0100
	Modify: 2020-11-12 13:13:09.213998852 +0100
	Change: 2020-11-12 13:13:<e>39.549936636</e> +0100
	Birth: -
	terre:/mnt/memdisk# cat SRC/file.txt
	Lello World!
	terre:/mnt/memdisk#
    </code></div>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# mkdir SRC
	terre:/mnt/memdisk# echo "Hello World!" > SRC/file.txt
	terre:/mnt/memdisk# dar -c full -R SRC -N


	--------------------------------------------
	1 inode(s) saved
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 1
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# ./hide_change SRC/file.txt
	terre:/mnt/memdisk# dar -c diff -A full -R SRC -N -q
	<e>SECURITY WARNING! SUSPICIOUS FILE /mnt/memdisk/SRC/file.txt: ctime changed since archive of reference was done, while no other inode information changed</e>
	terre:/mnt/memdisk#
    </code></div>

    <p>
      <i>dar</i> issues a warning because of this suspicious condition. Note that we still have the sane file in the full backup, in case of doubt,
      we can compare it with this modified version:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# dar -d full -R SRC -q
	DIFF /mnt/memdisk/SRC/file.txt: <e>different file data, offset of first difference is: 0</e>
	Some file comparisons failed
	terre:/mnt/memdisk#
    </code></div>

    <p>
      The previous test reports that the first byte to have changed is at offset 0, thus this is not just a metadata change
      that lead to this warning. We can if necessary restore the sane data from the full backup.
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rm -rf SRC
	terre:/mnt/memdisk# mkdir SRC
	terre:/mnt/memdisk# echo "Hello World!" > SRC/file.txt
	terre:/mnt/memdisk# rsync -arvHAX SRC DST
	sending incremental file list
	created directory DST
	SRC/
	SRC/file.txt

	sent 146 bytes  received 65 bytes  422.00 bytes/sec
	total size is 13  speedup is 0.06
	terre:/mnt/memdisk# ./hide_change SRC/file.txt
	terre:/mnt/memdisk# rsync -arvHAX SRC DST
	sending incremental file list

	sent 83 bytes  received 13 bytes  192.00 bytes/sec
	total size is 13  speedup is 0.14
	terre:/mnt/memdisk# cat SRC/file.txt
	<e>Lello World!</e>
	terre:/mnt/memdisk# cat DST/SRC/file.txt
	<e>Hello World!</e>
	terre:/mnt/memdisk#
    </code></div>

    <p>
      rsync has not reported the problem, but hopefully it has not synchronized the backup,
      thus we end in a sane version in the DST backup directory though, as user is not aware
      of this potential risk, the virus/ransomware can spread silently.
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rm -rf SRC
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# mkdir SRC
	terre:/mnt/memdisk# echo "Hello World!" > SRC/file.txt
	terre:/mnt/memdisk# tar --listed-incremental=snapshot.file -cf full.tar SRC
	terre:/mnt/memdisk# ./hide_change SRC/file.txt
	terre:/mnt/memdisk# tar --listed-incremental=snapshot.file -cvf diff.tar SRC
	SRC/
	SRC/file.txt
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xf ../full.tar
	terre:/mnt/memdisk/DST# cat SRC/file.txt
	<e>Hello World!</e>
	terre:/mnt/memdisk/DST# tar -xf ../diff.tar
	terre:/mnt/memdisk/DST# cat SRC/file.txt
	<e>Lello World!</e>
	terre:/mnt/memdisk/DST#
    </code></div>

    <p>
      As seen above <i>tar</i> does not see any problem, but the file has been resaved
      as a whole (while its last modification time was unchanged) which lead to corrupt the
      new backup with potential harmful data. The good point is that you have still the
      full backup with the sane data. But at a next backup cycle, as you were not notified of the
      risk, you will lose it and keep only the corrupted version of this file.
    </p>

    <h4>Snapshot</h4>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c full -z6 -R /usr <e>--on-fly-isolate snapshot</e>


	--------------------------------------------
	267245 inode(s) saved
	including 23 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 267245
	--------------------------------------------
	EA saved for 5 inode(s)
	FSA saved for 237962 inode(s)
	--------------------------------------------
	Now performing on-fly isolation...
	terre:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root 4006060941 Nov 12 15:34 full.1.dar
	-rw-r--r-- 1 root root    6662595 Nov 12 15:34 <e class=blue>snapshot.1.dar</e>
	terre:/mnt/memdisk# dar <e>-C recreated_snapshot</e> -A full -z6 -q
	terre:/mnt/memdisk# ls -al *.dar
	-rw-r--r-- 1 root root 4006060941 Nov 12 15:34 full.1.dar
	-rw-r--r-- 1 root root    7907094 Nov 12 16:33 <e class=blue>recreated_snapshot.1.dar</e>
	-rw-r--r-- 1 root root    6662595 Nov 12 15:34 snapshot.1.dar
	terre:/mnt/memdisk# dar -c diff -A snapshot -R /usr -z


	--------------------------------------------
	23 inode(s) saved
	including 23 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	<e>267222 inode(s) not saved (no inode/file change)</e>
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 267245
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# ls -lh *.dar
	-rw-r--r-- 1 root root  25M Nov 12 16:37 diff.1.dar
	-rw-r--r-- 1 root root 3.8G Nov 12 15:34 full.1.dar
	-rw-r--r-- 1 root root 7.6M Nov 12 16:33 recreated_snapshot.1.dar
	-rw-r--r-- 1 root root 6.4M Nov 12 15:34 snapshot.1.dar
	terre:/mnt/memdisk# dar -c diff2 -A recreated_snapshot -R /usr -z


	--------------------------------------------
	23 inode(s) saved
	including 23 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	<e>267222 inode(s) not saved (no inode/file change)</e>
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 267245
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# dar -c snapshot_alone <e>-A +</e> -R /usr -z


	--------------------------------------------
	23 inode(s) saved
	including 23 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	267222 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 267245
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# <e>touch /usr/local/src</e>
	terre:/mnt/memdisk# dar -c faked_diff -A snapshot -R /usr <e class=blue>--dry-run</e> -q -vt
	<e>Adding folder to archive: /usr/local/src</e>
	Saving Filesystem Specific Attributes for /usr/local/src
	terre:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root   25537139 Nov 12 16:37 diff.1.dar
	-rw-r--r-- 1 root root   25537139 Nov 12 16:39 diff2.1.dar
	-rw-r--r-- 1 root root 4006060941 Nov 12 15:34 full.1.dar
	-rw-r--r-- 1 root root    7907094 Nov 12 16:33 recreated_snapshot.1.dar
	-rw-r--r-- 1 root root    6662595 Nov 12 15:34 snapshot.1.dar
	-rw-r--r-- 1 root root   25537142 Nov 12 16:44 <e class=blue>snapshot_alone.1.dar</e>
	terre:/mnt/memdisk#
    </code></div>

    <p>As seen above,a snapshot can be created:
      <ul>
	<li>as part of a backup process (full, differential, incremental or even decremental backup) (<code>--on-fly-isolate</code>)</li>
	<li>from a existing backup(<code>-C</code>)</li>
	<li>alone by a dedicated operation (<code>-A +</code>)</li>
      </ul>
    </p>

    <div class=code><code>
	root@terre:/mnt/memdisk# ls -l full.1.dar
	-rw-r--r-- 1 root root <e>3895581703</e> Nov 29 21:53 full.1.dar
	root@terre:/mnt/memdisk# dar -l full -q
	FATAL error, aborting operation: Cannot open catalogue: unknown compression
	root@terre:/mnt/memdisk# !bitflip
	bitflip 31124653000 full.1.dar
	root@terre:/mnt/memdisk# dar -l full -q
	Archive version format               : 11
	Compression algorithm used           : gzip
	Compression block size used          : 0
	Symmetric key encryption used        : none
	Asymmetric key encryption used       : none
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : N/A
	<e>Catalogue size in archive            : 7799028 bytes</e>

	Archive is composed of 1 file(s)
	File size: 3895581703 bytes
	The global data compression ratio is:   51%

	CATALOGUE CONTENTS :

	total number of inode : 263480
	fully saved           : 263480
	binay delta patch     : 0
	inode metadata only   : 0
	distribution of inode(s)
	- directories        : 18080
	- plain files        : 216142
	- symbolic links     : 29258
	- named pipes        : 0
	- unix sockets       : 0
	- character devices  : 0
	- block devices      : 0
	- Door entries       : 0
	hard links information
	- number of inode with hard link           : 11
	- number of reference to hard linked inodes: 34
	destroyed entries information
	0 file(s) have been record as destroyed since backup of reference

	root@terre:/mnt/memdisk# <e>bitflip 31124653000 full.1.dar</e>
	root@terre:/mnt/memdisk# dar -t full
	Final memory cleanup...
	<e class=red>FATAL error, aborting operation: Cannot open catalogue: unknown compression</e>
	root@terre:/mnt/memdisk# dar -t full <e>-A snapshot</e>


	--------------------------------------------
	263503 item(s) treated
	0 item(s) with error
	0 item(s) ignored (excluded by filters)
	--------------------------------------------
	Total number of items considered: 263503
	--------------------------------------------
	root@terre:/mnt/memdisk#
	root@terre:/mnt/memdisk# dar -t full <e>--sequential-read</e>
	A problem occurred while reading this archive contents: <e>Cannot open catalogue: unknown compression</e>


	--------------------------------------------
	263503 item(s) treated
	0 item(s) with error
	0 item(s) ignored (excluded by filters)
	--------------------------------------------
	Total number of items considered: 263503
	--------------------------------------------
	root@terre:/mnt/memdisk#

    </code></div>

    <p>
      Once created a snapshot can be used:
      <ul>
	<li>to create a differential or incremental backup</li>
	<li>to list the files that would be saved (thus which have changed,
	  were added or have been removed) thus all changes since the time the snapshot was made (using the <code>--dry-run</code> option)</li>
	<li>
	  rescue a corrupted backup when the corruption falled into the
	  backup table of content located at the end of the <i>dar</i>
	  backup (only if it has been created based on the backup to rescue
	  either using <code>-C option</code> maybe long after the backup was made
	  or using <code>--on-fly-isolate</code> at the same time the backup was created.
	</li>
      </ul>
      Note, as shown above, a table of content (aka "catalogue") corruption, can also partially be recovered
      using the <code>--sequential-read</code> mode, it will just not let <i>dar</i> remove files that
      were removed since the reference backup was made (this does thus not concern full backups, as here).
    </p>

    <h5>Rsync</h5>
    <p>
      This feature is not supported by <i>rsync</i>.
    </p>

    <h5>Tar</h5>
    <p>
      <i>tar</i> can generate snapshot:
      <ul>
	<li>alone redirecting the backup output to /dev/null</li>
	<li>as part of a backup process (in fact <i>tar</i> cannot do else)</li>
      </ul>
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# tar --listed-incremental=snapshot.file -czf full.tar.gz /usr
	tar: Removing leading `/' from member names
	tar: Removing leading `/' from hard link targets
	terre:/mnt/memdisk# ls -l snapshot.file
	-rw-r--r-- 1 root root 6288644 Nov 12 15:12 snapshot.file
	terre:/mnt/memdisk# cp snapshot.file snapshot.file.ref
	tar --listed-incremental=snapshot.file -cvf /dev/null /usr
	/usr/
	/usr/bin/
	/usr/games/
	/usr/include/
	/usr/include/X11/
	/usr/include/X11/bitmaps/
	/usr/include/arpa/
	/usr/include/asm-generic/
	/usr/include/attr/
	/usr/include/c++/
	/usr/include/c++/
	<e>[...]</e>
	/usr/share/zoneinfo/right/Canada/
	/usr/share/zoneinfo/right/Chile/
	/usr/share/zoneinfo/right/Etc/
	/usr/share/zoneinfo/right/Europe/
	/usr/share/zoneinfo/right/Indian/
	/usr/share/zoneinfo/right/Mexico/
	/usr/share/zoneinfo/right/Pacific/
	/usr/share/zoneinfo/right/SystemV/
	/usr/share/zoneinfo/right/US/
	/usr/share/zsh/
	/usr/share/zsh/site-functions/
	/usr/share/zsh/vendor-completions/
	/usr/src/
	terre:/mnt/memdisk# ls -l sna
	snapshot.file      snapshot.file.ref
	terre:/mnt/memdisk# ls -l snapshot.file*
	-rw-r--r-- 1 root root 6288644 Nov 12 15:20 snapshot.file
	-rw-r--r-- 1 root root 6288644 Nov 12 15:18 snapshot.file.ref
	terre:/mnt/memdisk#
    </code></div>
    <p>
      If a snapshot can be used (and is in fact required) to make a differential backup, it
      cannot really be used to see the difference a current living filesystem has with a given
      snapshot. Worse, doing so modifies the snapshot, so you have first to make a copy
      to not screw up your backup process. Worse, if incremental backup fails and you have
      not created a copy of the backup, your snapshot being modified you will mostly have to
      remake the whole backup process from the full backup to be sure to not miss backing up
      some modified files. Same thing if you lose by mistake the snapshot file.
    </p>


    <h4>On-fly hashing</h4>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R /usr -g usr/bin -z6 <e>--hash sha1</e>


	--------------------------------------------
	0 inode(s) saved
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	8 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 8
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# ls -l *.dar*
	-rw-r--r-- 1 root root 171 Nov 12 17:22 backup.1.dar
	-rw-r--r-- 1 root root  55 Nov 12 17:22 <e>backup.1.dar.sha1</e>
	terre:/mnt/memdisk# sha1sum -c backup.1.dar.sha1
	<e>backup.1.dar: OK</e>
	terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <p>
      not supported by <i>rsync</i>
    </p>

    <h5>Tar</h5>

    <p>
      not supported by <i>tar</i>
    </p>


    <h4>Custom command during operation</h4>

    <p>
      As an example (but there is much more thing that can be done), we take the case
      of a automounted directory. Such type of volume is mounted only when used, if not
      used no mount point directory shows and unless you know it exists, no backup of
      its content is performed. The idea, is when entering the parent directory at backup
      process to trigger the mount point for the backup to include them.
    <p>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# cat /etc/auto.mnt
	Espace  -defaults,relatime,acl,bg,rsize=8192,wsize=8192       nfs.systeme-solaire.espace:/mnt/Externe/Espace
	Commun  -defaults,relatime,acl,bg,rsize=8192,wsize=8192,ro    nfs.systeme-solaire.espace:/mnt/Externe/Commun
	Backup  -defaults,relatime,acl,bg,rsize=8192,wsize=8192,ro    nfs.systeme-solaire.espace:/mnt/Backup
	terre:/mnt/memdisk# ls -l /mnt/Externe/
	total 4
	drwxr-xr-x 7 root root 4096 Jul 14 17:58 Espace
	terre:/mnt/memdisk# dar -c backup -R / -g /mnt -q
	terre:/mnt/memdisk# dar -l backup
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[Saved][-]       [-L-][     ][ ]  drwxr-xr-x   0        0       0       Wed Oct 21 18:17:07 2020        mnt
	[Saved][-]       [-L-][     ][ ]  drwxr-xr-x   1000     1002    0       Mon Nov  9 11:56:54 2020        mnt/localdisk
	[Saved][-]       [---][-----][ ]  lrwxrwxrwx   0        0       0       Thu Aug 15 23:29:46 2019        mnt/Backup
	[Saved][-]       [---][     ][ ]  drwxr-xr-x   0        0       0       Thu Nov 12 17:42:11 2020        mnt/Externe
	[Saved][-][Saved][---][     ][ ]  drwxr-xr-x   0        0       0       Tue Jul 14 17:58:57 2020        <e class=blue>mnt/Externe/Espace</e>
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# rm backup.1.dar
	terre:/mnt/memdisk# dar -c backup -R / -g mnt -q '-&lt;' mnt '-=' 'file %p/Externe/Backup %p/Externe/Commun'
	/mnt/Externe/Backup: directory
	/mnt/Externe/Commun: directory
	terre:/mnt/memdisk# dar -l backup
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[Saved][-]       [-L-][     ][ ]  drwxr-xr-x   0        0       0       Wed Oct 21 18:17:07 2020        mnt
	[Saved][-]       [-L-][     ][ ]  drwxr-xr-x   1000     1002    0       Mon Nov  9 11:56:54 2020        mnt/localdisk
	[Saved][-]       [---][-----][ ]  lrwxrwxrwx   0        0       0       Thu Aug 15 23:29:46 2019        mnt/Backup
	[Saved][-]       [---][     ][ ]  drwxr-xr-x   0        0       0       Thu Nov 12 18:01:41 2020        mnt/Externe
	[Saved][-][Saved][---][     ][ ]  drwxr-x---   993      1002    0       Wed Nov 11 10:21:55 2015        <e>mnt/Externe/Commun</e>
	[Saved][-][Saved][---][     ][ ]  drwxr-xr-x   0        0       0       Sun Sep 13 12:22:24 2020        <e>mnt/Externe/Backup</e>
	[Saved][-][Saved][---][     ][ ]  drwxr-xr-x   0        0       0       Tue Jul 14 17:58:57 2020        <e class=blue>mnt/Externe/Espace</e>
	terre:/mnt/memdisk# ls -l /mnt/Externe/
	total 12
	drwxr-xr-x 9 root   root   4096 Sep 13 12:22 Backup
	drwxr-x--- 4 commun maison 4096 Nov 11  2015 Commun
	drwxr-xr-x 7 root   root   4096 Jul 14 17:58 Espace
	terre:/mnt/memdisk#
    </code></div>

    <p>
      In the previous example we see that the /mnt/Externe directory is a mount point containing three auto-mounted
      volumes: <code>Espace</code>, <code>Commun</code> and <code>Backup</code>. At first only <code>Espace</code>
      was mounted. Performing a backup without care will skip the two other directories.
    </p>
    <p>
      In a second time, thanks to the <code>-&lt;</code> and <code>-=</code> options, we instructed <i>dar</i> to
      run the <code>file</code> command on the two missing directories when entering <code>/mnt</code>.
      As a result, we now see both of them in the backup. We could do that before executing the backup, but as
      the backup may include many other
      directories the time between such operation done before starting the backup and the time the backup finally
      saves the automount point at <code>/mnt/Externe</code> may exceed the automount timeout leading them to be
      unmounted and disappear before the backup process reaches them.
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin --hash sha512 -s 100M -q
	terre:/mnt/memdisk# ls -l backup.*
	-rw-r--r-- 1 root root 104857600 Nov 12 18:30 backup.1.dar
	-rw-r--r-- 1 root root       143 Nov 12 18:30 backup.1.dar.sha512
	-rw-r--r-- 1 root root 104857600 Nov 12 18:30 backup.2.dar
	-rw-r--r-- 1 root root       143 Nov 12 18:30 backup.2.dar.sha512
	-rw-r--r-- 1 root root 104857600 Nov 12 18:30 backup.3.dar
	-rw-r--r-- 1 root root       143 Nov 12 18:30 backup.3.dar.sha512
	-rw-r--r-- 1 root root  63577207 Nov 12 18:30 backup.4.dar
	-rw-r--r-- 1 root root       143 Nov 12 18:30 backup.4.dar.sha512
	terre:/mnt/memdisk# dar -t backup <e>-E 'sha512sum -c %p/%b.%N.%e.sha512'</e>
	backup.4.dar: OK
	backup.1.dar: OK
	backup.2.dar: OK
	backup.3.dar: OK
	backup.4.dar: OK


	--------------------------------------------
	2594 item(s) treated
	0 item(s) with error
	0 item(s) ignored (excluded by filters)
	--------------------------------------------
	Total number of items considered: 2594
	--------------------------------------------
	terre:/mnt/memdisk#
    </code></div>
    <p>
      In this example, this we used slicing with on-fly hashing which generated for each slice
      the corresponding sha512 hash file. Then we tested the archive content and at the same time the hash
      files thanks to the <code>-E</code> option. Of course any user command or shell or python script,
      can be used instead, and for backup, restoration, testing, snashotting,...
    </p>

    <h5>Rsync</h5>
    <p>
      not supported by <i>rsync</i>
    </p>

    <h5>Tar</h5>
    <p>
      <i>tar</i> has the <code>-F option</code> to launch a command after each tape,
      but it is only available with multi-volume tar archive, which in turn
      cannot be used with compression. Thus we won't test it quite restrictive and
      does not march very common use cases.
    </p>

    <h4>Dry-run execution</h4>
    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk/A# ls -l
	<e>total 0</e>
	terre:/mnt/memdisk/A# dar -c backup -R / -g usr/bin --dry-run


	--------------------------------------------
	2594 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	34 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2628
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2154 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk/A# ls -l
	<e>total 0</e>
	terre:/mnt/memdisk/A#
    </code></div>

    <h5>Rsync</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rsync -arHAX --dry-run /usr/bin DST
	terre:/mnt/memdisk# ls -l DST
	<e>ls: cannot access 'DST': No such file or directory</e>
	terre:/mnt/memdisk#
    </code></div>

    <h5>Tar</h5>
    <p>
      does not seem supported by <i>tar</i>
    </p>


    <h4>User message within backup</h4>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup <e>--user-comment "passphrase is the usual one. Archive was made on %d on host %h"</e> -R / -g usr/bin -K camellia: -zxz -s 100M
	Archive backup requires a password:
	Please confirm your password:


	--------------------------------------------
	2594 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	34 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2628
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2154 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# dar -l backup <e>-aheader</e>
	Archive version format               : 11
	Compression algorithm used           : xz
	Compression block size used          : 0
	Symmetric key encryption used        : camellia 256
	Asymmetric key encryption used       : none
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : <e>passphrase is the usual one. Archive was made on Thu Nov 12 18:57:35 2020 on host terre</e>
	KDF iteration count                  : 10000
	KDF hash algorithm                   : argon2
	Salt size                            : 32 bytes
	Final memory cleanup...
	FATAL error, aborting operation: header only mode asked
	terre:/mnt/memdisk#
    </code></div>

    <p>
      The use of the <code>-aheader</code> let one see the archive header that is always in clear-text. The usual listing
      operation provides some additional informations from the ciphered table of content and thus in that context requires the passphrase:
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# dar <e>-l</e> backup <e>-q</e>
	<e>Archive backup requires a password:</e>
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	Archive version format               : 11
	Compression algorithm used           : xz
	Compression block size used          : 0
	Symmetric key encryption used        : camellia 256
	Asymmetric key encryption used       : none
	Archive is signed                    : no
	Sequential reading marks             : present
	User comment                         : <e>passphrase is the usual one. Archive was made on Thu Nov 12 18:57:35 2020 on host terre</e>
	KDF iteration count                  : 10000
	KDF hash algorithm                   : argon2
	Salt size                            : 32 bytes
	Catalogue size in archive            : 78268 bytes

	Archive is composed of 2 file(s)
	File size             : 104857600 bytes
	Last file size        : 17168696 bytes
	Archive total size is : 122026296 bytes
	<e>The global data compression ratio is:   72%</e>

	<e>CATALOGUE CONTENTS :</e>

	total number of inode : 2589
	fully saved           : 2589
	binay delta patch     : 0
	inode metadata only   : 0
	distribution of inode(s)
	- directories        : 2
	- plain files        : 2152
	- symbolic links     : 435
	- named pipes        : 0
	- unix sockets       : 0
	- character devices  : 0
	- block devices      : 0
	- Door entries       : 0
	hard links information
	- number of inode with hard link           : 5
	- number of reference to hard linked inodes: 10
	destroyed entries information
	0 file(s) have been record as destroyed since backup of reference

	terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <p>
      not supported by <i>rsync</i>
    </p>

    <h5>Tar</h5>
    <p>
      not supported by <i>tar</i>
    </p>

    <h4>backup sanity test</h4>


    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin -zlz4


	--------------------------------------------
	2594 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	34 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2628
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2154 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# dar -t backup


	--------------------------------------------
	2594 item(s) treated
	0 item(s) with error
	0 item(s) ignored (excluded by filters)
	--------------------------------------------
	Total number of items considered: 2594
	--------------------------------------------
	terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <p>
      It does not seems possible to let <i>rsync</i> check that the target or destination
      directory is sane and usuable. All operation modify the destination file or save
      modified files in either the destination directory (the backup) or an alternate directory
      (<code>--compare-dest</code> option).
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rm -rf backup.tar.gz
	terre:/mnt/memdisk# tar -czf backup.tar.gz /usr/bin
	tar: Removing leading `/' from member names
	tar: Removing leading `/' from hard link targets
	terre:/mnt/memdisk# tar -tzf backup.tar.gz
	usr/bin/
	usr/bin/bitmap
	usr/bin/dot
	usr/bin/indi_usbdewpoint
	usr/bin/ruby2.5
	usr/bin/pod2man
	usr/bin/iptables-xml
	usr/bin/knotify4
	usr/bin/fakeroot
	usr/bin/xclock
	<e>[...]</e>
	/bin/traceproto
	usr/bin/ofm2opl
	usr/bin/akonadi_archivemail_agent
	usr/bin/resizecons
	usr/bin/rletopnm
	usr/bin/dh_install
	usr/bin/updvitomp
	usr/bin/h2xs
	usr/bin/xmessage
	terre:/mnt/memdisk# echo $?
	0
	terre:/mnt/memdisk#
    </code></div>


    <h4>Comparing with original data</h4>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R SRC -q
	terre:/mnt/memdisk# dar -d backup -R SRC


	--------------------------------------------
	2594 item(s) treated
	0 item(s) do not match those on filesystem
	0 item(s) ignored (excluded by filters)
	--------------------------------------------
	Total number of items considered: 2594
	--------------------------------------------
	terre:/mnt/memdisk# echo $?
	0
	terre:/mnt/memdisk#
    </code></div>

    <h5>Rsync</h5>
    <p>
      Does not seems supported by <i>rsync</i>
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk/SRC# tar -czf ../backup.tar.gz .
	terre:/mnt/memdisk/SRC# tar -dzf ../backup.tar.gz
	terre:/mnt/memdisk/SRC# echo $?
	0
	terre:/mnt/memdisk/SRC#
    </code></div>

    <h4>Tunable verbosity</h4>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin <e>-q</e>
	terre:/mnt/memdisk# rm backup.1.dar
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin


	--------------------------------------------
	2594 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	34 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2628
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2154 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin <e>-vm</e>
	Arguments read from /usr/local/etc/darrc :

	Creating low layer: Writing archive into a plain file object...
	Adding a new layer on top: Caching layer for better performances...
	Writing down the archive header...
	Adding a new layer on top: Escape layer to allow sequential reading...
	All layers have been created successfully
	Building the catalog object...
	Processing files for backup...
	Writing down archive contents...
	Closing the escape layer...
	Writing down the first archive terminator...
	Writing down archive trailer...
	Writing down the second archive terminator...
	Closing archive low layer...
	Archive is closed.


	--------------------------------------------
	2594 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	34 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2628
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2154 inode(s)
	--------------------------------------------
	Making room in memory (releasing memory used by archive of reference)...
	Final memory cleanup...
	terre:/mnt/memdisk# rm -f backup*
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin <e>-vt</e> -q
	Adding folder to archive: /usr
	Saving Filesystem Specific Attributes for /usr
	Adding folder to archive: /usr/bin
	Saving Filesystem Specific Attributes for /usr/bin
	Adding file to archive: /usr/bin/bitmap
	Saving Filesystem Specific Attributes for /usr/bin/bitmap
	<e>[...]</e>
	Saving Filesystem Specific Attributes for /usr/bin/dh_install
	Adding symlink to archive: /usr/bin/updvitomp
	Adding file to archive: /usr/bin/h2xs
	Saving Filesystem Specific Attributes for /usr/bin/h2xs
	Adding file to archive: /usr/bin/xmessage
	Saving Filesystem Specific Attributes for /usr/bin/xmessage
	terre:/mnt/memdisk# rm -f backup*
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin -vd
	Inspecting directory /root
	Inspecting directory /bin
	Inspecting directory /sbin
	Inspecting directory /tmp
	Inspecting directory /sys
	Inspecting directory /lib
	<e>[...]</e>
	Inspecting directory /var
	Inspecting directory /proc
	Inspecting directory /dev
	Inspecting directory /etc
	Inspecting directory /media
	Inspecting directory /run
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# rm -f backup.*
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin <e>-vf</e> -q
	Finished Inspecting directory /usr/bin , saved 408 Mio, compression ratio   13%
	Finished Inspecting directory /usr , saved 408 Mio, compression ratio   13%
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin <e>-vmasks</e> -q
	directory tree filter:
	AND
	| OR
	|   | Is subdir of: /usr/bin [case sensitive]
	|   +--
	+--

	filename filter:
	AND
	| TRUE
	+--

	EA filter:
	AND
	| TRUE
	+--

	Compression filter:
	TRUE

	terre:/mnt/memdisk#
    </code></div>

    <p>
      <i>dar</i> has several options to define which type of message to show or not to show:
      <code> -v, -vs, -vt, -vd, -vf, -vm, -vmasks, -q</code>. They can be combined.
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rsync -arHAX /usr/bin DST
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# rsync -arHAX <e>-v</e> /usr/bin DST
	sending incremental file list
	created directory DST
	bin/
	bin/2to3-2.7
	bin/411toppm
	bin/7z
	bin/7za
	bin/7zr
	bin/FvwmCommand
	<e>[...]</e>
	bin/zstdmt -> zstd
	bin/perl => bin/perl5.28.1
	bin/perlbug => bin/perlthanks
	bin/python3.7 => bin/python3.7m
	bin/pkg-config => bin/x86_64-pc-linux-gnu-pkg-config
	bin/unzip => bin/zipinfo

	sent 437,298,617 bytes  received 42,381 bytes  174,936,399.20 bytes/sec
	total size is 445,394,557  speedup is 1.02
	root@terre:/mnt/memdisk# rsync -arHAX <e>--info=progress2</e> /usr/bin DST
	437,083,500  98%  128.42MB/s    0:00:03 (xfr#2152, to-chk=0/2593)
	root@terre:/mnt/memdisk#

    </code></div>
    <p>
      <code>-v option</code> leads to a more verbose output, while <code>-q</code>
      remove the non error messages. Using both at the same time seems not to
      be different than using <code>-q</code> alone. <i>rsync</i> has a very rich
      set of additional options like <code>--info</code>, <code>--debug</code>
      that can be added on top.
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# tar -czf backup.tar.gz /usr/bin
	tar: Removing leading `/' from member names
	tar: Removing leading `/' from hard link targets
	terre:/mnt/memdisk# rm backup.tar.gz
	terre:/mnt/memdisk# tar <e>-v</e> -czf backup.tar.gz /usr/bin
	tar: Removing leading `/' from member names
	/usr/bin/
	/usr/bin/bitmap
	/usr/bin/dot
	/usr/bin/indi_usbdewpoint
	/usr/bin/ruby2.5
	/usr/bin/pod2man
	/usr/bin/iptables-xml
	/usr/bin/knotify4
	<e>[...]</e>
	/usr/bin/traceproto
	/usr/bin/ofm2opl
	/usr/bin/akonadi_archivemail_agent
	/usr/bin/resizecons
	/usr/bin/rletopnm
	/usr/bin/dh_install
	/usr/bin/updvitomp
	/usr/bin/h2xs
	/usr/bin/xmessage
	terre:/mnt/memdisk#
    </code></div>

    <p>
      <i>tar</i> provides the <code>-v</code> option to increase
      verbosity.
    </p>


    <h4>Modify Backup content</h4>
    <p>
      We will perform two types of tests:
      <ul>
	<li>remove one or several files from an existing backup without having to make a new backup process</li>
	<li>add some forgotten files to an existing backup without performing a new full backup process</li>
      </ul>
    </p>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R / -g usr/bin -z6 -q
	terre:/mnt/memdisk# dar -l backup -g usr/bin/emacs-gtk
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[Saved][-]       [-L-][  64%][ ]  drwxr-xr-x   root     root    408 Mio Sun Jun  2 23:25:09 2019        usr
	[Saved][-]       [-L-][  64%][ ]  drwxr-xr-x   root     root    408 Mio Sun Nov  8 13:43:58 2020        usr/bin
	[Saved][ ]       [-L-][  90%][X]  -rwxr-xr-x   root     root    38 Mio  Thu Sep  5 04:35:24 2019        <e>usr/bin/emacs-gtk</e>
	terre:/mnt/memdisk# dar -A backup <e>-+ without-emacs</e> <e class=blue>-ak</e> <e>-P usr/bin/emacs-gtk</e> -vs -q
	Skipping file: &lt;ROOT&gt;/usr/bin/emacs-gtk
	terre:/mnt/memdisk# dar -l without-emacs -g usr/bin/emacs-gtk
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[Saved][-]       [-L-][  62%][ ]  drwxr-xr-x   root     root    370 Mio Sun Jun  2 23:25:09 2019        usr
	[Saved][-]       [-L-][  62%][ ]  drwxr-xr-x   root     root    370 Mio Sun Nov  8 13:43:58 2020        usr/bin
	terre:/mnt/memdisk#rm backup.*
	terre:/mnt/memdisk#mv without-emacs.1.dar backup.1.dar
	terre:/mnt/memdisk#
    </code></div>
    <p>
      <i>dar</i> does not modify a existing backup but creates a copy of it with the requested files or
      directory removed. The process can be quick even with compression thanks to the <code>-ak</code>
      option that avoid uncompressing and recompressing
      file that are kept. Before removing the old backup you can test the sanity of the new generated one.
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c emacs -R / -g usr/bin/emacs-gtk -z6 -q
	terre:/mnt/memdisk# dar -l emacs
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[Saved][-]       [-L-][  90%][ ]  drwxr-xr-x   root     root    38 Mio  Sun Jun  2 23:25:09 2019        usr
	[Saved][-]       [-L-][  90%][ ]  drwxr-xr-x   root     root    38 Mio  Sun Nov  8 13:43:58 2020        usr/bin
	[Saved][ ]       [-L-][  90%][X]  -rwxr-xr-x   root     root    38 Mio  Thu Sep  5 04:35:24 2019        usr/bin/emacs-gtk
	terre:/mnt/memdisk# <e>dar -A backup -@ emacs -+ with-emacs</e> <e class=blue>-ak</e>


	--------------------------------------------
	2594 inode(s) added to archive
	with 10 hard link(s) recorded
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 2159 inode(s)
	--------------------------------------------
	Total number of inode(s) considered: 2594
	--------------------------------------------
	terre:/mnt/memdisk# dar -l with-emacs -g usr/bin/emacs-gtk
	[Data ][D][ EA  ][FSA][Compr][S]| Permission | User  | Group | Size    |          Date                 |    filename
	--------------------------------+------------+-------+-------+---------+-------------------------------+------------
	[Saved][-]       [-L-][  64%][ ]  drwxr-xr-x   root     root    408 Mio Sun Jun  2 23:25:09 2019        usr
	[Saved][-]       [-L-][  64%][ ]  drwxr-xr-x   root     root    408 Mio Sun Nov  8 13:43:58 2020        usr/bin
	[Saved][ ]       [-L-][  90%][X]  -rwxr-xr-x   root     root    38 Mio  Thu Sep  5 04:35:24 2019        usr/bin/emacs-gtk
	terre:/mnt/memdisk# rm emacs.* backup.*
	terre:/mnt/memdisk# mv with-emacs.1.dar backup.1.dar
	terre:/mnt/memdisk#
    </code></div>

    <p>
      Here to add files to a existing backup we must make a small backup of these files only, then merge
      this backup with the backup we want to modify. Nothing of the source data is touched in this operation,
      is something goes wrong or if you made an error, you can fix and restart without taking the risk
      to lose data.
    </p>

    <h5>Rsync</h5>
    <p>
      The backup made by <i>rsync</i> is just a copy of the save files, removing a file from the backup
      is as simple as calling <code>rm</code> on that file in the repository that is considered the backup.
    </p>
    <p>
      While adding a new file in the backup can be done by using <i>rsync</i> as usual including the directory
      tree where this file resides.
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# tar -czf backup.tar.gz /usr/bin
	tar: Removing leading `/' from member names
	tar: Removing leading `/' from hard link targets
	terre:/mnt/memdisk# tar -tvf backup.tar.gz | grep emacs-gtk
	-rwxr-xr-x root/root    39926024 2019-09-05 04:35 usr/bin/emacs-gtk
	terre:/mnt/memdisk# tar -tvf backup.tar.gz | grep emacs-gtk
	-rwxr-xr-x root/root    39926024 2019-09-05 04:35 usr/bin/emacs-gtk
	terre:/mnt/memdisk# tar --delete usr/bin/emacs-gtk -f backup.tar.gz
	<e>tar: Cannot update compressed archives</e>
	tar: Error is not recoverable: exiting now
	terre:/mnt/memdisk#
    </code></div>
    <p>
      Well, <i>tar</i> cannot manipulate compressed archives. What the point then to remove a
      file from a backup if storage space is not an issue, else, would compression be used?
    </p>

    <h4>stdin/stdout backup read/write</h4>

    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c - -z6 -R SRC &gt; backup.file


	--------------------------------------------
	2594 inode(s) saved
	including 5 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2594
	--------------------------------------------
	EA saved for 3 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# dar -x - --sequential-read -R DST &lt; backup.file


	--------------------------------------------
	2594 inode(s) restored
	including 5 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 2594
	--------------------------------------------
	EA restored for 3 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk#
    </code></div>
    <p>
      <i>dar</i> can read a backup from stdin and write a backup to stdout.
    </p>

    <h5>Rsync</h5>
    <p>
      Using stdin/stdout to send to or read from backed up data does not seems possible with <i>rsync</i>
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# tar -czf - SRC &gt; backup.file
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xzf - &lt; ../backup.file
	terre:/mnt/memdisk/DST#
    </code></div>

    <p>
      <i>tar</i> can read a backup from stdin and write a backup to stdout.
    </p>

    <h4>Remote network storage</h4>

    <p>
      For Remote Network storage, if you use a personal NAS you may avoid generating
      ciphered backup, though you still should transfer
      it using a secured protocol if the underlaying network is not your own from end to end
      (for example a part of the path goes over Internet without IPSec or equivalent).
    </p>
    <p>
      Why ciphering backup if using secure transfer protocol?
      <ul>
	<li>
	  Secure transfer avoids one to
	  read your data in transit in particular your credentials to the remote site, but at the
	  end the transferred data is stored in clear at the other end.
	</li>
	<li>
	  ciphered data avoids the owner of the remote storage to access to your data
	  without your consent, though it does not protect one to intercept your transfer and
	  read the credentials you used to connected to the remote storage. This one could
	  then connect later and delete all your backup... which is surely not what you want.
	</li>
      </ul>
    </p>
    <p>
      In the following we will use both: <b>secure protocol</b> and <b>ciphered backup</b>, without using
      local storage. We will also need <b>compression</b> to save precious space (usually you pay for the
      cloud storage you use) and <b>maybe slicing</b> depending on the constraints
      imposed by the remote storage (some provider ask you to pay an extra amount to store larger files,
      having slicing avoids you having to pay for the size of files in addition to the total
      amount of disk space you use.
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# sftp denis@dar
	The authenticity of host 'dar (192.168.6.32)' can't be established.
	RSA key fingerprint is SHA256:KN3o/psWC512grcZ5/J5dTSg9PzIXbZAHiig/hqfkc8.
	Are you sure you want to continue connecting (yes/no)? yes
	Warning: Permanently added 'dar,192.168.6.32' (RSA) to the list of known hosts.
	denis@dar's password:
	Connected to denis@dar.
	sftp> bye
	terre:/mnt/memdisk#
    </code></div>

    <h5>Dar</h5>

    <div class=code><code>
	terre:/mnt/memdisk# dar -c sftp://denis@dar/home/denis/backup -R / -g etc -K aes: -zlz4 -s 1M
	<e class=blue>Please provide the password for login denis at host dar:</e>
	<e>Archive backup requires a password:</e>
	<e>Please confirm your password:</e>


	--------------------------------------------
	2360 inode(s) saved
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	27 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 2387
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 1523 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# sftp denis@dar
	denis@dar's password:
	Connected to denis@dar.
	sftp> ls -l
	-rw-r--r--    1 denis    denis     1048576 Nov 26 17:15 backup.1.dar
	-rw-r--r--    1 denis    denis     1048576 Nov 26 17:15 backup.2.dar
	-rw-r--r--    1 denis    denis     1048576 Nov 26 17:15 backup.3.dar
	-rw-r--r--    1 denis    denis      474982 Nov 26 17:15 backup.4.dar
	sftp> bye
	terre:/mnt/memdisk#
    </code></div>
    <p>
      The backup results in four ciphered slices located on the remote sftp server. Let's add
      a <code>-E option</code> to see which slice are being read while testing the archive.
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# dar -t sftp://denis@dar/home/denis/backup <e class=blue>-E "echo 'openning slice %p/%b.%N.%e'"</e>
	<e class=blue>Please provide the password for login denis at host dar:</e>
	openning slice /home/denis/backup.4.dar
	<e>Archive backup requires a password:</e>
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	openning slice /home/denis/backup.1.dar
	openning slice /home/denis/backup.2.dar
	openning slice /home/denis/backup.3.dar
	openning slice /home/denis/backup.4.dar


	--------------------------------------------
	2360 item(s) treated
	0 item(s) with error
	0 item(s) ignored (excluded by filters)
	--------------------------------------------
	Total number of items considered: 2360
	--------------------------------------------
	terre:/mnt/memdisk#
    </code></div>

    <p>
      We see that all slices have been read as expected, now let's restore /etc/fstab in the current directory
      and compare the restored files with the real /etc/fstab
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# dar -x sftp://denis@dar/home/denis/backup -E "echo 'openning slice %p/%b.%N.%e'" -g etc/fstab --flat
	Please provide the password for login denis at host dar:
	<e>openning slice /home/denis/backup.4.dar</e>
	Archive backup requires a password:
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	<e>1 inode(s) restored</e>
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	269 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 270
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# <e>diff fstab /etc/fstab</e>
	terre:/mnt/memdisk# echo $?
	<e>0</e>
	terre:/mnt/memdisk#
    </code></div>
    <p>
      As seen above only the slice 4 has been necessary to restore /etc/fstab. But let's save two files,
      a huge one and a small one into a single sliced backup and measure the transfer time of backup
      and restoration of this ciphered an compressed backup through sftp. We have added public key authentification
      for precise time measurement:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# sftp denis@dar
	Connected to denis@dar.
	sftp> bye
	terre:/mnt/memdisk# ls -l SRC
	total 315396
	-rw------- 1 root root 322961408 Nov 26 17:28 devuan_beowulf_3.0.0_amd64-netinstall.iso
	-rw-r--r-- 1 root root       994 Nov 26 17:29 fstab
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# time dar -c sftp://denis@dar/home/denis/backup -R SRC -z6 -K aes:hello -afile-auth -q
	20.769u 2.445s <e>0:22.77</e> 101.8%   0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# time dar -x sftp://denis@dar/home/denis/backup -R DST -K hello -afile-auth -q
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	11.826u 4.211s <e>0:15.88</e> 100.9%   0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk# diff -rs SRC DST
	<e>Files SRC/devuan_beowulf_3.0.0_amd64-netinstall.iso and DST/devuan_beowulf_3.0.0_amd64-netinstall.iso are identical</e>
	<e>Files SRC/fstab and DST/fstab are identical</e>
	terre:/mnt/memdisk# <e class=blue>rm DST/fstab</e>
	terre:/mnt/memdisk# time dar -x sftp://denis@dar/home/denis/backup -R DST -K hello -afile-auth -q -g fstab
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	0.680u 0.012s <e>0:00.87</e> 79.3%     0+0k 0+0io 0pf+0w
	terre:/mnt/memdisk#
    </code></div>

    <p>
      While restoring the whole backup needs 15 seconds of transfer time, restoring <code>fstab</code> alone requires only 0.87 second,
      as there is only one slice, this shows that <i>dar</i> is reading only the necessary part of the archive even within a slice to
      perform the operation.
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rsync -arHAXSzq /etc denis@dar:/home/denis
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# rsync -arHAXSzq denis@dar:/home/denis/etc/fstab .
	terre:/mnt/memdisk# diff fstab /etc/fstab
	terre:/mnt/memdisk# echo $?
	0
	terre:/mnt/memdisk#
    </code></div>
    <p>
      We can backup to a remote sftp server, we can compress the data on-fly but it is not stored compressed nor ciphered.
      Restoration operation is possible per file or for the whole backup
    </p>

    <h5>Tar</h5>
    <p>
      tar has no way to perform sftp or other secured transfer protocol, nor encryption by itself. When time comes to
      restore a particular file, the whole backup has to be retrieved, unciphered and uncompressed to restore even
      just a sigle file</p>

    <h3>Backup Robustness</h3>


    <h5>Dar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# dar -c backup -R SRC -z6


	--------------------------------------------
	74725 inode(s) saved
	including 0 hard link(s) treated
	0 inode(s) changed at the moment of the backup and could not be saved properly
	0 byte(s) have been wasted in the archive to resave changing files
	0 inode(s) with only metadata changed
	0 inode(s) not saved (no inode/file change)
	0 inode(s) failed to be saved (filesystem error)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) recorded as deleted from reference backup
	--------------------------------------------
	Total number of inode(s) considered: 74725
	--------------------------------------------
	EA saved for 0 inode(s)
	FSA saved for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# ls -al backup*
	-rw-r--r-- 1 root root 219088536 Nov 17 17:45 backup.1.dar
	terre:/mnt/memdisk# ./hide_change backup.1.dar 1
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# dar -x backup -R DST
	<e>backup.1.dar is not a valid file (wrong magic number), please provide the good file. [return = YES | Esc = NO]</e>
	Escaping...
	Final memory cleanup...
	Aborting program. User refused to continue while asking: backup.1.dar is not a valid file (wrong magic number), please provide the good file.
	terre:/mnt/memdisk# dar -x backup -R DST <e>-alax</e>
	LAX MODE: In spite of its name, backup.1.dar does not appear to be a dar slice, assuming a data corruption took place and continuing
	LAX MODE: Archive is flagged as having escape sequence (which is normal in recent archive versions). However if this is not expected, shall I assume a data corruption occurred in this field and that this flag should be ignored? (If unsure, refuse) [return = YES | Esc = NO]
	Escaping...


	--------------------------------------------
	<e>74725 inode(s) restored</e>
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	<e>Total number of inode(s) considered: 74725</e>
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk# diff -r SRC DST
	terre:/mnt/memdisk# echo $?
	0
	terre:/mnt/memdisk#
    </code></div>
    <p>
      Modifying the first bit <i>dar/</i> has seen the corruption. We can use the lax mode (<code>-alax</code> option) to bypass this
      corruption and then the restoration proceeds normally. We can try a bit further for example somewhere in the middle of the archive,
      thus at offset 876354144 (half of the size expressed in bit, not byte):
    </p>
    <div class=code><code>
	terre:/mnt/memdisk# ls -l backup*
	-rw-r--r-- 1 root  root   219088536 Nov 17 17:45 backup.1.dar
	terre:/mnt/memdisk# hide_change backup.1.dar 876354144
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# dar -x backup -R DST
	<e>Error while restoring /mnt/memdisk/DST/linux-5.9.8/drivers/mtd/spi-nor/core.c : compressed data CRC error</e>


	--------------------------------------------
	74724 inode(s) restored
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	<e class=red>1 inode(s) failed to restore (filesystem error)</e>
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 74725
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	Final memory cleanup...
	All files asked could not be restored
	terre:/mnt/memdisk# diff -rq SRC DST
	<e>Files SRC/linux-5.9.8/drivers/mtd/spi-nor/core.c and DST/linux-5.9.8/drivers/mtd/spi-nor/core.c differ</e>
	terre:/mnt/memdisk#
    </code></div>

    <p>
      One file could not be restored properly as reported by <i>dar</i>,
      but all other files could be and are identical to their respective
      originals. Let's modifying the last bit for completness:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# ls -al *.dar
	-rw-r--r-- 1 root root 219088537 Nov 17 17:45 backup.1.dar
	terre:/mnt/memdisk# cp backup.1.dar backop.1.dar
	terre:/mnt/memdisk# hide_change backup.1.dar 1752708287
	terre:/mnt/memdisk# ls -al *.dar
	-rw-r--r-- 1 root root 219088536 Nov 17 17:58 backop.1.dar
	-rw-r--r-- 1 root root 219088536 Nov 17 17:58 backup.1.dar
	terre:/mnt/memdisk# diff backup.1.dar backop.1.dar
	Binary files backup.1.dar and backop.1.dar differ
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# dar -x backup -R DST


	--------------------------------------------
	74725 inode(s) restored
	including 0 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 74725
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	terre:/mnt/memdisk#
	terre:/mnt/memdisk# diff -rq SRC DST
	terre:/mnt/memdisk# echo $?
	0
	terre:/mnt/memdisk#
    </code></div>
    <p>
      By chance it did not affected the ability to restore the backup. However if it ever had,
      we could have fall back to the <code>--sequential-read</code> mode, use a already created
      snapshot (aka isolated catalogue) as seen about the snapshot feature, or as last resort
      use the <code>-alax option</code> eventually combined with the <code>--sequential-read</code>
      mode.
    </p>

    <h5>Rsync</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# rsync -arHAXS SRC/* DST
	terre:/mnt/memdisk# ls -al DST
	total 0
	drwxr-xr-x  3 root root  60 Nov 17 18:07 .
	drwxrwxrwt  4 root root 140 Nov 17 18:07 ..
	drwxrwxr-x 24 root root 740 Nov 10 21:16 linux-5.9.8
	terre:/mnt/memdisk# diff -rq SRC DST
	terre:/mnt/memdisk# ./hide_change DST/linux-5.9.8/README 10
	terre:/mnt/memdisk# diff -rq SRC DST
	Files SRC/linux-5.9.8/README and DST/linux-5.9.8/README differ
	terre:/mnt/memdisk# rsync -arvHAXS SRC/* DST
	sending incremental file list

	sent 1,254,054 bytes  received 5,215 bytes  839,512.67 bytes/sec
	total size is 954,980,692  speedup is 758.36
	terre:/mnt/memdisk# diff -rq SRC DST
	<e>Files SRC/linux-5.9.8/README and DST/linux-5.9.8/README differ</e>
	terre:/mnt/memdisk#
    </code></div>

    <p>
      modifying the backup (the directory we sync with), <i>rsync</i> does not
      report any difference and the backup stay corrupted.
    </p>

    <h5>Tar</h5>
    <div class=code><code>
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# tar -czf backup.tar.gz SRC
	terre:/mnt/memdisk# ls -l backup*
	-rw-r--r-- 1 root root 183659664 Nov 17 18:11 backup.tar.gz
	terre:/mnt/memdisk# ./hide_change backup.tar.gz 1
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xzf ../backup.tar.gz

	gzip: stdin: not in gzip format
	tar: Child returned status 1
	<e class=red>tar: Error is not recoverable: exiting now</e>
	terre:/mnt/memdisk/DST#
	terre:/mnt/memdisk/DST# find . -ls
	1720964      0 drwxr-xr-x   2 root     root           40 Nov 17 18:56 .
	terre:/mnt/memdisk/DST#
    </code></div>

    <p>
      Modifying the first byte leads to a completely unusable backup. Nothing got restored at all.
      Let's see what going on when modifying a single bit in the middle of the backup:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# ls -l backup*
	-rw-r--r-- 1 root root 183659664 Nov 17 18:11 backup.tar.gz
	terre:/mnt/memdisk# ./hide_change backup.tar.gz 734638656
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xf ../backup.tar.gz
	tar: Skipping to next header

	<e class=red>gzip: stdin: invalid compressed data--crc error</e>

	gzip: stdin: invalid compressed data--length error
	tar: Child returned status 1
	<e>tar: Error is not recoverable: exiting now</e>
	terre:/mnt/memdisk/DST#
	terre:/mnt/memdisk/DST# diff -rq ../SRC SRC | wc -l
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/arc: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/arm: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/arm64: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/c6x: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/h8300: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/microblaze: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/mips: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/nios2: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/openrisc: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/powerpc: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/sh: No such file or directory
	diff: SRC/linux-5.9.8/scripts/dtc/include-prefixes/xtensa: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/copyloops/copy_mc_64.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/copyloops/copyuser_64.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/copyloops/copyuser_power7.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/copyloops/memcpy_64.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/copyloops/memcpy_power7.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/nx-gzip/include/vas-api.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/primitives/asm/asm-compat.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/primitives/asm/asm-const.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/primitives/asm/feature-fixups.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/primitives/asm/ppc_asm.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/primitives/word-at-a-time.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/stringloops/memcmp_32.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/stringloops/memcmp_64.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/stringloops/strlen_32.S: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/vphn/asm/lppaca.h: No such file or directory
	diff: SRC/linux-5.9.8/tools/testing/selftests/powerpc/vphn/vphn.c: No such file or directory
	<e>150</e>
	terre:/mnt/memdisk/DST# find ../SRC | wc -l
	<e class=blue>74726</e>
	terre:/mnt/memdisk/DST# find SRC | wc -l
	<e class=red>32615</e>
	terre:/mnt/memdisk/DST#
    </code></div>
    <p>
      Only 32615 files on the 74726 that were saved could be restored. Assuming the problem is due to
      the fact the backup is compressed, let's see tar without compression:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# tar -cf backup.tar SRC
	terre:/mnt/memdisk# ls -l backup*
	-rw-r--r-- 1 root root 1011312640 Nov 17 19:28 backup.tar
	terre:/mnt/memdisk# ./hide_change backup.tar 1
	terre:/mnt/memdisk# rm -rf DST
	terre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xf ../backup.tar
	tar: This does not look like a tar archive
	<e>tar: Skipping to next header</e>
	tar: Exiting with failure status due to previous errors
	terre:/mnt/memdisk/DST# diff -rq ../SRC SRC
	terre:/mnt/memdisk/DST# echo $?
	0
	terre:/mnt/memdisk/DST#
    </code></div>
    <p>
      Without compression, a <i>tar</i> backup is much more reliable, however we now need more than 5 times
      storage space to hold the backup. Let's see what happens when we modify a single bit in the midle of the backup:
    </p>

    <div class=code><code>
	terre:/mnt/memdisk# ./hide_change backup.tar 4045250560
	terre:/mnt/memdisk# rm -rf DST
	mterre:/mnt/memdisk# mkdir DST
	terre:/mnt/memdisk# cd DST
	terre:/mnt/memdisk/DST# tar -xf ../backup.tar
	terre:/mnt/memdisk/DST#
	terre:/mnt/memdisk/DST# diff -rq ../SRC SRC
	<e class=red>Files ../SRC/linux-5.9.8/drivers/media/pci/bt8xx/bttv-cards.c and SRC/linux-5.9.8/drivers/media/pci/bt8xx/bttv-cards.c differ</e>
	terre:/mnt/memdisk/DST#
    </code></div>

    <p>
      the backup restoration suceeded according to <i>tar</i> but the corruption has been completely ignored!!!
      The result is both a corrupted backup and a corrupted restored data, with no notification at all...
    </p>

    <h5>Parchive</h5>

    <p>
      We can increase the robustness of any file or set of files by mean of <i>Parchive</i> software. If its use
      is adapted to <i>tar</i> and <i>dar</i> it is not adapted to <i>rsync</i> due to the directory tree structure it uses for its backup.
      We will thus here measure the par2create (<i>Parchive</i>) execution time compared to backup time of <i>tar</i> and <i>dar</i>.
    </p>

    <div class=code><code>
	devuan:/mnt/memdisk# mkdir SRC
	devuan:/mnt/memdisk# cp --preserve -r /usr SRC
	devuan:/mnt/memdisk# time <e class=blue>tar</e> -czf backup.tar.gz SRC
	62.550u 3.148s <e>1:01.75</e> 106.3%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time <e class=blue>dar</e> -c backup -z6 -1 0 -at -R SRC -q
	60.287u 1.152s <e>1:01.45</e> 99.9%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# ls -l backup.*
	-rw-r--r-- 1 root root <e>601976990</e> Dec  1 10:48 backup.1.dar
	-rw-r--r-- 1 root root <e>588260243</e> Dec  1 10:47 backup.tar.gz
	devuan:/mnt/memdisk# time <e class=blue>par2create</e> -r5 -n1 -q backup.tar.gz

	Opening: backup.tar.gz
	Done
	94.465u 0.535s <e>0:05.74</e> 1654.8%  0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time <e class=blue>par2create</e> -r5 -n1 -q backup.1.dar

	Opening: backup.1.dar
	Done
	110.048u 0.364s <e>0:06.19<e> 1783.5% 0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      We see that the redundancy process is not negligible: for 5% of data redundancy,
      we need around 10% of extra CPU time. Things get worse when the size of the
      data to process by <i>Parchive</i> increases and when the disk I/O comes to play
      (here the /mnt/memdisk was an in-memory tmpfs filesystem). This is the
      case when the amount of data to backup is larger than the available RAM space, which
      is a quite frequent situation:
    </p>

    <div class=code><code>
	devuan:~/tmp# du -sh SRC
	<e>27G</e>     SRC
	devuan:~/tmp# free -m
	.             total        used        free      shared  buff/cache   available
	Mem:          <e>15776</e>         560         433           1       14782       14823
	Swap:             0           0           0
	devuan:~/tmp#
    </code></div>
    <p>
      We are now placed in this context, having a 27 GiB data to backup on a machine having only around 16 GiB of
      RAM.
    </p>

    <div class=code><code>
	devuan:~/tmp# time dar -c backup -z6 -at -1 0 -R SRC -q <e class=blue>-E 'par2create -r5 -n1 -q %b.%N.%e'</e>

	Opening: backup.1.dar
	Done
	15237.777u 105.379s <e>36:48.53</e> 694.7%     0+0k 158854544+57572120io 158pf+0w
	devuan:~/tmp#
    </code></div>
    <p>
      This execution time of around 36 mn above can be improved by using multiple slices. Choosing a slice size smaller than the available RAM
      let <i>Parchive</i> compute parity data right after each slice has been generated, while it is still in the disk cache (RAM),
      bypassing the corresponding disks I/O we had previously in a second time:
    </p>
    <div class=code><code>
	devuan:~/tmp# time dar -c backup_splitted -z6 -at -1 0 -R SRC -q <e class=blue>-E 'par2create -r5 -n1 -q %b.%N.%e'</e> <e>-s 1G</e>

	Opening: backup_splitted.1.dar
	Done

	Opening: backup_splitted.2.dar
	Done
	<i>[...]</i>
	Opening: backup_splitted.26.dar
	Done

	Opening: backup_splitted.27.dar
	Done
	6040.106u 49.201s <e>21:58.73</e> 461.7%       0+0k 61862640+57567104io 123pf+0w
	devuan:~/tmp#
    </code></div>
    <p>
      The total execution time dropped to around 22 mn! Which makes a 40% time reduction.
      By the way, having here 27 files of 1 GiB is also easier to manipulate (file transfer,
      copy to removable media,...) than a huge equivalent file of 27 GiB.
    </p>
    <div class=code><code>
	devuan:~/tmp# time tar -czf backup.tar.gz SRC
	<e class=blue>837.662u</e> 80.776s <e>18:26.08</e> 83.0% 0+0k 54926128+54799696io 6pf+0w
	devuan:~/tmp# time par2create -r5 -n1 -q backup.tar.gz
	Opening: backup.tar.gz
	Done
	<e class=blue>13352.393u</e> 71.390s <e>18:24.34</e> 1215.5%     0+0k 95000064+2772144io 9pf+0w
	devuan:~/tmp#

    </code></div>
    <p>
      We get the same execution time (18 mn) for both <i>tar</i> and <i>par2</i> for thus a total of 36 mn.
      This same time for both software while the real CPU usage is much more important for <i>par2</i>,
      clearly shows that the slowest operation was the disk I/O. Else the overall time of the operation
      is similar to what we say with <i>dar</i> above, except that we cannot use multi-volume
      to speed up the operation as we did with <i>dar</i>: <i>tar</i> is not able to compress
      *and* produce multi-volume backup: What we would gain on one side would be lost on the
      other side...
    </p>


    <h3>Execution Performance</h3>

    </p>
    <p>
      In order to compare performance in a fair manner, we have to take into
      consideration that some CPU intensive features are not implement by all softwares or have
      different default values:
    </p>
    <ul>
      <li>
	The default compression level differs: <i>dar</i> uses level 9 by default while <i>rsync</i>
	and <i>tar</i> use level 6 which is faster. Only <i>dar</i> and <i>rsync</i> seems able
	let the user set this value, so we will have to manually set <i>dar</i> to use level 6 too:
	<code>-z6 option</code>
      </li>
      <li>
	the disk usage optimization is not supported by <i>tar</i> so we will not activate
	sparse file detection and optimization (for <i>rsync</i> no <code>-S option</code>)
	and disable it for <i>dar</i>
	(activated by default): <code>-1 0 option</code>
      </li>
      <li>
	<i>dar</i> spends non negligible CPU cycle to duplicate metadata along the backup, this
	is one of the root of exclusive robusness brought by <i>dar</i> backups, but this is an
	optional feature. We will disable it using the
	<code>-at option</code>
      </li>
      <li>
	<i>rsync</i> and <i>dar</i> calculate checksum on the saved data, while tar completely skips
	this data protection. Unfortunately this is not possible to disable for both,
	thus <i>tar</i> will have a speed advantage thanks to this difference.
      </li>
    </ul>
    </p>
    For the data reduction, we will first compare with the same feature set, then activate all specific
    features each software can leverage to improve data reduction, and will measure the execution
    time impact.
    </p>

    <p>
      All performance aspects are not interesting in all <b>use cases</b>. We can distinguish two main
      types of use cases:
    </p>
    <ul>
      <li>
	A first set of tests will cover the <b>copy operations</b>, they will not use any compression, focusing
	only on execution time.
      </li>
      <li>
	A second set of tests will cover the <b>backup operations</b>, use compression and focus on the data
	reduction mainly but also on the execution time.
      </li>
    </ul>

    <p>
      When using <i>rsync</i> as a backup tool (at the opposite of a copy operation), we assume the remote
      (or local) copy <i>is</i> the backup, and thus restoring implies syncing back this remote (or local)
      copy to the place the original data was located and has been lost.
    </p>

    <p>
      To prepare the data under test we used:
    </p>
    <ul>
      <li>a big ISO file</li>
      <li>a full linux system</li>
    </ul>

    <p>
      All data to backup or to copy has been stored in a tmpfs, which is also the destination of the created backups and
      restored data. The swap has been disabled to avoid any disk I/O penalty, in the intention to provide a fair
      comparison environment (avoiding disk cache variable performance).
    </p>

    <div class=code><code>
	devuan:/mnt/memdisk# free
	total        used        free      shared  buff/cache   available
	Mem:       16155172      691764      151608     8780152    15311800     6299316
	<e>Swap:             0           0           0</e>
	devuan:/mnt/memdisk# df -h .
	Filesystem      Size  Used Avail Use% Mounted on
	<e>tmpfs</e>            14G  4.0K   14G   1% /mnt/memdisk
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      To prepare the Linux system under backup we installed the <i>Devuan</i> system a few days before in a VM. On day D,
      a full backup has been executed, we updated/upgraded the system using the disto package manager and we made a differential
      backup based on the first one, both backup being wrote to the testing machine (bare-metal server) that was used for the performance tests:
    </p>

    <div class=code><code>
	root@Georges:~# dar -c sftp://denis@10.13.30.163/home/denis/tmp/full -zlz4 -R / -M -D --hash sha1 -afile-auth -G cat_full
	root@Georges:~# apt-get update
	<i>[...]</i>
	root@Georges:~# apt-get upgrade
	<i>[...]</i>
	root@Georges:~# dar -c sftp://denis@10.13.30.163/home/denis/tmp/diff -A cat_full -zlz4 -R / -M -D --hash sha1 -afile-auth
	root@Georges:~#
    </code></div>

    <p>
      Back on the testing host (the bare-metal server at 10.13.30.163) we restored the data
      for the performance test, the following way: excluding FSA and EA to avoid a tone of warning as those are not
      supported on tmpfs filesystem:
    </p>

    <div class=code><code>
	devuan:/mnt/memdisk# mkdir state-1
	devuan:/mnt/memdisk# mkdir state-2
	devuan:/mnt/memdisk# dar -x ~denis/tmp/full -R state-1 --fsa-scope none -u "*"


	--------------------------------------------
	136836 inode(s) restored
	including 27 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 136836
	--------------------------------------------
	EA restored for 3 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	devuan:/mnt/memdisk# dar -x ~denis/tmp/full -R state-2 --fsa-scope none -u "*"


	--------------------------------------------
	136836 inode(s) restored
	including 27 hard link(s)
	0 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 136836
	--------------------------------------------
	EA restored for 3 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	devuan:/mnt/memdisk# dar -x ~denis/tmp/diff -R state-2 --fsa-scope none -u "*" -w


	--------------------------------------------
	568 inode(s) restored
	including 0 hard link(s)
	136670 inode(s) not restored (not saved in archive)
	0 inode(s) not restored (overwriting policy decision)
	0 inode(s) ignored (excluded by filters)
	0 inode(s) failed to restore (filesystem error)
	0 inode(s) deleted
	--------------------------------------------
	Total number of inode(s) considered: 137238
	--------------------------------------------
	EA restored for 0 inode(s)
	FSA restored for 0 inode(s)
	--------------------------------------------
	devuan:/mnt/memdisk#

    </code></div>
    <p>
      This leads us to have two directories <code>state-1</code> and <code>state-2</code> corresponding to the state of the <i>Devuan</i> machine has two days ago and today respectively.
    </p>


    <h4>Performance of copy operations</h4>

    <p>
      To perform the copy operation, we have decomposed the operations to precisely measure the execution time. We could have decided to pipe the backup to a second instance of the
      backup tool restoring the data (<i>tar</i> and <i>dar</i> only would benefit from this). But the time measurement was less easy to obtain and doing that way does not seem to
      provide any noticable speed improvement. The data used here in <code>SRC1</code> is a single big ISO file (a <i>Devuan</i> installation DVD image).
    </p>

    <h5>Dar</h5>
    <div class=code><code>
	devuan:/mnt/memdisk# time dar -c copy -1 0 -at -R SRC1 -q
	1.834u 2.909s <e>0:04.87</e> 97.1%     0+0k 744+0io 12pf+0w
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time dar -x copy -R DST -q
	1.563u 2.836s <e>0:04.41</e> 99.5%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# du -sh SRC1 DST
	4.4G    SRC1
	4.4G    DST
	devuan:/mnt/memdisk# diff -r SRC1 DST
	devuan:/mnt/memdisk# echo $?
	0
	devuan:/mnt/memdisk# rm -rf DST copy.1.dar
	devuan:/mnt/memdisk# time dar -c copy -1 0 -at -R SRC2 -q
	4.739u 3.683s <e>0:08.44</e> 99.6%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time dar -x copy -R DST -q
	4.449u 3.872s <e>0:08.34</e> 99.6%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# du -sh SRC2 DST
	4.1G    SRC2
	4.1G    DST
	devuan:/mnt/memdisk# find DST | wc -l
	136837
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      The overall copy time for <i>dar</i> is:
    </p>
    <ul>
      <li>9.18 seconds for the big file in <code>SRC1</code></li>
      <li>16.78 seconds for the full linux system in <code>SRC2</code></li>
    </ul>

    <h5>Rsync</h5>
    <div class=code><code>
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time rsync -arH SRC1 DST
	23.088u 5.420s <e>0:15.28</e> 186.5%   0+0k 168+0io 4pf+0w
	devuan:/mnt/memdisk# diff -r SRC1/ DST/SRC1/
	devuan:/mnt/memdisk# echo $?
	0
	devuan:/mnt/memdisk# rm -rf DST
	devuan:/mnt/memdisk# time rsync -arH SRC2 DST
	22.408u 8.560s <e>0:16.59</e> 186.6%   0+0k 1224+0io 6pf+0w
	devuan:/mnt/memdisk# du -sh SRC2 DST
	4.1G    SRC2
	4.1G    DST
	devuan:/mnt/memdisk# find DST | wc -l
	136838
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      The overall copy time for <i>rsync</i> is:
    </p>
    <ul>
      <li>15.28 seconds for the big file in <code>SRC1</code></li>
      <li>16.59 seconds for the full linux system in <code>SRC2</code></li>
    </ul>


    <h5>Tar</h5>
    <div class=code><code>
	devuan:/mnt/memdisk# cd SRC1
	devuan:/mnt/memdisk/SRC1# time tar -cf ../copy.tar *
	0.343u 2.756s <e>0:03.10</e> 99.6%     0+0k 104+0io 1pf+0w
	devuan:/mnt/memdisk/SRC1# cd ../
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time tar -xf ../copy.tar
	0.339u 3.071s <e>0:03.41</e> 99.7%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# cd ..
	devuan:/mnt/memdisk# diff -r SRC1/ DST/
	devuan:/mnt/memdisk# echo $?
	0
	devuan:/mnt/memdisk# rm -rf DST copy.tar
	devuan:/mnt/memdisk# cd SRC2
	devuan:/mnt/memdisk/SRC2# time tar -cf ../copy.tar *
	<e class=red>tar: tmp/.ICE-unix/19789: socket ignored</e>
	<e class=red>tar: tmp/.X11-unix/X0: socket ignored</e>
	0.760u 2.887s <e>0:03.66</e> 99.4%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/SRC2# cd ..
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time tar -xf ../copy.tar
	0.814u 3.556s <e>0:04.38</e> 99.5%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# cd ..
	devuan:/mnt/memdisk# du -sh SRC2 DST
	4.1G    SRC2
	4.1G    DST
	devuan:/mnt/memdisk# find DST | wc -l
	136834
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      the overall copy time for <i>tar</i> is:
    </p>
    <ul>
      <li>6.51 seconds for the big file in <code>SRC1</code></li>
      <li>8.04 seconds for the full Linux system in <code>SRC2</code></li>
    </ul>

    <h5>Cp</h5>
    <div class=code><code>
	devuan:/mnt/memdisk# time cp --preserve -r SRC1 DST
	0.051u 2.514s <e>0:02.58</e> 99.2%     0+0k 8+0io 1pf+0w
	devuan:/mnt/memdisk# diff -r SRC1 DST
	devuan:/mnt/memdisk# echo $?
	0
	devuan:/mnt/memdisk# rm -rf DST
	devuan:/mnt/memdisk# time cp --preserve -r SRC2 DST
	0.910u 4.194s <e>0:05.15</e> 99.0%     0+0k 288+0io 1pf+0w
	devuan:/mnt/memdisk# du -sh SRC2 DST
	<e>4.1G</e>    SRC2
	<e class=red>4.2G</e>    DST
	devuan:/mnt/memdisk# find DST | wc -l
	136838
	devuan:/mnt/memdisk# find DST/SRC2/tmp/ -ls
	2315983      0 drwxrwxrwt   4 root     root          100 Dec  3 10:32 DST/SRC2/tmp/
	2315987      0 drwxrwxrwt   2 root     root           60 Dec  3 10:27 DST/SRC2/tmp/.ICE-unix
	2315988      0 srwxrwxrwx   1 denis    denis           0 Dec  3 10:27 DST/SRC2/tmp/.ICE-unix/19789
	2315985      0 drwxrwxrwt   2 root     root           60 Dec  3 10:32 DST/SRC2/tmp/.X11-unix
	2315986      0 srwxrwxrwx   1 root     root            0 Dec  3 10:32 DST/SRC2/tmp/.X11-unix/X0
	2315984      4 -r--r--r--   1 root     root           11 Dec  3 10:32 DST/SRC2/tmp/.X0-lock
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      The overall copy time for <i>cp</i> is:
    </p>
    <ul>
      <li>2.58 seconds for the big file in <code>SRC1</code></li>
      <li>5.15 seconds for the full Linux system in <code>SRC2</code></li>
    </ul>
    <p>
      <i>cp</i> is always the fastest and does reject the unix sockets as <i>tar</i> does.
      However it requires slightly more storage than all other softwares tested here. And if
      metadata (ACL, Extended Attributes, filesystem specific attributes, ...) need to be copied
      with data, it does not match the need.
    </p>

    <h4>Performance of Backup operations</h4>

    <p>
      For reference:
    </p>

    <div class=code><code>
	devuan:/mnt/memdisk# du -sb state-*
	<e>4095931349</e>      state-1
	<e>4136318367</e>      state-2
	devuan:/mnt/memdisk# find state-1 | wc -l
	136837
	devuan:/mnt/memdisk# find state-2 | wc -l
	137239
	devuan:/mnt/memdisk#
    </code></div>

    <h5>Dar</h5>
    <h6>Minimal features</h6>
    <div class=code><code>
	devuan:/mnt/memdisk# time dar -c dar-full -R state-1 -at -1 0 -z6 -q
	145.970u 3.263s <e>2:29.73</e> 99.6%   0+0k 12344+0io 71pf+0w
	devuan:/mnt/memdisk# time dar -c dar-diff -R state-2 -A dar-full -at -1 0 -z6 -q -asecu
	8.957u 0.959s <e>0:09.93</e> 99.6%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root   <e>49498524</e> Dec  3 16:17 dar-diff.1.dar
	-rw-r--r-- 1 root root <e>1580562224</e> Dec  3 16:16 dar-full.1.dar
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time dar -x dar-full -R DST -q
	18.677u 4.244s <e>0:22.94</e> 99.8%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -x dar-diff -R DST -q -w
	2.585u 0.780s <e>0:03.48</e> 96.5%     0+0k 1856+0io 20pf+0w
	devuan:/mnt/memdisk#
	devuan:/mnt/memdisk# time dar -x dar-full -R DST -q -w -g etc/fstab
	0.934u 0.036s <e>0:00.98</e> 97.9%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      for <i>dar</i> with minimal features (metadata no redundancy <code>-at</code>, no sparse file consideration <code>-1 0</code>):
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 61.41%</li>
      <li>data reduction on storage for the diff backup is: 98.80%</li>
      <li>data reduction over the network is the same as on storage</li>
      <li>execution time to restore a single file is: 0.98 s</li>
      <li>execution time to restore the full backup: 22.94 s</li>
      <li>execution time ot restore the diff backup: 3.48 s </li>
      <li>full backup time: 149.73 s</li>
      <li>diff backup time: 9.93 s</li>
    </ul>

    <h6>sparse file</h6>

    <div class=code><code>
	devuan:/mnt/memdisk# rm -rf DST *.dar
	devuan:/mnt/memdisk# time dar -c dar-full -R state-1 -at -z6 -q
	154.971u 3.000s <e>2:37.99</e> 99.9%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -c dar-diff -R state-2 -A dar-full -at -z6 -q -asecu
	9.488u 0.871s <e>0:10.37</e> 99.8%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root   <e>49505251</e> Dec  3 16:27 dar-diff.1.dar
	-rw-r--r-- 1 root root <e>1578428790</e> Dec  3 16:25 dar-full.1.dar
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time dar -x dar-full -R DST -q
	24.231u 6.110s <e>0:30.36</e> 99.9%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -x dar-diff -R DST -q -w
	2.677u 0.793s <e>0:03.48</e> 99.4%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -x dar-full -R DST -q -w -g etc/fstab
	1.067u 0.053s <e>0:01.13</e> 98.2%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      for <i>dar</i> with default features (metadata no redundancy <code>-at</code>, with sparse file consideration (activated by default))
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 61.46%</li>
      <li>data reduction on storage for the diff backup is: 98.80%</li>
      <li>data reduction over the network is the same as on storage</li>
      <li>execution time to restore a single file is: 1.13 s</li>
      <li>execution time to restore the full backup: 30.36 s</li>
      <li>execution time ot restore the diff backup: 3.48 s </li>
      <li>full backup time: 157.99 s</li>
      <li>diff backup time: 10.37 s</li>
    </ul>


    <h6>Sparse file and binary delta</h6>
    <div class=code><code>
	devuan:/mnt/memdisk# rm -rf DST *.dar
	devuan:/mnt/memdisk# time dar -c dar-full -R state-1 -at -z6 --delta sig -q
	159.262u 3.332s <e>2:42.62</e> 99.9%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -c dar-diff -R state-2 -A dar-full -at -z6 -q -asecu
	6.149u 0.950s <e>0:07.11</e> 99.7%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# ls -l *.dar
	-rw-r--r-- 1 root root   <e>23883368</e> Dec  3 16:39 dar-diff.1.dar
	-rw-r--r-- 1 root root <e>1602481058</e> Dec  3 16:38 dar-full.1.dar
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time dar -x dar-full -R DST -q
	24.169u 6.163s <e>0:30.35</e> 99.9%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -x dar-diff -R DST -q -w
	2.481u 0.942s <e>0:03.44</e> 99.4%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time dar -x dar-full -R DST -q -w -g etc/fstab
	1.205u 0.059s <e>0:01.27</e> 98.4%     0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      for <i>dar</i> with advanced features (metadata no redundancy <code>-at</code>, with binary delta computation <code>--delta sig</code>):
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 60,87%</li>
      <li>data reduction on storage for the diff backup is: 99.42%</li>
      <li>data reduction over the network is the same as on storage</li>
      <li>execution time to restore a single file is: 1.27 s</li>
      <li>execution time to restore the full backup: 30.35 s</li>
      <li>execution time ot restore the diff backup: 1.27 s </li>
      <li>full backup time: 162.62 s</li>
      <li>diff backup time: 7.11 s</li>
    </ul>

    <h5>Rsync</h5>
    <h6>minimal features</h6>

    <div class=code><code>
	devuan:/mnt/memdisk# mkdir rsync-backup
	devuan:/mnt/memdisk# time rsync -arHz --info=stats state-1/* rsync-backup

	sent <e>1,585,540,014 bytes  received 2,174,472 bytes</e>  10,080,726.90 bytes/sec
	total size is 4,260,538,564  speedup is 2.68
	202.640u 8.503s <e>2:36.98</e> 134.5%  0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
	devuan:/mnt/memdisk# time rsync -arHz --info=stats <e class=blue>--no-whole-file</e> state-2/* rsync-backup

	<e>sent 29,077,377 bytes  received 216,581 bytes</e>  3,446,348.00 bytes/sec
	total size is 4,300,916,222  speedup is 146.82
	7.555u 1.115s <e>0:07.33</e> 118.1%    0+0k 1784+0io 7pf+0w
	devuan:/mnt/memdisk# du -sb rsync-backup
	<e>4136318307</e>      rsync-backup
	devuan:/mnt/memdisk#
	devuan:/mnt/memdisk# rm -rf state-1
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time rsync -arHz --info=stats <e class=blue>--no-whole-file</e> rsync-backup/* DST

	<e>sent 1,599,585,756 bytes  received 2,181,147 bytes</e>  10,105,784.88 bytes/sec
	total size is 4,300,916,222  speedup is 2.69
	204.192u 8.306s <e>2:37.81</e> 134.6%  0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time rsync -arHz --info=stats rsync-backup/etc/fstab DST/etc

	sent 44 bytes  received 12 bytes  112.00 bytes/sec
	total size is 664  speedup is 11.86
	<e>0.001u 0.002s</e> 0:00.00 0.0%      0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      for <i>rsync</i> with minimal features (no sparse file consideration):
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 0%</li>
      <li>data reduction on storage for the diff backup is: 0%</li>
      <li>data reduction over the network for the full backup is: 61.23%</li>
      <li>data reduction over the network for the diff backup is: 99.29%</li>
      <li>execution time to restore a single file is: 0.003 s</li>
      <li>execution time ot restore the full+diff backup: 157.81 s (this is not due to the <code>--no-whole-file</code> see next text)</li>
      <li>full backup time: 156.98 s</li>
      <li>diff backup time: 7.33 s</li>
    </ul>

    <h6>sparse file + binary delta</h6>

    <div class=code><code>
	devuan:/mnt/memdisk# mkdir rsync-backup
	devuan:/mnt/memdisk# time rsync -arHSz --info=stats state-1/* rsync-backup

	<e>sent 1,585,540,014 bytes  received 2,174,460 bytes</e>  8,605,498.50 bytes/sec
	total size is 4,260,538,564  speedup is 2.68
	232.038u 13.137s <e>3:03.44</e> 133.6% 0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# time rsync -arHSz --info=stats <e class=blue>--no-whole-file</e> state-2/* rsync-backup

	<e>sent 29,077,381 bytes  received 216,577 bytes</e>  3,446,348.00 bytes/sec
	total size is 4,300,916,222  speedup is 146.82
	7.305u 1.275s <e>0:07.04</e> 121.7%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# du -sb rsync-backup
	<e>4136318307</e>      rsync-backup
	devuan:/mnt/memdisk# rm -rf state-1
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time rsync -arHSz --info=stats rsync-backup/* DST

	sent 1,599,585,756 bytes  received 2,181,219 bytes  10,042,426.18 bytes/sec
	total size is 4,300,916,222  speedup is 2.69
	205.089u 12.354s <e>2:38.39</e> 137.2% 0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
	devuan:/mnt/memdisk# time rsync -arHSz --info=stats rsync-backup/etc/fstab DST/etc

	sent 44 bytes  received 12 bytes  112.00 bytes/sec
	total size is 664  speedup is 11.86
	0.001u 0.002s 0:00.00 0.0%      0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      for <i>rsync</i> with advanced features (sparse file consideration <code>-S option</code>, binary delta <code>--no-whole-file</code>)
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 0%</li>
      <li>data reduction on storage for the diff backup is: 0%</li>
      <li>data reduction over the network for the full backup is: 60.64%</li>
      <li>data reduction over the network for the diff backup is: 99.28%</li>
      <li>execution time to restore a single file is: 0.003 s</li>
      <li>execution time to restore the full+diff backup: 158.39 s</li>
      <li>full backup time: 183.44 s</li>
      <li>diff backup time: 7.04 s</li>

    </ul>


    <h5>Tar</h5>
    <h6>minimal features</h6>
    <div class=code><code>
	devuan:/mnt/memdisk# cd state-1
	devuan:/mnt/memdisk/state-1# time tar --listed-incremental=../snapshot.file -czf ../tar-full.tar.gz *
	<e class=red>tar: tmp/.ICE-unix/19789: socket ignored</e>
	<e class=red>tar: tmp/.X11-unix/X0: socket ignored</e>
	153.624u 8.676s 2:31.71 106.9%  0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/state-1# time tar --listed-incremental=../snapshot.file -czf ../tar-diff.tar.gz *
	0.809u 0.369s 0:00.98 118.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/state-1# cd ..
	devuan:/mnt/memdisk# ls -l tar*
	-rw-r--r-- 1 root root     765425 Dec  3 16:49 tar-diff.tar.gz
	-rw-r--r-- 1 root root 1546464033 Dec  3 16:48 tar-full.tar.gz
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time tar -xzf ../tar-full.tar.gz
	27.106u 6.756s 0:26.72 126.6%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# cd ..
	devuan:/mnt/memdisk# diff --no-dereference -r state-1 DST
	Only in state-1: .cache
	Only in state-1/tmp/.ICE-unix: 19789
	Only in state-1/tmp/.X11-unix: X0
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time tar -xzf ../tar-diff.tar.gz
	0.183u 0.085s <e class=red>0:00.18</e> 144.4%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST#
    </code></div>
    <p>
      Doing that way, the <i>tar</i> differential backup is empty: it only contains empty directories, no file data.
      We will apply the changes over <code>state-1</code> rather than already setup changes at <code>state-2</code>.
      This seems to mean that if the system clock is wrong or was wrong at the time a file was modified
      (like daylight saving? or before NTP synchronization at system startup), which is
      the same as here, were the changes have been brought before full backup was done, <b><u>those changes will not be
      backed up by <i>tar</i></u></b>, while the file's attributes (file size, last modification date,...) changed.
    </p>
    <div class=code><code>
	devuan:/mnt/memdisk# cd state-1
	devuan:/mnt/memdisk/state-1# time tar --listed-incremental=../snapshot.file -czf ../tar-full.tar.gz *
	<e class=red>tar: tmp/.ICE-unix/19789: socket ignored</e>
	<e class=red>tar: tmp/.X11-unix/X0: socket ignored</e>
	150.751u 8.299s <e>2:28.59</e> 107.0%  0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/state-1# cd ..
	devuan:/mnt/memdisk# dar -x ~denis/tmp/diff -R state-1 --fsa-scope none -u "*" -w -q
	devuan:/mnt/memdisk# cd state-1
	devuan:/mnt/memdisk/state-1# time tar --listed-incremental=../snapshot.file -czf ../tar-diff.tar.gz *
	6.147u 0.559s <e>0:06.40</e> 104.5%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/state-1# cd ..
	devuan:/mnt/memdisk# ls -l tar* snapshot.file
	-rw-r--r-- 1 root root    <e>3350869</e> Dec  3 17:08 snapshot.file
	-rw-r--r-- 1 root root   <e>44607904</e> Dec  3 17:08 tar-diff.tar.gz
	-rw-r--r-- 1 root root <e>1546448179</e> Dec  3 17:04 tar-full.tar.gz
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd dst
	dst: No such file or directory.
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time tar -xzf ../tar-full.tar.gz
	26.807u 7.020s <e>0:26.72</e> 126.5%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# time tar -xzf ../tar-diff.tar.gz
	1.492u 0.381s <e>0:01.48</e> 126.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# time tar -xzf ../tar-full.tar.gz etc/fstab
	25.219u 2.581s <e>0:25.15</e> 110.4%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST#
    </code></div>

    <p>
      for <i>tar</i> with minimal features (no sparse file consideration):
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 62.16%</li>
      <li>data reduction on storage for the diff backup is: 98.92%</li>
      <li>data reduction over the network is the same as on storage</li>
      <li>execution time to restore a single file is: 25.15 s</li>
      <li>execution time to restore the full backup: 26.72 s</li>
      <li>execution time ot restore the diff backup: 1.48 s</li>
      <li>full backup time: 148.59 s</li>
      <li>diff backup time: 6.40 s</li>
    </ul>


    <h6>sparse file</h6>

    <p>
      Whe had to recreate <code>state-1</code> as we needed modifying it at previous test
    </p>

    <div class=code><code>
	devuan:/mnt/memdisk# rm tar* snapshot.file
	devuan:/mnt/memdisk# cd state-1
	devuan:/mnt/memdisk/state-1# time tar --listed-incremental=../snapshot.file -czSf ../tar-full.tar.gz *
	<e class=red>tar: tmp/.ICE-unix/19789: socket ignored</e>
	<e class=red>tar: tmp/.X11-unix/X0: socket ignored</e>
	152.878u 10.155s <e>2:29.38</e> 109.1% 0+0k 1520+0io 18pf+0w
	devuan:/mnt/memdisk/state-1# dar -x ~denis/tmp/diff --fsa-scope none -u "*" -w -q
	devuan:/mnt/memdisk/state-1# time tar --listed-incremental=../snapshot.file -czSf ../tar-diff.tar.gz *
	6.369u 0.752s <e>0:06.55</e> 108.5%    0+0k 3992+0io 16pf+0w
	devuan:/mnt/memdisk/state-1# cd ..
	devuan:/mnt/memdisk# ls -l tar* snap*
	-rw-r--r-- 1 root root    <e>3350870</e> Dec  3 17:29 snapshot.file
	-rw-r--r-- 1 root root   <e>44604194</e> Dec  3 17:29 tar-diff.tar.gz
	-rw-r--r-- 1 root root <e>1546226992</e> Dec  3 17:27 tar-full.tar.gz
	devuan:/mnt/memdisk# rm -rf DST
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time tar -xzSf ../tar-full.tar.gz
	27.331u 7.774s <e>0:26.27</e> 133.6%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# time tar -xzSf ../tar-diff.tar.gz
	1.547u 0.487s <e>0:01.50</e> 134.6%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# time tar -xzSf ../tar-full.tar.gz etc/fstab
	25.068u 2.565s <e>0:25.00</e> 110.4%   0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST#
    </code></div>

    <p>
      for <i>tar</i> with advanced features (sparse file consideration <code>-S option</code>):
    </p>
    <ul>
      <li>data reduction on storage for the full backup is: 62.16%</li>
      <li>data reduction on storage for the diff backup is: 98.92%</li>
      <li>data reduction over the network is the same as on storage</li>
      <li>execution time to restore a single file is: 25.0 s</li>
      <li>execution time to restore the full backup: 26.27 s</li>
      <li>execution time ot restore the diff backup: 1.50 s</li>
      <li>full backup time: 149.38 s</li>
      <li>diff backup time: 6.55 s</li>
    </ul>


    <h4>Ciphering performance</h4>

    <p>
      We evaluate here ciphering and deciphering performance. To compare on the same base we use the following
      parameters:
      <ul>
	<li>AES-256 algorithm with CBC mode</li>
	<li>pkcs5 v2 (pbkdf2) key derivation function (KDF) algorithm</li>
	<li>KDF with 100,000 iterations</li>
	<li>salt</li>
	<li>password provided on command-line (insecure) to not depend on user or disk access</li>
	<li>local system to backup and backup repository on a tmpfs filesystem</li>
	<li>swap has been disabled to avoid tmpfs latency in case it would have been swapped out</li>
      </ul>

      To measure the ciphering time only, we will not use compression, though most of the time compression
      should be used due to the use case encryption matches: relatively long time storage and/or costing
      cloud space and network transfer time or limited removable media storage.
    </p>
    <p>
      The content that will be backed up is a copy of <code> /usr</code> directory tree. We will measure:
      <ul>
	<li>the time to backup</li>
	<li>the time to restore the whole backup</li>
	<li>and the time to restore just the "diff" binary</li>
      </ul>
    </p>

    <div class=code><code>
	devuan:/mnt/memdisk# mkdir SRC
	devuan:/mnt/memdisk# cp --preserve -r /usr SRC
	devuan:/mnt/memdisk# time dar -c backup -K "aes256:hello world!" --kdf-param 100000:sha1 -R SRC -q -at -1 0
	9.213u 3.245s <e>0:05.38</e> 231.4%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# time dar -x backup -K "hello world!" -R DST -q
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	4.481u 2.628s <e>0:03.75</e> 189.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# rm -rf DST/usr
	evuan:/mnt/memdisk# time dar -x backup -K "hello world!" -R DST -q -g usr/bin/diff
	Warning, the archive backup has been encrypted. A wrong key is not possible to detect, it would cause DAR to report the archive as corrupted
	0.419u 0.025s <e>0:00.42</e> 102.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk#
    </code></div>
    <p>
      For <i>dar</i> the operation took:
    </p>
    <ul>
      <li>5.38 seconds to backup with encryption</li>
      <li>3.75 seconds to restore the whole ciphered backup</li>
      <li>0.42 seconds to restore a single file from the ciphered backup</li>
    </ul>
    <p>
      <i>dar</i> is twice quicker to uncipher than to cipher the whole archive, but restoring a particular file is quite immediate.
      By default, <i>dar</i> uses argon2 for KDF, which is the most secure algorithm as of year 2020 to derive a key, but we had to
      adapt to openssl used with <i>tar</i> that does not (yet) support this algorithm.
    </p>
    <p>
      To avoid plain-text attack a variable length elastic buffer containing random data is encrypted with the rest of the backed up files
      at the beginning and at the end of the backup, this has some performance penalties (time to generate and time to cipher/decipher).
      This explains why two identical invocations of <i>dar</i> produce backups of different sizes and execution times:
    </p>
    <div class=code><code>
	devuan:/mnt/memdisk# time dar -c backup -K "aes256:hello world!" -at -1 0 -R SRC -q -w
	9.782u 3.413s <e>0:06.28</e> 210.0%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# la backup.1.dar
	-rw-r--r-- 1 root root 1572<e>706497</e> Nov  9 14:50 backup.1.dar
	devuan:/mnt/memdisk# time dar -c backup -K "aes256:hello world!" -at -1 0 -R SRC -q -w
	9.173u 2.845s <e>0:05.50</e> 218.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk# la backup.1.dar
	-rw-r--r-- 1 root root 1572<e>655217</e> Nov  9 14:50 backup.1.dar
	devuan:/mnt/memdisk#
    </code></div>

    <p>
      <i>rsync</i> has no way to store the backup ciphered. Testing directly <i>tar</i> now:
    </p>
    <p>
      <i>tar</i> has not support for ciphering. Though it seems the some use openssl workaround
      this restriction. To measure the execution time we have to create as script that pipes <i>tar</i>
      and <i>openssl</i> so we can measure the execution time of this script as a whole. There is thus one
      script for backup and one for the restoration of <i>tar</i>+<i>openssl</i>.
    </p>
    <div class=code><code>
	devuan:/mnt/memdisk# cat > tar.backup
	#!/bin/bash

	if [ -z "$1" ] ; then
	&nbsp;&nbsp;echo "usage: $0 &lt;backup name&gt; [ &ltfile or dir&gt; ]"
	&nbsp;&nbsp;exit 1
	fi

	tar -cf - "$2" | openssl enc -e -aes256 -out "$1" -pbkdf2 -iter 100000 -salt -pass pass:"hello world!"
	devuan:/mnt/memdisk#
	devuan:/mnt/memdisk# chmod u+x tar.backup
	devuan:/mnt/memdisk# cd SRC
	devuan:/mnt/memdisk/SRC# time ../tar.backup ../backup.tar.crypted usr
	3.954u 2.498s <e>0:04.69</e> 137.3%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/SRC# cd ..
	devuan:/mnt/memdisk# ls -l backup.tar.crypted
	-rw-r--r-- 1 root root 1603594272 Nov  9 13:33 backup.tar.crypted
	devuan:/mnt/memdisk#
	devuan:/mnt/memdisk# cat > tar.restore
	#!/bin/bash

	if [ -z "$1" ] ; then
	&nbsp;&nbsp;echo "usage: $0 &lt;tar.crypted file&gt; [&lt;file or dir&gt;]"
	&nbsp;&nbsp;exit 1
	fi

	openssl enc -d -aes256 -in "$1" -pbkdf2 -iter 100000 -salt -pass pass:"hello world!" | tar -x "$2"
	devuan:/mnt/memdisk# chmod u+x tar.restore
	devuan:/mnt/memdisk# rm -rf DST
	devuan:/mnt/memdisk# mkdir DST
	devuan:/mnt/memdisk# cd DST
	devuan:/mnt/memdisk/DST# time ../tar.restore ../backup.tar.crypted
	1.807u 2.821s <e>0:02.70</e> 171.1%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST#
	devuan:/mnt/memdisk/DST# rm -rf usr
	devuan:/mnt/memdisk/DST# time ../tar.restore ../backup.tar.crypted usr/bin/diff
	1.336u 1.428s <e>0:01.79</e> 153.6%    0+0k 0+0io 0pf+0w
	devuan:/mnt/memdisk/DST# find
	.
	./usr
	./usr/bin
	./usr/bin/diff
	devuan:/mnt/memdisk/DST#

    </code></div>

    <p>
      For <i>tar</i> the operation took:
    </p>
    <ul>
      <li>4.69 seconds for backup</li>
      <li>2.70 seconds to restore the whole backup</li>
      <li>1.79 seconds to restore a single file</li>
    </ul>
    <p>
      <i>tar</i> as <i>dar</i> is also twice longer to cipher than to decipher, this seems to be related to the algorithm itself.
      Though <i>tar</i> is a bit faster than <i>dar</i> but lacks protection against clear-text: the generated encrypted backup
      have the exact same sizes at one byte precision, this means the blocks boundaries and tar file internal structure always
      lay at the same file offset for a given content:
    </p>
    <div class=code><code>
      devuan:/mnt/memdisk/SRC# time ../tar.backup ../backup.tar.crypted usr
      4.112u 2.343s 0:04.72 136.6%    0+0k 0+0io 0pf+0w
      devuan:/mnt/memdisk/SRC# ls -l ../bac
      backup.1.dar        backup.tar.crypted
      devuan:/mnt/memdisk/SRC# ls -l ../backup.tar.crypted
      -rw-r--r-- 1 root root <e>1603594272</e> Nov  9 14:56 ../backup.tar.crypted
      devuan:/mnt/memdisk/SRC# time ../tar.backup ../backup.tar.crypted usr
      3.952u 2.564s 0:04.79 135.9%    0+0k 0+0io 0pf+0w
      devuan:/mnt/memdisk/SRC# ls -l ../backup.tar.crypted
      -rw-r--r-- 1 root root <e>1603594272</e> Nov  9 14:56 ../backup.tar.crypted
      devuan:/mnt/memdisk/SRC#
    </code></div>


    <h2>Appendix 2 - Scripts used for testing</h2>

  </body>
</html>
